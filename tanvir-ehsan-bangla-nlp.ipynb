{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10648911,"sourceType":"datasetVersion","datasetId":6593694}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:12:07.909403Z","iopub.execute_input":"2025-02-05T10:12:07.909766Z","iopub.status.idle":"2025-02-05T10:12:07.933694Z","shell.execute_reply.started":"2025-02-05T10:12:07.909735Z","shell.execute_reply":"2025-02-05T10:12:07.932727Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bangla/1120.pdf\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Task 1: Project Setup & Team Coordination\nAssigned to:\nMd. Mahmudun Nobi\nObjective:\nEstablish the workspace, tools, and roles so the team can collaborate effectively.\nInputs\nNo prior inputs (starting point).\nDetailed Steps\n1.\nCreate a Shared Repository\nUse GitHub or GitLab for version control.\nInitialize a clear folder structure:\ndata/\n(for raw and processed data)\nscripts/\n(for code)\nmodels/\n(for trained models)\ndocs/\n(for documentation)\nresults/\n(for outputs or artifacts)\n2.\nList Team Roles & Responsibilities\nConfirm each of the following tasks (2–25) is assigned to one team member.\nPublish the roles in a shared document or project board.\n3.\nSet Up Version Control Rules\nDecide on a branching strategy (e.g.,\nmain\nbranch for stable).\nEnforce reviews or pull requests for quality control.\n4.\nDocument Required Tools\nPython, OCR software, Bangla NLP libraries (e.g., bnltk, PyBangla, etc.).\nProvide\nrequirements.txt\nor\nenvironment.yml\nfor easy setup.\nFinal Outputs\nA functioning version-control repository.\nA public list assigning tasks to each team member.\nBasic setup instructions in\ndocs/\nor\nREADME.md\n.\nTask 2: PDF Extraction & Verification\nAssigned to:\nAman Ullah\nObjective:\nConvert the Bangla PDF into text (using direct extraction or OCR) and verify no data islost.\nInputs\nBangla PDF file(s).\nRepository and environment (Task 1).\nDetailed Steps\n1.\nCheck PDF Type\nIf text-based, use\npdftotext\nor similar.\nIf scanned, set up Bangla OCR (e.g., Tesseract with Bangla language pack).\n2.\nExtract Text\nFor text-based PDF:\npdftotext input.pdf output.txt\n.\nFor scanned PDF: run each page through OCR, combine results.\n3.\nCombine & Label\nMerge all text outputs into one file or a structured format (e.g., JSON).\nLabel each page or section for traceability.\n4.\nManual Verification\nRandomly check paragraphs for accuracy.\nNote any corrupted pages or garbled text in a short report.\nFinal Outputs\nraw_extracted.txt\nor\nraw_extracted.json\ncontaining all text.\nA short verification log noting any anomalies.\nTask 3: Section/Chapter Segmentation\nAssigned to:\nMD. Mahabur Rahman\nObjective:\nSplit the extracted text into logical sections, chapters, or headings.\nInputs\nExtracted text from Task 2.\nDetailed Steps\n1.\nIdentify Section Boundaries\nLook for headings, page breaks, or known markers.\nConsider manual review if the PDF doesn’t have clear headings.\n2.\nCreate Segmentation Rules\nFor example, search for headings in all caps or numeric chapter titles.\nAlternatively, use page-based segmentation if structure is consistent.\n3.\nGenerate Structured Output\nSave each segment with a unique ID (e.g.,\nsection_001\n,\nsection_002\n).\nStore them in\nsegmented_data.json\n.\n4.\nValidate Samples\nCheck a few sections manually to ensure correct boundaries.\nFinal Outputs\nsegmented_data.json\n(or similar format) with each section labeled.\nBrief note on the segmentation criteria used.\nTask 4: Basic Cleanup & Formatting\nAssigned to:\nMd Khairul Kabir Simul\nObjective:\nRemove extraneous line breaks, unify encoding, and ensure consistent formatting.\nInputs\nSegmented text from Task 3.\nDetailed Steps\n1.\nEnsure UTF-8 Encoding\nConvert files to UTF-8 if needed.\nCheck for any stray BOM (Byte Order Mark) characters.\n2.\nRemove Unwanted Spaces\nTrim trailing or leading whitespace.\nMerge lines that were incorrectly split.\n3.\nPreserve Meaningful Paragraphs\nKeep paragraph boundaries if relevant.\nUse a consistent delimiter (e.g., newline or special token).\n4.\nReview Special Characters\nEnsure any Bangla punctuation or diacritics remain intact.\nRemove or replace invisible characters if they cause issues.\nFinal Outputs\nCleaned text files (e.g.,\ncleaned_segments.json\n).\nA short summary of formatting rules or regex patterns applied.\nTask 5: Text Normalization & Spell Checking\nAssigned to:\nMd Shahadat Kabir\nObjective:\nStandardize Bangla characters and correct spelling or OCR errors.\nInputs\nCleaned, formatted text (Task 4).\nDetailed Steps\n1.\nIdentify Common Errors\nUse a Bangla spell-check dictionary or manually curated list.\nLook for zero-width joiners or misread characters.\n2.\nAutomated Spell Checking\nUse an existing Bangla spell-check library if available.\nIf not, write scripts to match patterns of common mistakes.\n3.\nManual Review of Corrections\nSpot-check corrected text to ensure the changes make sense.\nList any unrecognized words for potential dictionary updates.\n4.\nMaintain a Correction Log\nDocument frequent error types and how they were fixed.\nFinal Outputs\nnormalized_text.json\n(fully corrected).\nA correction log (CSV or text) noting original vs. corrected forms.\nTask 6: Exploratory Data Analysis (EDA)\nAssigned to:\nMst. Tahmina Jerin Arju\nObjective:\nUnderstand overall text structure, frequencies, and any peculiarities.\nInputs\nNormalized text (Task 5).\nDetailed Steps\n1.\nCalculate Basic Stats\nWord count, unique vocabulary size, sentence lengths.\nFrequency of punctuation, special characters.\n2.\nFrequency Analysis\nTop N most frequent words (excluding stopwords, if relevant).\nPossibly bigrams or trigrams for collocations.\n3.\nVisualize Data\nGenerate charts/histograms (word count distribution, etc.).\nUse libraries like matplotlib, seaborn, or Plotly.\n4.\nIdentify Anomalies\nLook for extremely long sentences, repeated segments, or rare characters.\nNote potential issues for future tasks.\nFinal Outputs\nAn EDA report (notebook or PDF) with charts and tables.\nSuggestions for special handling or further cleaning if anomalies are detected.\nTask 7: Tokenization & Sentence Splitting\nAssigned to:\nTanvir Ehsan\nObjective:\nBreak text into tokens (words/subwords) and sentences, respecting Bangla languagerules.\nInputs\nNormalized text (Task 5), EDA insights (Task 6).\nDetailed Steps\n1.\nSelect or Implement Tokenizer\nUse a Bangla-specific tokenizer (e.g., from bnltk, PyBangla).\nOr implement custom logic handling Bangla punctuation and spacing.\n2.\nHandle Special Tokens\nIf you have numbers, emoticons, or domain-specific markers, decide how to tokenize them.\nRemove or keep punctuation tokens, based on downstream needs.\n3.\nSentence Splitting\nSplit on Bangla end-of-sentence markers (e.g., “।”), periods, exclamation marks.\nVerify correctness with sample text.\n4.\nValidate Sample Output\nCheck boundary cases (e.g., abbreviations, decimal numbers).\nAdjust rules if needed.\nFinal Outputs\ntokenized_data.json\nwith tokens per sentence.\nOptionally, a separate file listing sentence boundaries.\nTask 8: Part-of-Speech (POS) Tagging\nAssigned to:\nArif Miah\nObjective:\nLabel each token with a grammatical role (e.g., noun, verb, adjective).\nInputs\nTokenized text (Task 7).\nDetailed Steps\n1.\nChoose a POS Tagger\nUse a Bangla POS tagger if available (e.g., BNGLearn).\nAlternatively, train a CRF or neural model on a labeled dataset.\n2.\nApply the Tagger\nTag each token, generating (token, tag) pairs.\nWatch for out-of-vocabulary words or unknown forms.\n3.\nEvaluate on Sample\nIf you have labeled data, compare model output to ground truth.\nCalculate accuracy, precision, recall, F1 if feasible.\n4.\nRefine or Retrain\nIf performance is low, adjust hyperparameters or add more training data.\nDocument any improvements made.\nFinal Outputs\npos_tagged_data.json\ncontaining tokens and POS tags.\nA brief evaluation report (if labeled data is available).\nTask 9: Named Entity Recognition (NER)\nAssigned to:\nRishan Hasan Tenis\nObjective:\nIdentify entities (persons, locations, organizations) within text.\nInputs\nTokenized text (Task 7); optionally POS tags (Task 8).\nDetailed Steps\n1.\nChoose or Train an NER Model\nUse a known Bangla NER tool or train from scratch (CRF, BiLSTM, Transformer).\nGather or create annotation data if needed.\n2.\nAnnotate Named Entities\nTag tokens as PERSON, LOCATION, ORGANIZATION, or OTHER.\nEvaluate performance on a small set of manually annotated examples.\n3.\nResolve Ambiguities\nCheck for entity label conflicts or misclassifications.\nAdjust model or add gazetteers to improve recognition.\n4.\nFinalize Annotated Data\nStore results in\nner_annotated_data.json\nwith the recognized entities.\nFinal Outputs\nner_annotated_data.json\nwith entity labels.\nAn NER performance summary (precision, recall, F1).\nTask 10: Domain Terminology Extraction\nAssigned to:\nMahjabin Siddika Oyshi\nObjective:\nIdentify specialized or domain-specific terms (e.g., legal, technical) to build a glossary.\nInputs\nTokenized/POS-tagged data (Tasks 7 & 8).\nAny known domain dictionaries if available.\nDetailed Steps\n1.\nFrequency & POS-Based Filtering\nIdentify potential domain terms by frequency thresholds or POS patterns (nouns, noun-phrases).\nExclude common stopwords.\n2.\nCandidate Term Extraction\nUse statistical methods (e.g., TF-IDF, RAKE) to find multi-word terms.\nCombine with NER if relevant (organizations, product names).\n3.\nManual Verification\nCurate the list to remove irrelevant or generic words.\nEnrich domain terms with definitions if possible.\n4.\nCreate a Glossary\nStore each term with optional metadata (frequency, part-of-speech, definition).\nFinal Outputs\nA domain glossary file (CSV, JSON) listing specialized terms.\nAny reference material or definitions for each term.\nTask 11: Keyphrase Extraction\nAssigned to:\nRidwan Ahmed Arman\nObjective:\nExtract important phrases that summarize the essence of each segment or the overalltext.\nInputs\nTokenized text (Task 7), domain glossary (Task 10).\nDetailed Steps\n1.\nApply Extraction Methods\nImplement or use an existing method (TF-IDF, RAKE, YAKE, etc.).\nFocus on top phrases for each segment.\n2.\nFilter Out Irrelevant Phrases\nExclude overly common words or phrases.\nUse domain glossary to boost or highlight relevant terms.\n3.\nRank Keyphrases\nScore phrases by frequency, position, or other heuristics.\nKeep the top N phrases per section or chapter.\n4.\nReview & Validate\nSpot-check keyphrases for correctness.\nRefine thresholds or parameters as needed.\nFinal Outputs\nA structured file (e.g.,\nkeyphrases.json\n) listing top phrases per segment.\nA short memo describing the extraction method and parameters used.\nTask 12: Morphological Analysis\nAssigned to:\nMd. Mehedi Hasan Miju\nObjective:\nExamine word structures in Bangla (roots, prefixes, suffixes) for linguistic insights orimproved NLP results.\nInputs\nTokenized text (Task 7).\nPotentially POS-tagged data (Task 8).\nDetailed Steps\n1.\nIdentify Common Morphemes\nUse a morphological analyzer if available, or compile known roots and affixes.\nNote special rules for Bangla (e.g., sandhi, reduplication).\n2.\nApply or Develop Morphological Parser\nFor each token, attempt to split into root + suffix/prefix.\nRecord any unknown forms for review.\n3.\nAnalyze Results\nDocument recurrent patterns or exceptions.\nConsider if morphological insights can improve tokenization or POS tags.\n4.\nValidate & Refine\nManually inspect a subset of words for correctness.\nUpdate rules as needed.\nFinal Outputs\nA file or table showing morphological breakdown of select words.\nA mini “Bangla Morphology Guide” describing patterns or edge cases.\nTask 13: Summarization\nAssigned to:\nShahidur Rahman\nObjective:\nGenerate concise summaries of each chapter or section in the Bangla text.\nInputs\nTokenized text (Task 7); optionally keyphrases (Task 11).\nDetailed Steps\n1.\nSelect a Summarization Approach\nExtractive: e.g., TextRank, LexRank.\nAbstractive: neural summarizer (if resources and data allow).\n2.\nCompute Summaries\nFor extractive: rank sentences by importance (using a graph or similarity).\nFor abstractive: pass segments through a pre-trained or custom Bangla summarizer.\n3.\nEvaluate Quality\nIf you have reference summaries, calculate ROUGE scores.\nOtherwise, do a manual review for coherence and completeness.\n4.\nFine-tune Parameters\nAdjust length constraints or model parameters.\nRe-check final output for clarity.\nFinal Outputs\nA file (e.g.,\nsummaries.json\n) with short summaries for each section.\nA brief evaluation or review report.\nTask 14: Sentiment Analysis\nAssigned to:\nAbdullah Al Mamun Sakib\nObjective:\nClassify text (or segments) by sentiment polarity (positive, negative, neutral), ifapplicable.\nInputs\nTokenized text (Task 7).\n(Optional) Labeled training data if you have sentiment annotations.\nDetailed Steps\n1.\nGather/Prepare Sentiment Data\nIf no labeled data is available, create a small set of labeled examples or use a pre-trainedBangla sentiment model.\n2.\nTrain or Fine-tune Model\nUse classical ML (Naive Bayes, SVM) or deep learning (LSTM, Transformer).\nEnsure any text features (embeddings, TF-IDF) are consistent with earlier tasks.\n3.\nMake Predictions\nAssign sentiment labels to each section or sentence.\nInclude confidence scores if your model provides them.\n4.\nEvaluate Performance\nIf labeled data exists, compute accuracy, precision, recall, F1.\nIf no labels exist, do a manual check on sample predictions.\nFinal Outputs\nsentiment_annotations.json\nmapping segments to sentiment labels.\nA sentiment model or script, plus an evaluation summary.\nTask 15: Topic Modeling\nAssigned to:\nSaiful Islam\nObjective:\nDiscover hidden topics in the text (using LDA or similar techniques).\nInputs\nCleaned/tokenized text (Tasks 5, 7).\nDetailed Steps\n1.\nPrepare Text Data\nConvert text into a suitable representation (Bag-of-Words, TF-IDF).\nRemove stopwords or extremely rare tokens if needed.\n2.\nApply Topic Model\nUse LDA, NMF, or another approach.\nDecide on the number of topics (k) based on domain knowledge or perplexity measures.\n3.\nLabel Topics\nExamine top words for each topic to assign a descriptive label.\nDocument how many segments fall under each topic distribution.\n4.\nEvaluate Coherence\nCalculate topic coherence metrics (C_v, UMass, etc.) if possible.\nManually inspect top words for interpretability.\nFinal Outputs\nA file showing each segment’s topic distribution (e.g.,\ntopic_model_results.json\n).\nA summary of the discovered topics, including their key terms.\nTask 16: Document/Text Classification\nAssigned to:\nMd. Al Amin\nObjective:\nClassify text segments into predefined categories if your corpus is labeled (e.g., subjectareas).\nInputs\nTokenized text (Task 7).\nLabeled data indicating categories or classes (if available).\nDetailed Steps\n1.\nCollect/Identify Categories\nCommon categories might be “news,” “legal,” “technical,” etc.\nEnsure you have enough data in each class for training.\n2.\nFeature Engineering\nUse TF-IDF, embeddings, or topic distributions as features.\nPossibly incorporate domain glossary terms (Task 10).\n3.\nTrain Classifier\nTest algorithms like Naive Bayes, SVM, or a neural network.\nEvaluate using cross-validation or a hold-out test set.\n4.\nOptimize & Validate\nTune hyperparameters.\nDocument precision, recall, and F1 for each class.\nFinal Outputs\nClassification model files or scripts.\nA performance report with confusion matrix and metrics.\nTask 17: Building Language Models or Embeddings\nAssigned to:\nPalash Chandra Dash\nObjective:\nTrain or fine-tune word embeddings (Word2Vec, FastText) or a transformer-basedBangla model.\nInputs\nLarge corpus of tokenized text (Task 7).\n(Optional) External Bangla text data for better coverage.\nDetailed Steps\n1.\nChoose Method\nWord2Vec, GloVe, FastText for static embeddings, or BERT-like models for contextualembeddings.\nEnsure you have enough data for meaningful embeddings.\n2.\nPreprocess Data\nConfirm text is consistently tokenized.\nRemove any extraneous tokens if they might degrade training.\n3.\nTrain the Model\nFor Word2Vec or FastText, set parameters (window size, vector dimension, etc.).\nFor BERT or GPT-based models, fine-tune or pre-train with a GPU if possible.\n4.\nEvaluate Embeddings\nPerform intrinsic tests (e.g., word similarity).\nTest extrinsic tasks (POS tagging, classification) to see improvement.\nFinal Outputs\nTrained embedding files or model checkpoints.\nEvaluation summary (nearest neighbors, analogy tasks, or downstream performance).\nTask 18: Quality Assurance for NLP Outputs\nAssigned to:\nTithee Chakma Mama\nObjective:\nSystematically review outputs from POS tagging, NER, classification, etc., for accuracyand consistency.\nInputs\nAll intermediate NLP outputs (Tasks 8–17).\nDetailed Steps\n1.\nDefine QA Checklists\nFor POS: Are common words tagged correctly?\nFor NER: Are known person/organization names accurately identified?\n2.\nRandom Sampling & Review\nSelect random samples from each output.\nCompare to a small manual “gold” set or run quick checks for obvious errors.\n3.\nLog Common Mistakes\nE.g., mislabeled entities, incorrect sentence boundaries.\nSuggest possible improvements (e.g., retraining with more data, rule-based post-processing).\n4.\nCompile QA Report\nSummarize error rates.\nPropose next steps or re-training strategies as needed.\nFinal Outputs\nA QA report highlighting accuracy, error patterns, and recommended fixes.\nUpdated guidelines for subsequent retesting or model fine-tuning.\nTask 19: Model Tuning & Versioning\nAssigned to:\nMd. RASEL SARKER\nObjective:\nFine-tune hyperparameters and manage version control for each trained model (POS,NER, sentiment, etc.).\nInputs\nModels from Tasks 8–17.\nQA feedback from Task 18.\nDetailed Steps\n1.\nList All Trained Models\nKeep a central registry (POS model v1, NER model v2, etc.).\nDocument their training datasets and major parameters.\n2.\nHyperparameter Sweeps\nFor each model, systematically vary key parameters (learning rate, batch size, number ofepochs, etc.).\nTrack performance improvements or declines.\n3.\nVersion Control\nStore each model checkpoint and training config in a structured format.\nTag versions in Git (e.g.,\npos-model-v1.1\n).\n4.\nPick the Best Models\nBased on evaluation metrics (accuracy, F1) and QA results.\nArchive older or lower-performing versions to avoid confusion.\nFinal Outputs\nUpdated and optimized model checkpoints.\nA versioning document or table mapping model names to performance metrics.\nTask 20: Data Visualization & Reporting\nAssigned to:\nMd Maruf Hossain\nObjective:\nCreate visualizations and consolidated reports showing key findings (topics, sentimentdistribution, etc.).\nInputs\nProcessed/annotated data, model outputs (Tasks 8–19).\nDetailed Steps\n1.\nCompile Key Metrics\nSummaries from EDA, topic modeling, sentiment analysis, etc.\nCombine into a single analytics dashboard or a set of charts.\n2.\nGenerate Visuals\nBar charts for topic frequencies, pie charts for sentiment distribution, line graphs for wordcount over sections, etc.\nUse Python libraries (matplotlib, seaborn) or BI tools.\n3.\nHighlight Critical Insights\nFor instance, which topics are most prevalent, average sentiment, top entities.\nProvide commentary on possible interpretations.\n4.\nDraft a Presentation\nCould be a PPT, PDF, or web dashboard.\nMake visuals easy to understand for non-technical stakeholders.\nFinal Outputs\nA set of plots and charts (\n/results/visuals/\n).\nA consolidated presentation or report summarizing major insights.\nTask 21: Documentation (Technical & User Guides)\nAssigned to:\nMd Reja Alam Talukder\nObjective:\nDocument how each task was performed, the tools used, and instructions toreproduce results.\nInputs\nAll previous tasks (1–20).\nDetailed Steps\n1.\nCollect Methodologies\nInclude steps for extraction, segmentation, normalization, tokenization, etc.\nNote any special libraries or custom scripts with usage instructions.\n2.\nCreate a Step-by-Step Guide\nFor each task, outline required inputs, commands, and output formats.\nProvide examples (e.g., how to run the POS tagger).\n3.\nConsolidate References\nLink to external resources (Bangla dictionaries, tool documentation).\nKeep a bibliography or reference list if relevant.\n4.\nEnsure Clarity\nWrite for someone joining the project fresh.\nInclude troubleshooting tips or known issues.\nFinal Outputs\nA comprehensive documentation folder (\n/docs/\n).\nPossibly a README linking to each subsection of the documentation.\nTask 22: Final Review & Consistency Check\nAssigned to:\nMd.Mahmumudn Nobi\nObjective:\nEnsure all tasks are properly completed and outputs are consistent.\nInputs\nAll deliverables from Tasks 1–21.\nDetailed Steps\n1.\nValidate Naming & File Formats\nConfirm consistent naming conventions, e.g.,\nsegmented_data.json\n,\npos_tagged_data.json\n,etc.\nCheck that no essential files are missing or misplaced.\n2.\nCross-Reference Documentation\nVerify that the documentation (Task 21) accurately reflects the final directory structure.\nFix any broken links or references.\n3.\nCheck Model & Data Alignment\nEnsure the correct versions of data were used to train each model (per the versioningsystem).\nConfirm model outputs match the documented performance metrics.\n4.\nCompile a Final Handoff Note\nSummarize the entire pipeline, known limitations, and recommended next steps.\nFinal Outputs\nA final checklist or sign-off document verifying all tasks are done.\nA “known issues” list if any remain unresolved.\nTask 23: Packaging & Delivery\nAssigned to:\nSubena Khatun\nObjective:\nBundle all artifacts—data, models, code, documentation—into a coherent structureready for handover or deployment.\nInputs\nVerified outputs from Task 22.\nDetailed Steps\n1.\nOrganize Deliverables\nFolder structure:\ndata/\n(raw and processed)\nmodels/\n(final best versions)\nscripts/\n(all code)\ndocs/\n(all documentation)\nresults/\n(final charts, logs, etc.)\n2.\nCreate an Installation Guide\nInclude environment setup, library dependencies, and system requirements.\nProvide any Dockerfiles or containerization instructions if relevant.\n3.\nCompress or Archive\nZIP or tarball for offline sharing.\nAlternatively, create a GitHub release with all attached artifacts.\n4.\nPrepare a README\nSummarize contents of the package.\nProvide quickstart instructions.\nFinal Outputs\nA final packaged archive or GitHub release.\nA short installation and usage guide (\nINSTALL.md\nor within\nREADME\n).\nTask 24: Translation & Transliteration (Optional)\nAssigned to:\nMd. Nur Alam Sarker\nObjective:\nConvert Bangla text to English (or vice versa) and/or provide phonetic transliteration ifneeded.\nInputs\nCleaned or segmented text (Tasks 3–5) and potentially tokenized text (Task 7).\nDetailed Steps\n1.\nCheck Project Requirements\nDetermine if partial or entire text translation is needed.\nConfirm if transliteration is also required for certain tools.\n2.\nMachine Translation\nIf a Bangla-English MT system is available, run batch translations.\nIf none is available, do partial manual translation for key sections.\n3.\nTransliteration\nUse a transliteration library or mapping (Bangla script → Latin script).\nValidate accuracy with bilingual team members.\n4.\nReview Output\nCheck for mistranslations or transliteration errors (especially for names).\nMaintain a mapping table if multiple variants exist.\nFinal Outputs\ntranslated_text.json\nor\n.txt\n(if performing translation).\ntransliterated_text.json\n(if performing transliteration).\nValidation notes highlighting accuracy or known limitations.\nTask 25: Future Maintenance & Improvement\nAssigned to:\nArman Hossain\nObjective:\nPlan for incremental updates, bug fixes, and expansions.\nInputs\nFeedback from all previous tasks and final packaging (Tasks 1–24).\nDetailed Steps\n1.\nCollect Feedback\nGather user or stakeholder input on current deliverables.\nIdentify known issues (from Task 22) requiring deeper investigation.\n2.\nIdentify Enhancement Areas\nPotential expansions: more domain data, improved NER, additional language model training,etc.\nProposed timeline or version increments (v1.1, v2.0).\n3.\nSet Maintenance Schedule\nDecide how often the dataset, models, or codebase will be updated.\nAssign responsibility for future bug tracking and patch releases.\n4.\nPublish a Roadmap\nCreate a living document (e.g., a GitHub project board or\nroadmap.md\n).\nOutline short-term vs. long-term goals.\nFinal Outputs\nA roadmap document detailing next steps, future features, and timeline.\nAn optional “maintenance owners” list ensuring continuity if original team members change.","metadata":{}},{"cell_type":"code","source":"import shutil\n\ninput_pdf = \"/kaggle/input/bangla/1120.pdf\"\nwritable_pdf = \"/kaggle/working/1120.pdf\"\n\nshutil.copy(input_pdf, writable_pdf)  # Copy to writable location\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:12:07.934737Z","iopub.execute_input":"2025-02-05T10:12:07.934976Z","iopub.status.idle":"2025-02-05T10:12:08.285679Z","shell.execute_reply.started":"2025-02-05T10:12:07.934955Z","shell.execute_reply":"2025-02-05T10:12:08.284842Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/1120.pdf'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-ben\n!pip install pdf2image pytesseract\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:25:02.770932Z","iopub.execute_input":"2025-02-05T10:25:02.771256Z","iopub.status.idle":"2025-02-05T10:25:26.101740Z","shell.execute_reply.started":"2025-02-05T10:25:02.771222Z","shell.execute_reply":"2025-02-05T10:25:26.100606Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\nHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [62.9 kB]                 \nGet:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,651 kB]                     \nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                  \nGet:12 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]         \nGet:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,523 kB]            \nGet:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,606 kB]              \nHit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,654 kB]                      \nGet:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]   \nGet:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,742 kB]          \nGet:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]          \nGet:22 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,606 kB]        \nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,907 kB]                \nGet:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nFetched 28.9 MB in 3s (8,772 kB/s)                             \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\nThe following additional packages will be installed:\n  libpoppler-dev libpoppler-private-dev libpoppler118\nThe following NEW packages will be installed:\n  poppler-utils tesseract-ocr-ben\nThe following packages will be upgraded:\n  libpoppler-dev libpoppler-private-dev libpoppler118\n3 upgraded, 2 newly installed, 0 to remove and 114 not upgraded.\nNeed to get 1,977 kB of archives.\nAfter this operation, 1,567 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.6 [199 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.6 [5,184 B]\nGet:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.6 [1,071 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-ben all 1:4.00~git30-7274cfa-1.1 [516 kB]\nFetched 1,977 kB in 1s (2,677 kB/s)        \n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack .../libpoppler-private-dev_22.02.0-2ubuntu0.6_amd64.deb ...\nUnpacking libpoppler-private-dev:amd64 (22.02.0-2ubuntu0.6) over (22.02.0-2ubuntu0.5) ...\nPreparing to unpack .../libpoppler-dev_22.02.0-2ubuntu0.6_amd64.deb ...\nUnpacking libpoppler-dev:amd64 (22.02.0-2ubuntu0.6) over (22.02.0-2ubuntu0.5) ...\nPreparing to unpack .../libpoppler118_22.02.0-2ubuntu0.6_amd64.deb ...\nUnpacking libpoppler118:amd64 (22.02.0-2ubuntu0.6) over (22.02.0-2ubuntu0.5) ...\nSelecting previously unselected package poppler-utils.\nPreparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\nUnpacking poppler-utils (22.02.0-2ubuntu0.6) ...\nSelecting previously unselected package tesseract-ocr-ben.\nPreparing to unpack .../tesseract-ocr-ben_1%3a4.00~git30-7274cfa-1.1_all.deb ...\nUnpacking tesseract-ocr-ben (1:4.00~git30-7274cfa-1.1) ...\nSetting up tesseract-ocr-ben (1:4.00~git30-7274cfa-1.1) ...\nSetting up libpoppler118:amd64 (22.02.0-2ubuntu0.6) ...\nSetting up poppler-utils (22.02.0-2ubuntu0.6) ...\nSetting up libpoppler-dev:amd64 (22.02.0-2ubuntu0.6) ...\nSetting up libpoppler-private-dev:amd64 (22.02.0-2ubuntu0.6) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\nRequirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nimport subprocess\nfrom pdf2image import convert_from_path\nimport pytesseract\n\n# Paths\ninput_pdf = \"/kaggle/input/bangla/1120.pdf\"\nwritable_pdf = \"/kaggle/working/1120.pdf\"\n\n# Copy to writable directory\nshutil.copy(input_pdf, writable_pdf)\n\ndef is_text_pdf(pdf_path):\n    \"\"\"Check if the PDF contains embedded text.\"\"\"\n    try:\n        output = subprocess.run([\"pdffonts\", pdf_path], capture_output=True, text=True)\n        return len(output.stdout.splitlines()) > 2  # If fonts exist, it's text-based\n    except Exception as e:\n        print(f\"Error checking PDF type: {e}\")\n        return False\n\ndef extract_text_pdf(pdf_path, output_txt):\n    \"\"\"Extract text from a text-based PDF.\"\"\"\n    subprocess.run([\"pdftotext\", pdf_path, output_txt])\n    print(f\"Extracted text saved to {output_txt}\")\n\ndef extract_text_ocr(pdf_path, output_json):\n    \"\"\"Extract text using OCR for a scanned PDF.\"\"\"\n    pages = convert_from_path(pdf_path, poppler_path=\"/usr/bin/\")\n    extracted_text = {}\n\n    for i, page in enumerate(pages):\n        text = pytesseract.image_to_string(page, lang=\"ben\")  # Bangla OCR\n        extracted_text[f\"page_{i+1}\"] = text.strip()\n    \n    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n        json.dump(extracted_text, f, ensure_ascii=False, indent=4)\n    \n    print(f\"OCR extracted text saved to {output_json}\")\n\n# Determine PDF type and extract text\noutput_text = \"/kaggle/working/raw_extracted.txt\"\noutput_json = \"/kaggle/working/raw_extracted.json\"\n\nif is_text_pdf(writable_pdf):\n    extract_text_pdf(writable_pdf, output_text)\nelse:\n    extract_text_ocr(writable_pdf, output_json)\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:25:30.289744Z","iopub.execute_input":"2025-02-05T10:25:30.290093Z","iopub.status.idle":"2025-02-05T10:26:07.123850Z","shell.execute_reply.started":"2025-02-05T10:25:30.290065Z","shell.execute_reply":"2025-02-05T10:26:07.122831Z"},"trusted":true},"outputs":[{"name":"stdout","text":"OCR extracted text saved to /kaggle/working/raw_extracted.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from pdf2image import convert_from_path\nimport pytesseract\nimport json\n\n# Define paths\npdf_path = \"/kaggle/working/1120.pdf\"\noutput_json = \"/kaggle/working/raw_extracted.json\"\n\n# Convert PDF to images\ntry:\n    pages = convert_from_path(pdf_path, poppler_path=\"/usr/bin/\")\n    extracted_text = {}\n    \n    # Process each page\n    for i, page in enumerate(pages):\n        text = pytesseract.image_to_string(page, lang=\"ben\")  # Bangla OCR\n        print(f\"Processing page {i+1}: {text[:200]}...\")  # Preview first 200 characters\n        extracted_text[f\"page_{i+1}\"] = text.strip()\n\n    if not extracted_text:\n        print(\"No text was extracted from OCR.\")\n    else:\n        # Save the extracted text to JSON\n        try:\n            with open(output_json, \"w\", encoding=\"utf-8\") as f:\n                json.dump(extracted_text, f, ensure_ascii=False, indent=4)\n            print(f\"OCR extracted text saved to {output_json}\")\n        except Exception as e:\n            print(f\"Error saving OCR output: {e}\")\nexcept Exception as e:\n    print(f\"Error during PDF processing: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:26:32.890641Z","iopub.execute_input":"2025-02-05T10:26:32.890975Z","iopub.status.idle":"2025-02-05T10:27:07.284041Z","shell.execute_reply.started":"2025-02-05T10:26:32.890950Z","shell.execute_reply":"2025-02-05T10:27:07.282885Z"}},"outputs":[{"name":"stdout","text":"Processing page 1: ফুলের বিবাহ\n\nবঙ্কিমচন্দ্র চট্টোপাধ্যায়\n\n[লেখক-পরিচিতি : বঙ্কিমচন্দ্র চট্টোপাধ্যায় ২৬শে জুন ১৮৩৮ সালে পশ্চিমবঙ্গের চব্বিশ পরগনা জেলার\nঅন্তর্গত কীঠালপাড়া গ্রামে জন্মগ্রহণ করেন। তিনি ১৮৫৮ সালে কলকাতা ...\nProcessing page 2: ২০১৮\n\nফুলের বিবাহ ্\n\nভ্রমর ভোৌ করিয়া স্থলপদ্মের বৈঠকখানায় গিয়া রাজপুত্রের সঙ্গে ইয়ারকি করিতে বসিলেন। এদিকে\nমল্পিকার সন্ধ্যাঠাকুরাণী-দিদি আসিয়া তাহাকে কত বুঝাইতে লাগিল -_ বলিল, “দিদি, একবার ঘোম্টা...\nProcessing page 3: ৮ মাধ্যমিক বাংলা সাহিত্য\n\nনীতবর হইবে বলিয়া, সাজিয়া আসিয়া দুলিতে লাগিল। গরদের জোড় পরিয়া চাপা আসিয়া\nদীড়াইল _ উগ্ব গন্ধ ছুটিতে লাগিল । গন্ধরাজেরা বড় বাহার দিয়া, দলে দলে আসিয়া, গন্ধ বিলাইয়া\nদেশ...\nProcessing page 4: ২০১৮\n\nফুলের বিবাহ ৯\n\nকুসুম ঘেঁষে এসে, হেসে হেসে কাছে দীড়াইয়া আদর করিয়া জিজ্ঞাসা করিল, “কার বিয়ে, কাকা?\nআমি বলিলাম, “ফুলের বিয়ে ।”\n\n“ওঃ পোড়া কপাল, ফুলের? আমি বলি কি ! আমিও যে এই ফুলের বিয়ে দিয়ে...\nProcessing page 5: ১০ মাধ্যমিক বাংলা সাহিত্য\n\n২। এ গল্পে কন্যাকুল বলতে কাদের বোঝানো হয়েছে?\nক. ভোমর খ.. বৃক্ষ\n\nগ. গাছপালা ঘ. ফুল\nনিচের উদ্দীপকটি পড়ে ৩ সংখ্যক প্রশ্রের উত্তর দাও :\n\nজমিদার জনার্দন ঘোষ মেয়ের বিয়ে দিতে গ...\nProcessing page 6: ২০১৮\n\nসুভা\nরবীন্দ্রনাথ ঠাকুর\n\n[লেখক -পরিচিতি : রবীন্দ্রনাথ ঠাকুর ২৫শে বৈশাখ ১২৬৮ সালে পেই মে ১৮৬১ খিষ্টাব্দ) কলকাতার\nজোড়াসীকোর ঠাকুর পরিবারে জন্য্রহণ করেন। তার পিতা মহর্ষি দেবেন্দ্রনাথ ঠাকুর এবং পিতা...\nProcessing page 7: ১২ সুভা\n\nকথায় আমরা যে ভাব প্রকাশ করি সেটা আমাদিগকে অনেকটা নিজের চেষ্টায় গড়িয়া লইতে হয়,\nকতকটা তর্জমা করার মতো; সকল সময়ে ঠিক হয় না, ক্ষমতার অভাবে অনেক সময়ে ভুলও\nহয়। কিন্তু কালো চোখকে কিছু তর্জম...\nProcessing page 8: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৩\n\nসুভার যে গুটিকতক অন্তরঙ্গ বন্ধুর দল ছিল না তাহা নহে। গোয়ালের দুটি গাতী, তাহাদের নাম\nসর্বশী ও পাঙ্গুলি। সে নাম বালিকার মুখে তাহারা কখনো শুনে নাই, কিন্তু তাহার পদশব্দ ত...\nProcessing page 9: ১৪ সুভা\n\nসুভা তেতুলতলায় বসিয়া থাকিত এবং প্রতাপ অনতিদূরে ছিপ ফেলিয়া জলের দিকে চাহিয়া\nথাকিত। প্রতাপের জন্য একটি করিয়া পান বরাদ্দ ছিল, সুভা তাহা নিজে সাজিয়া আনিত। এবং\nবোধ করি অনেকক্ষণ বসিয়া বসিয়া...\nProcessing page 10: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৫\n\nবিদেশযাত্রার উদ্যোগ হইতে লাগিল । কুয়াশা-ঢাকা প্রভাতের মতো সুভার সমস্ত হৃদয় অশ্রুবাষ্পে\nএকেবারে ভরিয়া গেল। একটা অনির্দিষ্ট আশঙ্কা-বশে সে কিছুদিন হইতে ক্রমাগত নির্বাক...\nOCR extracted text saved to /kaggle/working/raw_extracted.json\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from pdf2image import convert_from_path\nimport pytesseract\nimport json\nimport os\n\n# Define paths\npdf_path = \"/kaggle/working/1120.pdf\"\noutput_json = \"/kaggle/working/raw_extracted.json\"\n\n# Ensure Poppler path is set correctly for your environment (for Kaggle, it's often '/usr/bin')\npoppler_path = \"/usr/bin/\"\n\n# Convert PDF to images (with explicit poppler_path)\ntry:\n    pages = convert_from_path(pdf_path, poppler_path=poppler_path)\n    extracted_text = {}\n    \n    # Process each page\n    for i, page in enumerate(pages):\n        text = pytesseract.image_to_string(page, lang=\"ben\")  # Bangla OCR\n        print(f\"Processing page {i+1}: {text[:200]}...\")  # Preview first 200 characters\n        extracted_text[f\"page_{i+1}\"] = text.strip()\n\n    if not extracted_text:\n        print(\"No text was extracted from OCR.\")\n    else:\n        # Save the extracted text to JSON\n        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n            json.dump(extracted_text, f, ensure_ascii=False, indent=4)\n        print(f\"OCR extracted text saved to {output_json}\")\nexcept Exception as e:\n    print(f\"Error during PDF processing: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:27:23.561138Z","iopub.execute_input":"2025-02-05T10:27:23.561591Z","iopub.status.idle":"2025-02-05T10:27:58.837503Z","shell.execute_reply.started":"2025-02-05T10:27:23.561537Z","shell.execute_reply":"2025-02-05T10:27:58.836235Z"}},"outputs":[{"name":"stdout","text":"Processing page 1: ফুলের বিবাহ\n\nবঙ্কিমচন্দ্র চট্টোপাধ্যায়\n\n[লেখক-পরিচিতি : বঙ্কিমচন্দ্র চট্টোপাধ্যায় ২৬শে জুন ১৮৩৮ সালে পশ্চিমবঙ্গের চব্বিশ পরগনা জেলার\nঅন্তর্গত কীঠালপাড়া গ্রামে জন্মগ্রহণ করেন। তিনি ১৮৫৮ সালে কলকাতা ...\nProcessing page 2: ২০১৮\n\nফুলের বিবাহ ্\n\nভ্রমর ভোৌ করিয়া স্থলপদ্মের বৈঠকখানায় গিয়া রাজপুত্রের সঙ্গে ইয়ারকি করিতে বসিলেন। এদিকে\nমল্পিকার সন্ধ্যাঠাকুরাণী-দিদি আসিয়া তাহাকে কত বুঝাইতে লাগিল -_ বলিল, “দিদি, একবার ঘোম্টা...\nProcessing page 3: ৮ মাধ্যমিক বাংলা সাহিত্য\n\nনীতবর হইবে বলিয়া, সাজিয়া আসিয়া দুলিতে লাগিল। গরদের জোড় পরিয়া চাপা আসিয়া\nদীড়াইল _ উগ্ব গন্ধ ছুটিতে লাগিল । গন্ধরাজেরা বড় বাহার দিয়া, দলে দলে আসিয়া, গন্ধ বিলাইয়া\nদেশ...\nProcessing page 4: ২০১৮\n\nফুলের বিবাহ ৯\n\nকুসুম ঘেঁষে এসে, হেসে হেসে কাছে দীড়াইয়া আদর করিয়া জিজ্ঞাসা করিল, “কার বিয়ে, কাকা?\nআমি বলিলাম, “ফুলের বিয়ে ।”\n\n“ওঃ পোড়া কপাল, ফুলের? আমি বলি কি ! আমিও যে এই ফুলের বিয়ে দিয়ে...\nProcessing page 5: ১০ মাধ্যমিক বাংলা সাহিত্য\n\n২। এ গল্পে কন্যাকুল বলতে কাদের বোঝানো হয়েছে?\nক. ভোমর খ.. বৃক্ষ\n\nগ. গাছপালা ঘ. ফুল\nনিচের উদ্দীপকটি পড়ে ৩ সংখ্যক প্রশ্রের উত্তর দাও :\n\nজমিদার জনার্দন ঘোষ মেয়ের বিয়ে দিতে গ...\nProcessing page 6: ২০১৮\n\nসুভা\nরবীন্দ্রনাথ ঠাকুর\n\n[লেখক -পরিচিতি : রবীন্দ্রনাথ ঠাকুর ২৫শে বৈশাখ ১২৬৮ সালে পেই মে ১৮৬১ খিষ্টাব্দ) কলকাতার\nজোড়াসীকোর ঠাকুর পরিবারে জন্য্রহণ করেন। তার পিতা মহর্ষি দেবেন্দ্রনাথ ঠাকুর এবং পিতা...\nProcessing page 7: ১২ সুভা\n\nকথায় আমরা যে ভাব প্রকাশ করি সেটা আমাদিগকে অনেকটা নিজের চেষ্টায় গড়িয়া লইতে হয়,\nকতকটা তর্জমা করার মতো; সকল সময়ে ঠিক হয় না, ক্ষমতার অভাবে অনেক সময়ে ভুলও\nহয়। কিন্তু কালো চোখকে কিছু তর্জম...\nProcessing page 8: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৩\n\nসুভার যে গুটিকতক অন্তরঙ্গ বন্ধুর দল ছিল না তাহা নহে। গোয়ালের দুটি গাতী, তাহাদের নাম\nসর্বশী ও পাঙ্গুলি। সে নাম বালিকার মুখে তাহারা কখনো শুনে নাই, কিন্তু তাহার পদশব্দ ত...\nProcessing page 9: ১৪ সুভা\n\nসুভা তেতুলতলায় বসিয়া থাকিত এবং প্রতাপ অনতিদূরে ছিপ ফেলিয়া জলের দিকে চাহিয়া\nথাকিত। প্রতাপের জন্য একটি করিয়া পান বরাদ্দ ছিল, সুভা তাহা নিজে সাজিয়া আনিত। এবং\nবোধ করি অনেকক্ষণ বসিয়া বসিয়া...\nProcessing page 10: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৫\n\nবিদেশযাত্রার উদ্যোগ হইতে লাগিল । কুয়াশা-ঢাকা প্রভাতের মতো সুভার সমস্ত হৃদয় অশ্রুবাষ্পে\nএকেবারে ভরিয়া গেল। একটা অনির্দিষ্ট আশঙ্কা-বশে সে কিছুদিন হইতে ক্রমাগত নির্বাক...\nOCR extracted text saved to /kaggle/working/raw_extracted.json\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"if not extracted_text:\n    print(\"No text was extracted from OCR.\")\nelse:\n    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n        json.dump(extracted_text, f, ensure_ascii=False, indent=4)\n    print(f\"OCR extracted text saved to {output_json}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:28:08.955278Z","iopub.execute_input":"2025-02-05T10:28:08.955701Z","iopub.status.idle":"2025-02-05T10:28:08.963904Z","shell.execute_reply.started":"2025-02-05T10:28:08.955668Z","shell.execute_reply":"2025-02-05T10:28:08.962479Z"}},"outputs":[{"name":"stdout","text":"OCR extracted text saved to /kaggle/working/raw_extracted.json\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from pdf2image import convert_from_path\nimport pytesseract\nimport json\nimport os\n\n# Define paths\npdf_path = \"/kaggle/working/1120.pdf\"\noutput_json = \"/kaggle/working/raw_extracted.json\"\n\n# Ensure Poppler path is set correctly for your environment (for Kaggle, it's often '/usr/bin')\npoppler_path = \"/usr/bin/\"\n\n# Initialize the extracted_text variable\nextracted_text = {}\n\n# Convert PDF to images (with explicit poppler_path)\ntry:\n    pages = convert_from_path(pdf_path, poppler_path=poppler_path)\n    \n    # Process each page\n    for i, page in enumerate(pages):\n        text = pytesseract.image_to_string(page, lang=\"ben\")  # Bangla OCR\n        print(f\"Processing page {i+1}: {text[:200]}...\")  # Preview first 200 characters\n        extracted_text[f\"page_{i+1}\"] = text.strip()\n\n    if not extracted_text:\n        print(\"No text was extracted from OCR.\")\n    else:\n        # Save the extracted text to JSON\n        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n            json.dump(extracted_text, f, ensure_ascii=False, indent=4)\n        print(f\"OCR extracted text saved to {output_json}\")\n\nexcept Exception as e:\n    print(f\"Error during PDF processing: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:28:12.930137Z","iopub.execute_input":"2025-02-05T10:28:12.930479Z","iopub.status.idle":"2025-02-05T10:28:48.776105Z","shell.execute_reply.started":"2025-02-05T10:28:12.930454Z","shell.execute_reply":"2025-02-05T10:28:48.774787Z"}},"outputs":[{"name":"stdout","text":"Processing page 1: ফুলের বিবাহ\n\nবঙ্কিমচন্দ্র চট্টোপাধ্যায়\n\n[লেখক-পরিচিতি : বঙ্কিমচন্দ্র চট্টোপাধ্যায় ২৬শে জুন ১৮৩৮ সালে পশ্চিমবঙ্গের চব্বিশ পরগনা জেলার\nঅন্তর্গত কীঠালপাড়া গ্রামে জন্মগ্রহণ করেন। তিনি ১৮৫৮ সালে কলকাতা ...\nProcessing page 2: ২০১৮\n\nফুলের বিবাহ ্\n\nভ্রমর ভোৌ করিয়া স্থলপদ্মের বৈঠকখানায় গিয়া রাজপুত্রের সঙ্গে ইয়ারকি করিতে বসিলেন। এদিকে\nমল্পিকার সন্ধ্যাঠাকুরাণী-দিদি আসিয়া তাহাকে কত বুঝাইতে লাগিল -_ বলিল, “দিদি, একবার ঘোম্টা...\nProcessing page 3: ৮ মাধ্যমিক বাংলা সাহিত্য\n\nনীতবর হইবে বলিয়া, সাজিয়া আসিয়া দুলিতে লাগিল। গরদের জোড় পরিয়া চাপা আসিয়া\nদীড়াইল _ উগ্ব গন্ধ ছুটিতে লাগিল । গন্ধরাজেরা বড় বাহার দিয়া, দলে দলে আসিয়া, গন্ধ বিলাইয়া\nদেশ...\nProcessing page 4: ২০১৮\n\nফুলের বিবাহ ৯\n\nকুসুম ঘেঁষে এসে, হেসে হেসে কাছে দীড়াইয়া আদর করিয়া জিজ্ঞাসা করিল, “কার বিয়ে, কাকা?\nআমি বলিলাম, “ফুলের বিয়ে ।”\n\n“ওঃ পোড়া কপাল, ফুলের? আমি বলি কি ! আমিও যে এই ফুলের বিয়ে দিয়ে...\nProcessing page 5: ১০ মাধ্যমিক বাংলা সাহিত্য\n\n২। এ গল্পে কন্যাকুল বলতে কাদের বোঝানো হয়েছে?\nক. ভোমর খ.. বৃক্ষ\n\nগ. গাছপালা ঘ. ফুল\nনিচের উদ্দীপকটি পড়ে ৩ সংখ্যক প্রশ্রের উত্তর দাও :\n\nজমিদার জনার্দন ঘোষ মেয়ের বিয়ে দিতে গ...\nProcessing page 6: ২০১৮\n\nসুভা\nরবীন্দ্রনাথ ঠাকুর\n\n[লেখক -পরিচিতি : রবীন্দ্রনাথ ঠাকুর ২৫শে বৈশাখ ১২৬৮ সালে পেই মে ১৮৬১ খিষ্টাব্দ) কলকাতার\nজোড়াসীকোর ঠাকুর পরিবারে জন্য্রহণ করেন। তার পিতা মহর্ষি দেবেন্দ্রনাথ ঠাকুর এবং পিতা...\nProcessing page 7: ১২ সুভা\n\nকথায় আমরা যে ভাব প্রকাশ করি সেটা আমাদিগকে অনেকটা নিজের চেষ্টায় গড়িয়া লইতে হয়,\nকতকটা তর্জমা করার মতো; সকল সময়ে ঠিক হয় না, ক্ষমতার অভাবে অনেক সময়ে ভুলও\nহয়। কিন্তু কালো চোখকে কিছু তর্জম...\nProcessing page 8: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৩\n\nসুভার যে গুটিকতক অন্তরঙ্গ বন্ধুর দল ছিল না তাহা নহে। গোয়ালের দুটি গাতী, তাহাদের নাম\nসর্বশী ও পাঙ্গুলি। সে নাম বালিকার মুখে তাহারা কখনো শুনে নাই, কিন্তু তাহার পদশব্দ ত...\nProcessing page 9: ১৪ সুভা\n\nসুভা তেতুলতলায় বসিয়া থাকিত এবং প্রতাপ অনতিদূরে ছিপ ফেলিয়া জলের দিকে চাহিয়া\nথাকিত। প্রতাপের জন্য একটি করিয়া পান বরাদ্দ ছিল, সুভা তাহা নিজে সাজিয়া আনিত। এবং\nবোধ করি অনেকক্ষণ বসিয়া বসিয়া...\nProcessing page 10: ২০১৮\n\nমাধ্যমিক বাংলা সাহিত্য ১৫\n\nবিদেশযাত্রার উদ্যোগ হইতে লাগিল । কুয়াশা-ঢাকা প্রভাতের মতো সুভার সমস্ত হৃদয় অশ্রুবাষ্পে\nএকেবারে ভরিয়া গেল। একটা অনির্দিষ্ট আশঙ্কা-বশে সে কিছুদিন হইতে ক্রমাগত নির্বাক...\nOCR extracted text saved to /kaggle/working/raw_extracted.json\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import re\nimport json\n\n# Sample input text (Replace this with your actual extracted text)\nwith open('/kaggle/working/raw_extracted.json', 'r', encoding='utf-8') as f:\n    text = f.read()\n\n# Define segmentation rules (example using regex patterns)\n# You can adapt this pattern based on the structure of your text\nheading_pattern = r'([A-Z][A-Za-z\\s]+(?:\\d+\\.?\\d*)*)'  # Match headings (example)\n\n# Split text by headings (or you can adapt based on page breaks or specific titles)\nsections = re.split(heading_pattern, text)\nsections = [s.strip() for s in sections if s.strip()]  # Clean up any empty sections\n\n# Create structured output\nsegmented_data = {}\nfor i, section in enumerate(sections):\n    section_id = f\"section_{i + 1:03}\"\n    segmented_data[section_id] = section\n\n# Save the segmented data to a JSON file\nwith open('segmented_data.json', 'w', encoding='utf-8') as json_file:\n    json.dump(segmented_data, json_file, ensure_ascii=False, indent=4)\n\nprint(f\"Segmentation complete. {len(segmented_data)} sections saved to segmented_data.json.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:29:06.235399Z","iopub.execute_input":"2025-02-05T10:29:06.235880Z","iopub.status.idle":"2025-02-05T10:29:06.246496Z","shell.execute_reply.started":"2025-02-05T10:29:06.235846Z","shell.execute_reply":"2025-02-05T10:29:06.245136Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Segmentation complete. 1 sections saved to segmented_data.json.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import json\nimport re\n\n# Load segmented data (assumed to be in JSON format from Task 3)\nwith open('segmented_data.json', 'r', encoding='utf-8') as f:\n    segmented_data = json.load(f)\n\n# Step 1: Ensure UTF-8 Encoding\n# This is typically handled when opening the file, but ensure it is converted if needed\ndef ensure_utf8_encoding(text):\n    return text.encode('utf-8', errors='ignore').decode('utf-8')\n\n# Step 2: Remove Unwanted Spaces (Trim trailing/leading whitespace & merge split lines)\ndef clean_spaces(text):\n    # Trim leading/trailing whitespace\n    text = text.strip()\n    # Merge lines that are split (example: splitting by newline and then joining back)\n    text = re.sub(r'\\n+', ' ', text)\n    return text\n\n# Step 3: Preserve Meaningful Paragraphs (using newline as delimiter for paragraphs)\ndef preserve_paragraphs(text):\n    # Assuming paragraphs are separated by two newlines\n    text = re.sub(r'\\n{2,}', '\\n\\n', text)  # Replace multiple newlines with single\n    return text\n\n# Step 4: Review Special Characters (Ensure Bangla punctuation remains intact)\ndef handle_special_characters(text):\n    # Remove invisible characters (e.g., zero-width spaces, control characters)\n    text = re.sub(r'[\\u200B\\u200C\\u200D\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064]+', '', text)\n    return text\n\n# Perform cleanup on each section\ncleaned_segments = {}\nfor section_id, section_text in segmented_data.items():\n    # Ensure UTF-8 Encoding (handled at the text level)\n    section_text = ensure_utf8_encoding(section_text)\n    \n    # Clean spaces, preserve paragraphs, and handle special characters\n    section_text = clean_spaces(section_text)\n    section_text = preserve_paragraphs(section_text)\n    section_text = handle_special_characters(section_text)\n    \n    cleaned_segments[section_id] = section_text\n\n# Step 5: Save the cleaned text to a new file\nwith open('cleaned_segments.json', 'w', encoding='utf-8') as json_file:\n    json.dump(cleaned_segments, json_file, ensure_ascii=False, indent=4)\n\nprint(f\"Text cleanup complete. Cleaned data saved to 'cleaned_segments.json'.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:29:12.415397Z","iopub.execute_input":"2025-02-05T10:29:12.415794Z","iopub.status.idle":"2025-02-05T10:29:12.429171Z","shell.execute_reply.started":"2025-02-05T10:29:12.415762Z","shell.execute_reply":"2025-02-05T10:29:12.427825Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Text cleanup complete. Cleaned data saved to 'cleaned_segments.json'.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import re\nimport json\n\n# Load the cleaned text from Task 4\nwith open('cleaned_segments.json', 'r', encoding='utf-8') as f:\n    cleaned_data = json.load(f)\n\n# Function to remove zero-width joiners and other invisible characters\ndef remove_zero_width(text):\n    # Replace common zero-width characters (ZWJ, ZWNJ, etc.)\n    return re.sub(r'[\\u200B\\u200C\\u200D\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064]+', '', text)\n\n# Function to fix common OCR misreads (this can be extended with specific mappings)\ndef fix_ocr_errors(text):\n    # Example replacements for common OCR errors (you can extend this list based on known errors)\n    corrections = {\n        'ক' : 'ক',   # Example of a common OCR fix\n        'ত' : 'থ',   # Add more OCR misread mappings as required\n    }\n    for incorrect, correct in corrections.items():\n        text = text.replace(incorrect, correct)\n    return text\n\n# List of known correct Bangla words (could be a bigger list or loaded from a file)\n# Here, we use a small sample list, which can be extended\nknown_words = {'বাংলা', 'বিদ্যা', 'বই', 'অধ্যায়', 'বিশ্ববিদ্যালয়'}\n\n# Function to check and correct unrecognized words using a predefined list\ndef spell_check(text):\n    words = text.split()  # Split text into words\n    corrected_words = []\n    unrecognized_words = []  # To track words not in the list\n    for word in words:\n        clean_word = re.sub(r'[^\\w\\s]', '', word)  # Remove punctuation\n        if clean_word not in known_words:  # Check if word is in the known words list\n            unrecognized_words.append(clean_word)\n            corrected_words.append(word)  # You can add custom corrections here\n        else:\n            corrected_words.append(word)\n    return ' '.join(corrected_words), unrecognized_words\n\n# Create a correction log\ncorrection_log = []\n\n# Process each section\nnormalized_data = {}\nfor section_id, section_text in cleaned_data.items():\n    # Step 1: Remove zero-width joiners\n    section_text = remove_zero_width(section_text)\n    \n    # Step 2: Fix common OCR errors\n    section_text = fix_ocr_errors(section_text)\n    \n    # Step 3: Perform basic spell checking using known words list\n    corrected_text, unrecognized_words = spell_check(section_text)\n    \n    # Update the correction log with any unrecognized words\n    correction_log.extend(unrecognized_words)\n    \n    normalized_data[section_id] = corrected_text\n\n# Save the normalized text to a file\nwith open('normalized_text.json', 'w', encoding='utf-8') as json_file:\n    json.dump(normalized_data, json_file, ensure_ascii=False, indent=4)\n\n# Save the correction log to a file\nwith open('correction_log.txt', 'w', encoding='utf-8') as log_file:\n    for word in correction_log:\n        log_file.write(f\"{word}\\n\")\n\nprint(\"Text normalization and spell checking complete.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:29:16.286203Z","iopub.execute_input":"2025-02-05T10:29:16.286617Z","iopub.status.idle":"2025-02-05T10:29:16.308768Z","shell.execute_reply.started":"2025-02-05T10:29:16.286547Z","shell.execute_reply":"2025-02-05T10:29:16.307484Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Text normalization and spell checking complete.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import json\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the normalized text from Task 5\nwith open('normalized_text.json', 'r', encoding='utf-8') as f:\n    normalized_data = json.load(f)\n\n# Helper function to calculate basic stats\ndef calculate_basic_stats(text):\n    words = text.split()\n    word_count = len(words)\n    unique_vocab = len(set(words))\n    sentences = re.split(r'[।!？]', text)  # Bangla sentence enders: । (। is common)\n    sentence_lengths = [len(s.split()) for s in sentences]\n    \n    # Frequency of punctuation marks\n    punctuation = re.findall(r'[^\\w\\s]', text)\n    punctuation_freq = dict(Counter(punctuation))\n    \n    return word_count, unique_vocab, sentence_lengths, punctuation_freq\n\n# Aggregate stats for all sections\nall_sentence_lengths = []\nall_punctuation_freq = Counter()\nword_counts = []\nunique_vocabs = []\n\nfor section_text in normalized_data.values():\n    word_count, unique_vocab, sentence_lengths, punctuation_freq = calculate_basic_stats(section_text)\n    word_counts.append(word_count)\n    unique_vocabs.append(unique_vocab)\n    all_sentence_lengths.extend(sentence_lengths)\n    all_punctuation_freq.update(punctuation_freq)\n\n# Plot word count and unique vocabulary size\nplt.figure(figsize=(12, 6))\n\n# Word count histogram\nplt.subplot(1, 2, 1)\nsns.histplot(word_counts, kde=True, color=\"skyblue\", bins=30)\nplt.title(\"Word Count Distribution\")\nplt.xlabel(\"Word Count\")\nplt.ylabel(\"Frequency\")\n\n# Unique vocabulary size histogram\nplt.subplot(1, 2, 2)\nsns.histplot(unique_vocabs, kde=True, color=\"orange\", bins=30)\nplt.title(\"Unique Vocabulary Size Distribution\")\nplt.xlabel(\"Unique Vocabulary Size\")\nplt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.show()\n\n# Plot sentence lengths distribution\nplt.figure(figsize=(8, 6))\nsns.histplot(all_sentence_lengths, kde=True, color=\"green\", bins=30)\nplt.title(\"Sentence Length Distribution\")\nplt.xlabel(\"Sentence Length (in words)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Display punctuation frequency (top 10 most common punctuation marks)\nprint(\"Top 10 Most Common Punctuation Marks:\")\nfor punct, count in all_punctuation_freq.most_common(10):\n    print(f\"{punct}: {count}\")\n\n# Frequency analysis of top N frequent words (excluding stopwords)\nstopwords = {'এটি', 'একটি', 'এর', 'এ', 'এই', 'সে', 'ও', 'আমি', 'তুমি'}  # Example stopwords list\nall_words = []\n\nfor section_text in normalized_data.values():\n    words = section_text.split()\n    filtered_words = [w for w in words if w not in stopwords]\n    all_words.extend(filtered_words)\n\nword_freq = Counter(all_words)\n\n# Display top 10 frequent words\nprint(\"Top 10 Most Frequent Words (Excluding Stopwords):\")\nfor word, count in word_freq.most_common(10):\n    print(f\"{word}: {count}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:29:21.318358Z","iopub.execute_input":"2025-02-05T10:29:21.318750Z","iopub.status.idle":"2025-02-05T10:29:23.090603Z","shell.execute_reply.started":"2025-02-05T10:29:21.318722Z","shell.execute_reply":"2025-02-05T10:29:23.089668Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Top 10 Most Common Punctuation Marks:\nা: 1895\nে: 1135\n্: 1066\nি: 1041\n়: 504\nু: 424\n\\: 383\n,: 250\nো: 235\n।: 225\nTop 10 Most Frequent Words (Excluding Stopwords):\nথাহার: 36\n।: 35\n-: 32\nকরিয়া: 24\nএবং: 22\nকিন্থু: 17\nযে: 17\nহইয়া: 13\nএকটা: 13\nনা,: 12\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import re\nimport json\n\n# Load the normalized text from Task 5\nwith open('normalized_text.json', 'r', encoding='utf-8') as f:\n    normalized_data = json.load(f)\n\n# Step 1: Define a simple Bangla-specific tokenizer\ndef bangla_tokenizer(text):\n    # Split the text based on spaces and punctuation, considering Bangla characters\n    tokens = re.findall(r'\\w+|[^\\w\\s]', text)  # Include words and punctuation marks\n    return tokens\n\n# Step 2: Handle special tokens (numbers, emoticons)\ndef handle_special_tokens(tokens):\n    # Example: Define custom rules for emoticons or numbers (optional)\n    tokens = [t if t.isdigit() else t for t in tokens]  # Keeping numbers as tokens\n    # Add other special token rules (e.g., emoticons, URLs) as needed\n    return tokens\n\n# Step 3: Sentence Splitting based on Bangla sentence markers (like \"।\", \"!\", \"?\")\ndef bangla_sentence_splitter(text):\n    # Split on Bangla sentence end markers like \"।\", \"!\", \"?\" and handle edge cases\n    sentences = re.split(r'([।!?])', text)  # Keep the end marker with the sentence\n    sentences = [s.strip() + mark for s, mark in zip(sentences[::2], sentences[1::2])]  # Merge markers back\n    return sentences\n\n# Step 4: Validate output and handle boundary cases (e.g., abbreviations)\ndef validate_output(sentences):\n    # Example: Handle boundary cases for abbreviations or decimal numbers\n    sentences = [s.replace(\"বিশ্ববিদ্যালয়.\", \"বিশ্ববিদ্যালয়।\") for s in sentences]  # Example for abbreviation\n    return sentences\n\n# Apply the tokenizer and sentence splitter on the extracted text\ntokenized_data = {}\nfor section, text in normalized_data.items():\n    tokens = bangla_tokenizer(text)\n    tokens = handle_special_tokens(tokens)\n    sentences = bangla_sentence_splitter(text)\n    validated_sentences = validate_output(sentences)\n    \n    # Store results\n    tokenized_data[section] = {\n        \"tokens\": tokens,\n        \"sentences\": validated_sentences\n    }\n\n# Save tokenized and sentence-split data\nwith open('tokenized_data.json', 'w', encoding='utf-8') as f:\n    json.dump(tokenized_data, f, ensure_ascii=False, indent=4)\n\n# Sample output (view first section's tokens and sentences)\nprint(\"Tokens of the first section:\", tokenized_data[\"section_001\"][\"tokens\"])\nprint(\"Sentences of the first section:\", tokenized_data[\"section_001\"][\"sentences\"])\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:39:27.204525Z","iopub.execute_input":"2025-02-05T10:39:27.205063Z","iopub.status.idle":"2025-02-05T10:39:27.244370Z","shell.execute_reply.started":"2025-02-05T10:39:27.205020Z","shell.execute_reply":"2025-02-05T10:39:27.242865Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Tokens of the first section: ['{', '\"', 'page_1', '\"', ':', '\"', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '\\\\', 'n', '\\\\', 'nবঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', 'চট', '্', 'ট', 'ো', 'প', 'া', 'ধ', '্', 'য', 'া', 'য', '়', '\\\\', 'n', '\\\\', 'n', '[', 'ল', 'ে', 'খক', '-', 'পর', 'ি', 'চ', 'ি', 'থ', 'ি', ':', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', 'চট', '্', 'ট', 'ো', 'প', 'া', 'ধ', '্', 'য', 'া', 'য', '়', '২৬শ', 'ে', 'জ', 'ু', 'ন', '১৮৩৮', 'স', 'া', 'ল', 'ে', 'পশ', '্', 'চ', 'ি', 'মবঙ', '্', 'গ', 'ে', 'র', 'চব', '্', 'ব', 'ি', 'শ', 'পরগন', 'া', 'জ', 'ে', 'ল', 'া', 'র', '\\\\', 'nঅন', '্', 'থর', '্', 'গথ', 'ক', 'ী', 'ঠ', 'া', 'লপ', 'া', 'ড', '়', 'া', 'গ', '্', 'র', 'া', 'ম', 'ে', 'জন', '্', 'মগ', '্', 'রহণ', 'কর', 'ে', 'ন', '।', 'থ', 'ি', 'ন', 'ি', '১৮৫৮', 'স', 'া', 'ল', 'ে', 'কলক', 'া', 'থ', 'া', 'ব', 'ি', 'শ', '্', 'বব', 'ি', 'দ', '্', 'য', 'া', 'লয', '়', 'থ', 'ে', 'ক', 'ে', 'ব', 'ি', '.', 'এ', '.', 'পর', 'ী', 'ক', '্', 'ষ', 'া', 'য', '়', '\\\\', 'nউথ', '্', 'থ', 'ী', 'র', '্', 'ণ', 'হন', 'এব', 'ং', 'স', 'ে', 'বছরই', 'ড', 'ে', 'প', 'ু', 'ট', 'ি', 'ম', '্', 'য', 'া', 'জ', 'ি', 'স', '্', 'ট', '্', 'র', 'ে', 'ট', 'ও', 'ড', 'ে', 'প', 'ু', 'ট', 'ি', 'ক', 'া', 'ল', 'ে', 'ক', '্', 'টর', 'পদ', 'ে', 'চ', 'া', 'কর', 'ি', 'থ', 'ে', 'ন', 'ি', 'য', 'ু', 'ক', '্', 'থ', 'হন', '।', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', '\\\\', 'nথ', 'ে', 'থ', '্', 'র', 'ি', 'শ', 'বছর', 'একই', 'পদ', 'ে', 'চ', 'া', 'কর', 'ি', 'কর', 'ে', '১৮৯১', 'স', 'া', 'ল', 'ে', 'অবসর', 'গ', '্', 'রহণ', 'কর', 'ে', 'ন', '।', 'থ', 'ি', 'ন', 'ি', 'প', 'া', 'ঠ', '্', 'য', 'া', 'বস', '্', 'থ', 'া', 'য', '়', 'ই', 'স', 'া', 'হ', 'ি', 'থ', '্', 'যচর', '্', 'চ', 'া', '\\\\', 'nশ', 'ু', 'র', 'ু', 'কর', 'ে', 'ন', '।', 'থ', 'া', 'র', 'অস', 'া', 'ম', 'া', 'ন', '্', 'য', 'ক', 'ৃ', 'থ', 'ি', 'থ', '্', 'ব', 'প', '্', 'রক', 'া', 'শ', 'প', 'ে', 'য', '়', 'ে', 'ছ', 'ে', 'প', 'া', 'শ', '্', 'চ', 'া', 'থ', '্', 'য', 'ভ', 'া', 'ব', 'া', 'দর', '্', 'শ', 'ে', 'ব', 'া', 'ং', 'ল', 'া', 'উপন', '্', 'য', 'া', 'স', 'রচন', 'া', 'র', 'পথ', 'ি', 'ক', 'ৃ', 'ৎ', 'হ', 'ি', 'স', 'ে', 'ব', 'ে', '।', '\\\\', 'n১৮৬৫', 'স', 'া', 'ল', 'ে', 'প', '্', 'রক', 'া', 'শ', 'ি', 'থ', 'থ', 'া', 'র', 'প', '্', 'রথম', 'ব', 'া', 'ং', 'ল', 'া', 'উপন', '্', 'য', 'া', 'স', 'দ', 'ু', 'র', '্', 'গ', 'ে', 'শনন', '্', 'দ', 'ি', 'ন', 'ী', 'ব', 'া', 'ং', 'ল', 'া', 'কথ', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ে', 'এক', 'নবদ', 'ি', 'গন', '্', 'থ', 'উন', '্', 'ম', 'ো', 'চন', '\\\\', 'nকর', 'ে', '।', 'থ', 'া', 'র', 'অন', '্', 'য', 'া', 'ন', '্', 'য', 'উপন', '্', 'য', 'া', 'স', 'হল', 'ো', ':', 'কপ', 'া', 'লক', 'ু', 'গ', 'ু', 'ল', 'া', ',', 'ম', 'ৃ', 'ণ', 'া', 'ল', 'ি', 'ন', 'ী', ',', 'ব', 'ি', 'ষব', 'ৃ', 'ক', '্', 'ষ', ',', 'ইন', '্', 'দ', 'ি', 'র', 'া', ',', 'ম', 'ু', 'গল', 'া', 'ঙ', '্', 'গ', 'ু', 'র', 'ী', 'য', '়', ',', 'র', 'া', 'ধ', 'া', 'র', 'া', 'ন', 'ী', ',', 'চন', '্', 'দ', '্', 'রশ', 'ে', 'খর', ',', '\\\\', 'nরজন', 'ী', ',', 'ক', 'ৃ', 'ষ', '্', 'ক', 'া', 'ন', '্', 'থ', 'ে', 'র', 'উইল', ',', 'র', 'া', 'জস', 'ি', 'ং', 'হ', ',', 'আনন', '্', 'দমঠ', ',', 'দ', 'ে', 'ব', 'ী', 'চ', 'ৌ', 'ধ', 'ু', 'র', 'া', 'ন', 'ী', 'ও', 'স', 'ী', 'থ', 'া', 'র', 'া', 'ম', '।', 'প', '্', 'রবন', '্', 'ধ', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ে', 'ও', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', '\\\\', 'nক', 'ৃ', 'থ', 'ি', 'থ', '্', 'ব', 'দ', 'ে', 'খ', 'ি', 'য', '়', 'ে', 'ছ', 'ে', 'ন', '।', 'কমল', 'া', 'ক', 'া', 'ন', '্', 'থ', 'ে', 'র', 'দণ', '্', 'থর', ',', 'ল', 'ো', 'করহস', '্', 'য', ',', 'ক', 'ৃ', 'ষ', '্', 'ণ', 'চর', 'ি', 'থ', '্', 'র', 'ইথ', '্', 'য', 'া', 'দ', 'ি', 'থ', 'া', 'র', 'উল', '্', 'ল', 'ে', 'খয', 'ো', 'গ', '্', 'য', 'প', '্', 'রবন', '্', 'ধগরন', '্', 'থ', '।', '\\\\', 'nবঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', 'চট', '্', 'ট', 'ো', 'প', 'া', 'ধ', '্', 'য', 'া', 'য', '়', '১৮৯৪', 'স', 'া', 'ল', 'ে', 'র', '৮ই', 'এপ', '্', 'র', 'ি', 'ল', 'ম', 'ৃ', 'থ', '্', 'য', 'ু', 'বরণ', 'কর', 'ে', 'ন', '|', ']', '\\\\', 'n', '\\\\', 'nব', 'ৈ', 'শ', 'া', 'খ', 'ম', 'া', 'স', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'র', 'ম', 'া', 'স', '।', 'আম', 'ি', '১ল', 'া', 'ব', 'ৈ', 'শ', 'া', 'খ', 'ে', 'নস', 'ী', 'ব', 'া', 'ব', 'ু', 'র', 'ফ', 'ু', 'লব', 'া', 'গ', 'া', 'ন', 'ে', 'বস', 'ি', 'য', '়', 'া', 'একট', 'ি', 'ব', 'ি', 'ব', 'া', 'হ', '\\\\', 'nদ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', '।', 'ভব', 'ি', 'ষ', '্', 'যৎ', 'বরকন', '্', 'য', 'া', 'দ', 'ি', 'গ', 'ে', 'র', 'শ', 'ি', 'ক', '্', 'ষ', 'া', 'র', '্', 'থ', 'ল', 'ি', 'খ', 'ি', 'য', '়', 'া', 'র', 'া', 'খ', 'ি', 'থ', 'ে', 'ছ', 'ি', '।', '\\\\', 'n', '\\\\', 'nমল', '্', 'ল', 'ি', 'ক', 'া', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '।', 'ব', 'ৈ', 'ক', 'া', 'ল', '-', 'শ', 'ৈ', 'শব', 'অবস', 'া', 'নপ', '্', 'র', 'া', 'য', '়', ',', 'কল', 'ি', 'ক', 'া', '-', 'কন', '্', 'য', 'া', 'ব', 'ি', 'ব', 'া', 'হয', 'ো', 'গ', '্', 'য', 'া', 'হইয', '়', 'া', 'আস', 'ি', 'ল', '।', 'কন', '্', 'য', 'া', 'র', '\\\\', 'nপ', 'ি', 'থ', 'া', 'বড', '়', 'ল', 'ো', 'ক', 'নহ', 'ে', ',', 'ক', '্', 'ষ', 'ু', 'দ', '্', 'র', 'ব', 'ৃ', 'ক', '্', 'ষ', ',', 'থ', 'া', 'হ', 'া', 'থ', 'ে', 'আব', 'া', 'র', 'অন', 'ে', 'কগ', 'ু', 'ল', 'ি', 'কন', '্', 'য', 'া', 'ভ', 'া', 'রপ', '্', 'রস', '্', 'থ', '।', 'সম', '্', 'বন', '্', 'ধ', 'ে', 'র', 'অন', 'ে', 'ক', 'কথ', 'া', '\\\\', 'nহইথ', 'ে', 'ছ', 'ি', 'ল', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ক', 'ো', 'নট', 'া', 'স', '্', 'থ', 'ি', 'র', 'হয', '়', 'ন', 'া', 'ই', '।', 'উদ', '্', 'য', 'া', 'ন', 'ে', 'র', 'র', 'া', 'জ', 'া', 'স', '্', 'থলপদ', '্', 'ম', 'ন', 'ি', 'র', '্', 'দ', 'ো', 'ষ', 'প', 'া', 'থ', '্', 'র', 'বট', 'ে', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ঘর', 'বড', '়', 'উচ', 'ু', ',', '\\\\', 'nস', '্', 'থলপদ', '্', 'ম', 'অথ', 'দ', 'ূ', 'র', 'ন', 'া', 'ম', 'ি', 'ল', 'ন', 'া', '।', 'জব', 'া', 'এ', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'অসম', '্', 'মথ', 'ছ', 'ি', 'ল', 'ন', 'া', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'জব', 'া', 'বড', '়', 'র', 'া', 'গ', 'ী', ',', 'কন', '্', 'য', 'া', 'ক', '্', 'থ', 'া', '\\\\', 'nপ', 'ি', 'ছ', 'া', 'ইল', 'ে', 'ন', '।', 'গন', '্', 'ধর', 'া', 'জ', 'প', 'া', 'থ', '্', 'র', 'ভ', 'া', 'ল', 'ো', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'বড', '়', 'দ', 'ে', 'ম', 'া', 'গ', ',', 'প', '্', 'র', 'া', 'য', '়', 'থ', 'া', 'হ', 'া', 'র', 'বর', 'প', 'া', 'ওয', '়', 'া', 'য', 'া', 'য', '়', 'ন', 'া', '।', 'এইর', 'ূ', 'প', '\\\\', 'nঅব', '্', 'যবস', '্', 'থ', 'া', 'র', 'সময', '়', 'ে', 'ভ', '্', 'রমরর', 'া', 'জ', 'ঘটক', 'হইয', '়', 'া', 'মন', '্', 'র', 'ি', 'ক', 'া', '-', 'ব', 'ৃ', 'ক', '্', 'ষসদন', 'ে', 'উপস', '্', 'থ', 'ি', 'থ', 'হইল', 'ে', 'ন', '।', 'থ', 'ি', 'ন', 'ি', 'আস', 'ি', 'য', '়', 'া', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '\\\\', 'n', '€', 'গ', 'ু', 'ণ', '্', '!', 'গ', 'ু', 'ণ', '্', '!', 'গ', 'ু', 'ণ', '্', 'ম', 'ে', 'য', '়', 'ে', 'আছ', 'ে', '?', '\\\\', 'n', '\\\\', 'nমন', '্', 'ল', 'ি', 'ক', 'া', 'ব', 'ৃ', 'ক', '্', 'ষ', 'প', 'া', 'থ', 'া', 'ন', 'া', 'ড', '়', 'ি', 'য', '়', 'া', 'স', 'া', 'য', '়', 'দ', 'ি', 'ল', 'ে', 'ন', ',', '“', 'আছ', 'ে', '!', 'ভ', '্', 'রমর', 'পথ', '্', 'র', 'া', 'সন', 'গ', '্', 'রহণ', 'কর', 'ি', 'য', '়', 'া', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '“', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '!', '\\\\', 'nগ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', 'া', 'গ', 'ু', 'ণ', '্', '!', 'ম', 'ে', 'য', '়', 'ে', 'দ', 'ে', 'খ', 'ি', 'ব', '|', '”', '\\\\', 'n', '\\\\', 'nব', 'ৃ', 'ক', '্', 'ষ', ',', 'শ', 'া', 'খ', 'া', 'নথ', 'কর', 'ি', 'য', '়', 'া', 'ম', 'ু', 'দ', 'ি', 'থনয', '়', 'ন', 'া', 'অবগ', 'ু', 'ষ', '্', 'ঠনবথ', 'ী', 'কন', '্', 'য', 'া', 'দ', 'ে', 'খ', 'া', 'ইল', 'ে', 'ন', '।', '\\\\', 'nভ', '্', 'রমর', 'একব', 'া', 'র', 'ব', 'ৃ', 'ক', '্', 'ষক', 'ে', 'প', '্', 'রদক', '্', 'ষ', 'ি', 'ণ', 'কর', 'ি', 'য', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '“', 'গ', 'ু', 'ণ', 'ৃ', '!', 'গ', 'ু', 'ণ', 'ৃ', '!', 'গ', 'ু', 'ণ', 'ৃ', '!', 'গ', 'ু', 'ণ', 'দ', 'ে', 'খ', 'ি', 'থ', 'ে', 'চ', 'া', 'ই', '।', 'ঘ', 'ো', 'মট', 'া', 'খ', 'ো', 'ল', '।', '”', '\\\\', 'n', '\\\\', 'nলজ', '্', 'জ', 'া', 'শ', 'ী', 'ল', 'া', 'কন', '্', 'য', 'া', 'ক', 'ি', 'ছ', 'ু', 'থ', 'ে', 'ই', 'ঘ', 'ো', 'ম', '্', 'ট', 'া', 'খ', 'ু', 'ল', 'ে', 'ন', 'া', '।', 'ব', 'ৃ', 'ক', '্', 'ষ', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '“', 'আম', 'া', 'র', 'ম', 'ে', 'য', '়', 'ে', 'গ', 'ু', 'ল', 'ি', 'বড', '়', 'ল', 'া', 'জ', 'ু', 'ক', '।', 'থ', 'ু', 'ম', 'ি', '\\\\', 'nএকট', 'ু', 'অপ', 'ে', 'ক', '্', 'ষ', 'া', 'কর', ',', 'আম', 'ি', 'ম', 'ু', 'খ', 'দ', 'ে', 'খ', 'া', 'ইথ', 'ে', 'ছ', 'ি', '।', '”', '\\\\', 'n', '\\\\', 'n২০১৮', '\"', ',', '\"', 'page_2', '\"', ':', '\"', '২০১৮', '\\\\', 'n', '\\\\', 'nফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '্', '\\\\', 'n', '\\\\', 'nভ', '্', 'রমর', 'ভ', 'ো', 'ৌ', 'কর', 'ি', 'য', '়', 'া', 'স', '্', 'থলপদ', '্', 'ম', 'ে', 'র', 'ব', 'ৈ', 'ঠকখ', 'া', 'ন', 'া', 'য', '়', 'গ', 'ি', 'য', '়', 'া', 'র', 'া', 'জপ', 'ু', 'থ', '্', 'র', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'ইয', '়', 'া', 'রক', 'ি', 'কর', 'ি', 'থ', 'ে', 'বস', 'ি', 'ল', 'ে', 'ন', '।', 'এদ', 'ি', 'ক', 'ে', '\\\\', 'nমল', '্', 'প', 'ি', 'ক', 'া', 'র', 'সন', '্', 'ধ', '্', 'য', 'া', 'ঠ', 'া', 'ক', 'ু', 'র', 'া', 'ণ', 'ী', '-', 'দ', 'ি', 'দ', 'ি', 'আস', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'কথ', 'ব', 'ু', 'ঝ', 'া', 'ইথ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '-', '_', 'বল', 'ি', 'ল', ',', '“', 'দ', 'ি', 'দ', 'ি', ',', 'একব', 'া', 'র', 'ঘ', 'ো', 'ম', '্', 'ট', 'া', '\\\\', 'nখ', 'ো', 'ল', '_', 'নইল', 'ে', ',', 'বর', 'আস', 'ি', 'ব', 'ে', 'ন', 'া', '_', 'লক', '্', 'ষ', '্', 'ম', 'ী', 'আম', 'া', 'র', ',', 'চ', 'া', 'দ', 'আম', 'া', 'র', ',', 'স', 'ো', 'ন', 'া', 'আম', 'া', 'র', ',', 'ইথ', '্', 'য', 'া', 'দ', 'ি', '।', \"'\", 'কল', 'ি', 'ক', 'া', 'কথব', 'া', 'র', '\\\\', 'nঘ', 'া', 'ড', '়', 'ন', 'া', 'ড', '়', 'ি', 'ল', ',', 'কথব', 'া', 'র', 'র', 'া', 'গ', 'কর', 'ি', 'য', '়', 'া', 'ম', 'ু', 'খ', 'ঘ', 'ু', 'র', 'া', 'ইল', ',', 'কথব', 'া', 'র', 'বল', 'ি', 'ল', ',', \"'\", 'ঠ', 'া', 'ন', '্', 'দ', 'ি', 'দ', 'ি', ',', 'থ', 'ু', 'ই', 'য', 'া', '!', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'শ', 'ে', 'ষ', 'ে', '\\\\', 'nসন', '্', 'ধ', '্', 'য', 'া', 'র', 'ঘ', '্', 'ল', 'ি', 'ঞ', '্', 'ধ', 'স', '্', 'বভ', 'া', 'ব', 'ে', 'ম', 'ু', 'গ', '্', 'ধ', 'হইয', '়', 'া', 'ম', 'ু', 'খ', 'খ', 'ু', 'ল', 'ি', 'ল', '।', 'থখন', 'ঘটক', 'মহ', 'া', 'শয', '়', 'ভ', 'ৌ', 'কর', 'ি', 'য', '়', 'া', 'র', 'া', 'জব', 'া', 'ড', '়', 'ী', 'হইথ', 'ে', 'ন', 'া', 'ম', 'ি', 'য', '়', 'া', '\\\\', 'nআস', 'ি', 'য', '়', 'া', 'ঘটক', 'া', 'ল', 'ী', 'থ', 'ে', 'মন', 'দ', 'ি', 'ল', 'ে', 'ন', '।', 'কন', '্', 'য', 'া', 'র', 'পর', 'ি', 'মল', 'ে', 'ম', 'ু', 'গ', '্', 'ধ', 'হইয', '়', 'া', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '“', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', 'গ', 'ু', 'ণ', 'া', 'গ', 'ু', 'ণ', '্', '!', '\\\\', 'nকন', '্', 'য', 'া', 'গ', 'ু', 'ণবথ', 'ী', 'বট', 'ে', '।', 'ঘর', 'ে', 'মধ', 'ু', 'কথ', '?', '\\\\', 'n', '\\\\', 'nকন', '্', 'য', 'া', 'কর', '্', 'থ', 'া', 'ব', 'ৃ', 'ক', '্', 'ষ', 'বল', 'ি', 'ল', 'ে', 'ন', ',', '“', 'ফর', '্', 'দ', 'দ', 'ি', 'ব', 'ে', 'ন', ',', 'কড', '়', 'া', 'য', '়', 'গণ', '্', 'ড', 'া', 'য', '়', 'ব', 'ু', 'ঝ', 'া', 'ইয', '়', 'া', 'দ', 'ি', 'ব', 'ে', '।', \"'\", 'ভ', '্', 'রমর', 'বল', 'ি', 'ল', 'ে', 'ন', ',', \"'\", 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', ',', '\\\\', 'nআপন', 'া', 'র', 'অন', 'ে', 'ক', 'গ', 'ু', 'ণ', '-', 'ঘটক', 'া', 'ল', 'ী', 'ট', 'া', '?', '\\\\', 'n', '\\\\', 'nকন', '্', 'য', 'া', 'কর', '্', 'থ', 'া', 'শ', 'া', 'খ', 'া', 'ন', 'া', 'ড', '়', 'ি', 'য', '়', 'া', 'স', 'া', 'য', '়', 'দ', 'ি', 'ল', ',', '“', 'থ', 'া', 'ও', 'হব', 'ে', '।', '”', '\\\\', 'n', '\\\\', 'nভ', '্', 'রমর', '-', '“', 'বল', 'ি', 'ঘটক', 'া', 'ল', 'ী', 'র', 'ক', 'ি', 'ছ', 'ু', 'আগ', 'া', 'ম', 'দ', 'ি', 'ল', 'ে', 'হয', '়', 'ন', 'া', '?', 'নগদ', 'দ', 'া', 'ন', 'বড', '়', 'গ', 'ু', 'ণ', '-', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', 'গ', 'ু', 'ণ', '্', '।', '*', '\\\\', 'n', '\\\\', 'n', '্', 'ষ', 'ু', '্', 'ব', 'ৃ', 'ক', '্', 'ষট', 'ি', 'থখন', 'ব', 'ি', 'রক', '্', 'থ', 'হইয', '়', 'া', ',', 'সকল', 'শ', 'া', 'খ', 'া', 'ন', 'া', 'ড', '়', 'ি', 'য', '়', 'া', 'বল', 'ি', 'ল', ',', '“', 'আগ', 'ে', 'বর', 'ে', 'র', 'কথ', 'া', 'বল', '-', 'বর', 'ক', 'ে', '?', \"'\", '\\\\', 'nভ', '্', 'রমর', '-', '“', 'বর', 'অথ', 'ি', 'স', 'ু', 'প', 'া', 'থ', '্', 'র', '।', '_', 'থ', 'া', 'র', 'অন', 'ে', 'ক', 'গ', 'ু', 'ণ', '-', 'ণ', 'ৃ', '-', 'ণ', '্', '।', '”', '\\\\', 'n', '\\\\', 'nএসকল', 'কথ', 'ো', 'পকথন', 'মন', 'ু', 'ষ', '্', 'য', 'ে', 'শ', 'ু', 'ন', 'ি', 'থ', 'ে', 'প', 'া', 'য', '়', 'ন', 'া', ',', 'আম', 'ি', 'ক', 'ে', 'বল', 'দ', 'ি', 'ব', '্', 'য', 'কর', '্', 'ণ', 'প', 'া', 'ইয', '়', 'া', 'ই', 'এ', 'সকল', 'শ', 'ু', 'ন', 'ি', 'থ', 'ে', 'ছ', 'ি', 'ল', 'া', 'ম', '।', '\\\\', 'nআম', 'ি', 'শ', 'ু', 'ন', 'ি', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', 'া', 'ম', ',', 'ক', 'ু', 'ল', 'া', 'চ', 'া', 'র', '্', 'য', 'মহ', 'া', 'শয', '়', ',', 'প', 'া', 'খ', 'া', 'ঝ', 'া', 'ড', '়', 'ি', 'য', '়', 'া', ',', 'ছয', '়', 'প', 'া', 'ছড', '়', 'া', 'ইয', '়', 'া', 'গ', 'ো', 'ল', 'া', 'ব', 'ে', 'র', 'মহ', 'ি', 'ম', 'া', 'ক', 'ী', 'র', '্', 'থন', '\\\\', 'nকর', 'ি', 'থ', 'ে', 'ছ', 'ি', 'ল', 'ে', 'ন', '।', 'বল', 'ি', 'থ', 'ে', 'ছ', 'ি', 'ল', 'ে', 'ন', 'য', 'ে', ',', 'গ', 'ো', 'ল', 'া', 'ব', 'ব', 'ং', 'শ', 'বড', '়', 'ক', 'ু', 'ল', 'ী', 'ন', ';', 'ক', 'ে', 'ন', 'ন', 'া', ',', 'ইহ', 'া', 'র', 'া', '“', 'ফ', 'ু', 'ল', 'ে', \"'\", 'ম', 'ে', 'ল', '।', 'যদ', 'ি', '\\\\', 'nবল', ',', 'সকল', 'ফ', 'ু', 'লই', 'ফ', 'ু', 'ল', 'ে', ',', 'থথ', 'া', 'প', 'ি', 'গ', 'ো', 'ল', 'া', 'ব', 'ে', 'র', 'গ', 'ৌ', 'রব', 'অধ', 'ি', 'ক', ';', 'ক', 'ে', 'ন', 'ন', 'া', ',', 'ইহ', 'া', 'র', 'া', 'স', 'া', 'ক', '্', 'ষ', 'া', 'ৎ', 'ব', 'া', 'ঞ', '্', 'চ', 'া', 'ম', 'া', 'ল', 'ী', 'র', 'সন', '্', 'থ', 'া', 'ন', ';', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'স', '্', 'বহস', '্', 'থর', 'ো', 'প', 'ি', 'থ', '|', 'যদ', 'ি', 'বল', ',', 'এ', 'ফ', 'ু', 'ল', 'ে', 'ক', 'া', 'ট', 'া', 'আছ', 'ে', ',', 'ক', 'ো', 'ন', '্', 'ক', 'ু', 'ল', 'ে', 'ব', 'া', 'ক', 'ো', 'ন', '্', 'ফ', 'ু', 'ল', 'ে', 'ন', 'া', 'ই', '?', '\\\\', 'n', '\\\\', 'nয', 'া', 'হ', 'া', 'হউক', ',', 'ঘটকর', 'া', 'জ', 'ক', 'ো', 'নর', 'ু', 'প', 'ে', 'সম', '্', 'বন', '্', 'ধ', 'স', '্', 'থ', 'ি', 'র', 'কর', 'ি', 'য', '়', 'া', ',', 'ব', 'ৌ', 'কর', 'ি', 'য', '়', 'া', 'উড', '়', 'ি', 'য', '়', 'া', 'গ', 'ি', 'য', '়', 'া', ',', 'গ', 'ো', 'ল', 'া', 'ব', 'ব', 'া', 'ব', 'ু', 'র', '\\\\', 'nব', 'া', 'ড', '়', 'ি', 'থ', 'ে', 'খবর', 'দ', 'ি', 'ল', 'ে', 'ন', '।', 'গ', 'ো', 'ল', 'া', 'ব', ',', 'থখন', 'ব', 'া', 'থ', 'া', 'স', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'ন', 'া', 'চ', 'ি', 'য', '়', 'া', 'ন', 'া', 'চ', 'ি', 'য', '়', 'া', ',', 'হ', 'া', 'স', 'ি', 'য', '়', 'া', 'হ', 'া', 'স', 'ি', 'য', '়', 'া', ',', 'ল', 'া', 'ফ', 'া', 'ইয', '়', 'া', '\\\\', 'nল', 'া', 'ফ', 'া', 'ইয', '়', 'া', 'খ', 'ে', 'ল', 'া', 'কর', 'ি', 'থ', 'ে', 'ছ', 'ি', 'ল', ',', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'র', 'ন', 'া', 'ম', 'শ', 'ু', 'ন', 'ি', 'য', '়', 'া', 'অহ', 'ো', 'দ', 'ি', 'থ', 'হইয', '়', 'া', 'কন', '্', 'য', 'া', 'র', 'বয', '়', 'স', 'জ', 'ি', 'জ', '্', 'ঞ', 'া', 'স', 'া', 'কর', 'ি', 'ল', '।', '\\\\', 'nভ', '্', 'রমর', 'বল', 'ি', 'ল', ',', '“', 'আজ', 'ি', 'ক', 'া', 'ল', 'ি', 'ফ', 'ু', 'ট', 'ি', 'ব', 'ে', '।', '”', '\\\\', 'n', '\\\\', 'nগ', 'ো', 'ধ', 'ু', 'ল', 'ি', 'লগ', '্', 'ন', 'উপস', '্', 'থ', 'ি', 'থ', ',', 'গ', 'ো', 'ল', 'া', 'ব', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'য', 'া', 'থ', '্', 'র', 'া', 'র', 'উদ', '্', 'য', 'ো', 'গ', 'কর', 'ি', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', 'ে', 'ন', '।', 'উচ', '্', 'চ', 'ি', 'ঙ', '্', 'গড', '়', 'া', 'নহবৎ', 'ব', 'া', 'জ', 'া', 'ইথ', 'ে', '\\\\', 'nন', 'া', '।', 'খদ', '্', 'য', 'ো', 'থ', 'ে', 'র', 'া', 'ঝ', 'া', 'ড', '়', 'ধর', 'ি', 'ল', ';', 'আক', 'া', 'শ', 'ে', 'থ', 'া', 'র', 'া', 'ব', 'া', 'জ', 'ি', 'হইথ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'ক', 'ো', 'ক', 'ি', 'ল', 'আগ', 'ে', 'আগ', 'ে', 'ফ', 'ু', 'কর', 'া', 'ইথ', 'ে', '\\\\', 'nল', 'া', 'গ', 'ি', 'ল', '।', 'অন', 'ে', 'ক', 'বরয', 'া', 'থ', '্', 'র', 'ী', 'চল', 'ি', 'ল', ';', 'স', '্', 'বয', '়', 'ং', 'র', 'া', 'জক', 'ু', 'ম', 'া', 'র', 'স', '্', 'থলপদ', '্', 'ম', 'দ', 'ি', 'ব', 'া', 'বস', 'া', 'ন', 'ে', 'অস', 'ু', 'স', '্', 'থকর', 'বল', 'ি', 'য', '়', 'া', 'আস', 'ি', 'থ', 'ে', '\\\\', 'nপ', 'া', 'র', 'ি', 'ল', 'ে', 'ন', 'ন', 'া', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'জব', 'া', 'গ', 'ো', 'ষ', '্', 'ঠ', 'ী', '-', 'শ', '্', 'ব', 'ে', 'থ', 'জব', 'া', ',', 'রক', '্', 'থ', 'জব', 'া', ',', 'জরদ', 'জব', 'া', 'প', '্', 'রভ', 'ৃ', 'থ', 'ি', 'সব', 'ং', 'শ', 'ে', 'আস', 'ি', 'য', '়', 'া', 'ছ', 'ি', 'ল', '।', '\\\\', 'nকরব', 'ী', 'দ', 'ে', 'র', 'দল', ',', 'স', 'ে', 'ক', 'ে', 'ল', 'ে', 'র', 'া', 'জ', 'া', 'দ', 'ি', 'গ', 'ে', 'র', 'মথ', 'বড', '়', 'উচ', '্', 'চ', 'ড', 'া', 'ল', 'ে', 'চড', '়', 'ি', 'য', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'উপস', '্', 'থ', 'ি', 'থ', 'হইল', '।', 'স', 'ে', 'ঁ', 'উথ', 'ি', '\"', ',', '\"', 'page_3', '\"', ':', '\"', '৮', 'ম', 'া', 'ধ', '্', 'যম', 'ি', 'ক', 'ব', 'া', 'ং', 'ল', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', '\\\\', 'n', '\\\\', 'nন', 'ী', 'থবর', 'হইব', 'ে', 'বল', 'ি', 'য', '়', 'া', ',', 'স', 'া', 'জ', 'ি', 'য', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'দ', 'ু', 'ল', 'ি', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'গরদ', 'ে', 'র', 'জ', 'ো', 'ড', '়', 'পর', 'ি', 'য', '়', 'া', 'চ', 'া', 'প', 'া', 'আস', 'ি', 'য', '়', 'া', '\\\\', 'nদ', 'ী', 'ড', '়', 'া', 'ইল', '_', 'উগ', '্', 'ব', 'গন', '্', 'ধ', 'ছ', 'ু', 'ট', 'ি', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'গন', '্', 'ধর', 'া', 'জ', 'ে', 'র', 'া', 'বড', '়', 'ব', 'া', 'হ', 'া', 'র', 'দ', 'ি', 'য', '়', 'া', ',', 'দল', 'ে', 'দল', 'ে', 'আস', 'ি', 'য', '়', 'া', ',', 'গন', '্', 'ধ', 'ব', 'ি', 'ল', 'া', 'ইয', '়', 'া', '\\\\', 'nদ', 'ে', 'শ', 'ম', 'া', 'থ', 'া', 'ইথ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'অশ', 'ো', 'ক', 'ন', 'ে', 'শ', 'া', 'য', '়', 'ল', 'া', 'ল', 'হইয', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'উপস', '্', 'থ', 'ি', 'থ', ';', 'সঙ', '্', 'গ', 'ে', 'একপ', 'া', 'ল', 'প', 'ি', 'প', '্', 'ড', '়', 'া', 'ম', 'ো', 'স', 'া', 'য', '়', 'ে', 'ব', '\\\\', 'nহইয', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'ছ', 'ে', ';', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'গ', 'ু', 'ণ', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'সম', '্', 'বন', '্', 'ধ', 'ন', 'া', 'ই', ',', 'ক', 'ি', 'ন', '্', 'থ', 'দ', 'া', 'থ', 'ে', 'র', 'জ', '্', 'ব', 'া', 'ল', 'া', 'বড', '়', '-', 'ক', 'ো', 'ন', '্', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'ন', 'া', 'এর', 'ু', 'প', '\\\\', 'nবরয', 'া', 'থ', '্', 'র', 'ী', 'জ', 'ো', 'ট', 'ে', ',', 'আর', 'ক', 'ো', 'ন', '্', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'ন', 'া', 'থ', 'া', 'হ', 'া', 'র', 'া', 'হ', 'ু', 'ল', 'ফ', 'ু', 'ট', 'া', 'ইয', '়', 'া', 'ব', 'ি', 'ব', 'া', 'দ', 'ব', 'া', 'ধ', 'া', 'য', '়', '?', 'ক', 'ু', 'র', 'ু', 'বক', 'ক', 'ু', 'টজ', 'প', '্', 'রভ', 'ৃ', 'থ', 'ি', '\\\\', 'nআরও', 'অন', 'ে', 'ক', 'বরয', 'া', 'থ', '্', 'র', 'ী', 'আস', 'ি', 'য', '়', 'া', 'ছ', 'ি', 'ল', 'ে', 'ন', ',', 'ঘটক', 'মহ', 'া', 'শয', '়', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'পর', 'ি', 'চয', '়', 'শ', 'ু', 'ন', 'ি', 'ব', 'ে', 'ন', '।', 'সর', '্', 'বথ', '্', 'রই', 'থ', 'ি', 'ন', 'ি', '\\\\', 'nয', 'া', 'থ', 'া', 'য', '়', 'া', 'থ', 'কর', 'ে', 'ন', 'এব', 'ং', 'ক', 'ি', 'ছ', 'ু', 'ক', 'ি', 'ছ', 'ু', 'মধ', 'ু', 'প', 'া', 'ইয', '়', 'া', 'থ', 'া', 'ক', 'ে', 'ন', '।', '\\\\', 'n', '\\\\', 'nআম', 'া', 'রও', 'ন', 'ি', 'মন', '্', 'থ', '্', 'রণ', 'ছ', 'ি', 'ল', ',', 'আম', 'ি', 'ও', 'গ', 'ে', 'ল', 'া', 'ম', '।', 'দ', 'ে', 'খ', 'ি', ',', 'বরপক', '্', 'ষ', 'ে', 'র', 'বড', '়', 'ব', 'ি', 'পদ', '।', 'ব', 'া', 'থ', 'া', 'স', 'ব', 'া', 'হক', 'ে', 'র', 'ব', 'া', 'য', '়', 'ন', 'া', '\\\\', 'nল', 'ু', 'ক', 'া', 'ইল', 'ে', 'ন', ',', 'ক', 'ে', 'হ', 'খ', 'ু', 'ঁ', 'জ', 'ি', 'য', '়', 'া', 'প', 'া', 'য', '়', 'ন', 'া', '।', 'দ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', ',', 'বর', 'বরয', 'া', 'থ', '্', 'র', 'ী', ',', 'সকল', 'ে', 'অব', 'া', 'ক', 'হইয', '়', 'া', 'স', '্', 'থ', 'ি', 'রভ', 'া', 'ব', 'ে', 'দ', 'ী', 'ড', '়', 'া', 'ইয', '়', 'া', '\\\\', 'nআছ', 'ে', 'ন', '।', 'মল', '্', 'ল', 'ি', 'ক', 'া', 'দ', 'ি', 'গ', 'ে', 'র', 'ক', 'ু', 'ল', 'য', 'া', 'য', '়', 'দ', 'ে', 'খ', 'ি', 'য', '়', 'া', ',', 'আম', 'ি', 'ই', 'ব', 'া', 'হক', 'ে', 'র', 'ক', 'া', 'র', '্', 'য', 'স', '্', 'ব', 'ী', 'ক', 'া', 'র', 'কর', 'ি', 'ল', 'া', 'ম', '।', 'বর', ',', 'বরয', 'া', 'থ', '্', 'র', 'ী', '\\\\', 'nসকলক', 'ে', 'থ', 'ু', 'ল', 'ি', 'য', '়', 'া', 'লইয', '়', 'া', 'মল', '্', 'প', 'ি', 'ক', 'া', 'প', 'ু', 'র', 'ে', 'গ', 'ে', 'ল', 'া', 'ম', '।', '\\\\', 'n', '\\\\', 'nস', 'ু', 'খ', 'ে', 'র', 'হ', 'া', 'স', 'ি', 'হ', 'া', 'স', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', 'দ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', ',', 'প', 'া', 'থ', 'া', 'য', '়', 'প', 'া', 'থ', 'া', 'য', '়', 'জড', '়', 'া', 'জড', '়', 'ি', ',', 'গন', '্', 'ধ', 'ে', 'র', 'ভ', 'া', 'ণ', '্', 'ড', 'া', 'র', 'ে', 'ছড', '়', 'া', 'ছড', '়', 'ি', 'পড', '়', 'ি', 'য', '়', 'া', 'গ', 'ি', 'য', '়', 'া', 'ছ', 'ে', '\\\\', 'n_র', 'ূ', 'প', 'ে', 'র', 'ভ', 'া', 'র', 'ে', 'সকল', 'ে', 'ভ', 'া', 'ঙ', '্', 'গ', 'ি', 'য', '়', 'া', 'পড', '়', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', 'য', 'ু', 'খ', 'ি', ',', 'ম', 'া', 'লথ', 'ী', ',', 'বক', 'ু', 'ল', ',', 'রজন', 'ী', 'গন', '্', 'ধ', 'া', 'প', '্', 'রভ', 'ৃ', 'থ', 'ি', 'এয', '়', 'ো', 'গণ', 'স', '্', 'থ', '্', 'র', 'ী', '-', 'আচ', 'া', 'র', '\\\\', 'nকর', 'ি', 'য', '়', 'া', 'বরণ', 'কর', 'ি', 'ল', '।', 'দ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', ',', 'প', 'ু', 'র', 'ো', 'হ', 'ি', 'থ', 'উপস', '্', 'থ', 'ি', 'থ', ';', 'নস', 'ী', 'ব', 'া', 'ব', 'ু', 'র', 'নবমব', '্', 'ধ', 'ী', 'য', '়', 'া', 'কন', '্', 'য', 'া', '(', 'জ', 'ী', 'বন', '্', 'থ', 'ক', 'ু', 'স', 'ু', 'মর', 'ূ', 'প', 'ি', 'ণ', 'ী', ')', '\\\\', 'nক', 'ু', 'স', 'ু', 'মলথ', 'া', 'স', 'ূ', 'চ', 'স', 'ু', 'থ', 'া', 'লইয', '়', 'া', 'দ', 'ী', 'ড', '়', 'া', 'ইয', '়', 'া', 'আছ', 'ে', ';', 'কন', '্', 'য', 'া', 'কর', '্', 'থ', 'া', 'কন', '্', 'য', 'া', 'সম', '্', 'প', '্', 'রদ', 'া', 'ন', 'কর', 'ি', 'ল', 'ে', 'ন', ';', 'প', 'ু', 'র', 'ো', 'হ', 'ি', 'থ', 'মহ', 'া', 'শয', '়', '\\\\', 'nদ', 'ু', 'ইজনক', 'ে', 'এক', 'স', 'ু', 'থ', 'া', 'য', '়', 'গ', 'া', 'থ', 'ি', 'য', '়', 'া', 'গ', 'া', 'টছড', '়', 'া', 'ব', 'া', 'ঁ', 'ধ', 'ি', 'য', '়', 'া', 'দ', 'ি', 'ল', 'ে', 'ন', '।', '\\\\', 'n', '\\\\', 'nথখন', 'বরক', 'ে', 'ব', 'া', 'সর', '-', 'ঘর', 'ে', 'লইয', '়', 'া', 'গ', 'ে', 'ল', '।', 'কথ', 'য', 'ে', 'রসময', '়', 'ী', 'মধ', 'ু', 'ময', '়', 'ী', 'স', 'ু', 'ন', '্', 'দর', 'ী', 'স', 'ে', 'খ', 'া', 'ন', 'ে', 'বরক', 'ে', 'ঘ', 'ি', 'র', 'ি', 'য', '়', 'া', 'বস', 'ি', 'ল', ',', '\\\\', 'nথ', 'া', 'হ', 'া', 'ক', 'ি', 'বল', 'ি', 'ব', '।', 'প', '্', 'র', 'া', 'চ', 'ী', 'ন', 'া', 'ঠ', 'া', 'ক', 'ু', 'র', 'া', 'ণ', 'ী', 'দ', 'ি', 'দ', 'ি', 'টগর', 'স', 'া', 'দ', 'া', 'প', '্', 'র', 'া', 'ণ', 'ে', 'ব', 'া', 'ধ', 'া', 'রস', 'ি', 'কথ', 'া', 'কর', 'ি', 'থ', 'ে', 'কর', 'ি', 'থ', 'ে', 'শ', 'ু', 'ক', 'া', 'ইয', '়', 'া', '\\\\', 'nউঠ', 'ি', 'ল', 'ে', 'ন', '।', 'রঙ', '্', 'গণ', 'ে', 'র', 'র', 'া', 'ঙ', '্', 'গ', 'া', 'ম', 'ু', 'খ', 'ে', 'হ', 'া', 'স', 'ি', 'ধর', 'ে', 'ন', 'া', '।', 'য', 'ু', 'ই', ',', 'কন', '্', 'য', 'ে', 'র', 'সই', ',', 'কন', '্', 'য', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', 'গ', 'ি', 'য', '়', 'া', 'শ', 'ু', 'ইল', ';', 'রজন', 'ী', 'গন', '্', 'ধ', 'া', 'ক', 'ে', '\\\\', 'nবর', 'থ', 'া', 'ড', '়', 'ক', 'া', 'র', 'া', 'ক', '্', 'ষস', 'ী', 'বল', 'ি', 'য', '়', 'া', 'কথ', 'থ', 'া', 'ম', 'া', 'স', 'া', 'কর', 'ি', 'ল', ';', 'বক', 'ু', 'ল', 'এক', 'ে', 'ব', 'া', 'ল', 'ি', 'ক', 'া', ',', 'থ', 'া', 'থ', 'ে', 'যথ', 'গ', 'ু', 'ণ', ',', 'থথ', 'র', 'ু', 'প', 'নহ', 'ে', ';', '\\\\', 'nএকক', 'ো', 'ণ', 'ে', 'গ', 'ি', 'য', '়', 'া', 'চ', 'ু', 'প', 'কর', 'ি', 'য', '়', 'া', 'বস', 'ি', 'য', '়', 'া', 'রহ', 'ি', 'ল', ';', 'আর', 'ঝ', 'ু', 'ম', '্', 'ক', 'া', 'ফ', 'ু', 'ল', 'বড', '়', 'ম', 'া', 'ন', 'ু', 'ষ', 'ে', 'র', 'গ', 'ৃ', 'হ', 'ি', 'ণ', 'ী', 'র', 'মথ', 'ম', 'ো', 'ট', 'া', 'ন', 'ী', 'ল', 'শ', 'া', 'ড', '়', 'ি', '\\\\', 'nছড', '়', 'া', 'ইয', '়', 'া', 'জমক', 'া', 'ইয', '়', 'া', 'বস', 'ি', 'ল', '।', 'থখন', '-', '\\\\', 'n', '\\\\', 'n', '“', 'কমলক', 'া', 'ক', 'া', '-', 'ওঠ', 'ব', 'া', 'ড', '়', 'ি', 'য', 'া', 'ই', '-', 'র', 'া', 'থ', 'হয', '়', 'ে', 'ছ', 'ে', ',', 'ও', 'ক', 'ি', ',', 'ঢ', 'ু', 'ল', 'ে', 'পড', '়', 'ব', 'ে', 'য', 'ে', '?', 'ক', 'ু', 'স', 'ু', 'মলথ', 'া', 'এই', 'কথ', 'া', 'বল', 'ি', 'য', '়', 'া', 'আম', 'া', 'র', '\\\\', 'nগ', 'া', 'ঠ', 'ে', 'ল', 'ি', 'থ', 'ে', 'ছ', 'ি', 'ল', ';', '-', 'চমক', 'হইল', 'ে', ',', 'দ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', 'ক', 'ি', 'ছ', 'ু', 'ই', 'ন', 'া', 'ই', '।', 'স', 'ে', 'ই', 'প', 'ু', 'ষ', '্', 'পব', 'া', 'সর', 'ক', 'ো', 'থ', 'া', 'য', '়', 'ম', 'ি', 'শ', 'ি', 'ল', '?', '-', 'মন', 'ে', '\\\\', 'nকর', 'ি', 'ল', 'া', 'ম', ',', 'স', 'ং', 'স', 'া', 'র', 'অন', 'ি', 'থ', '্', 'যই', 'বট', 'ে', 'এই', 'আছ', 'ে', 'এই', 'ন', 'া', 'ই', '।', 'স', 'ে', 'রম', '্', 'য', 'ব', 'া', 'সর', 'ক', 'ো', 'থ', 'া', 'য', '়', 'গ', 'ে', 'ল', ',', '_', 'স', 'ে', 'ই', '\\\\', 'nহ', 'া', 'স', '্', 'যম', 'ু', 'খ', 'ী', 'শ', 'ু', 'ভ', '্', 'রস', '্', 'ম', 'ি', 'থস', 'ু', 'ধ', 'া', 'ময', '়', 'ী', 'প', 'ু', 'ষ', '্', 'পস', 'ু', 'ন', '্', 'দর', 'ী', 'সকল', 'ক', 'ো', 'থ', 'া', 'য', '়', 'গ', 'ে', 'ল', '?', 'য', 'ে', 'খ', 'া', 'ন', 'ে', 'সব', 'য', 'া', 'ইব', 'ে', ',', 'স', 'ে', 'ইখ', 'া', 'ন', 'ে', '-', 'স', '্', 'ম', 'ৃ', 'থ', 'ি', 'র', '\\\\', 'nদর', '্', 'পণথল', 'ে', ',', 'ভ', 'ূ', 'থস', 'া', 'গরগর', '্', 'ভ', 'ে', '।', 'য', 'ে', 'খ', 'া', 'ন', 'ে', 'র', 'া', 'জ', 'া', 'প', '্', 'রজ', 'া', ',', 'পর', '্', 'বথ', 'সম', 'ু', 'দ', '্', 'র', ',', 'গ', '্', 'রহ', 'নক', '্', 'ষথ', '্', 'র', 'া', 'দ', 'ি', 'গ', 'ি', 'য', '়', 'া', 'ছ', 'ে', 'ব', 'া', 'য', 'া', 'ইব', 'ে', ',', '\\\\', 'nস', 'ে', 'ইখ', 'া', 'ন', 'ে', '-', 'ধ', '্', 'ব', 'ং', 'সপ', 'ু', 'র', 'ে', '!', 'এই', 'ব', 'ি', 'ব', 'া', 'হ', 'ে', 'র', 'ন', '্', 'য', 'া', 'য', '়', 'সব', 'শ', 'ৃ', 'ন', '্', 'য', 'ে', 'ম', 'ি', 'শ', 'া', 'ইব', 'ে', ',', 'সব', 'ব', 'া', 'থ', 'া', 'স', 'ে', 'গল', 'ি', 'য', '়', 'া', 'য', 'া', 'ইব', 'ে', '।', '\\\\', 'nক', 'ু', 'স', 'ু', 'ম', 'বল', 'ি', 'ল', ',', '“', 'ওঠ', 'ন', 'া', '-', 'ক', 'ি', 'কচ', '্', 'চ', 'ো', '?', '\\\\', 'n', '\\\\', 'nআম', 'ি', 'বল', 'ি', 'ল', 'া', 'ম', ',', '“', 'দ', 'ূ', 'র', 'প', 'া', 'গল', 'ি', ',', 'আম', 'ি', 'ব', 'ি', 'য', '়', 'ে', 'দ', 'ি', 'চ', '্', 'ছ', 'ি', 'ল', 'া', 'ম', '1', '”', '\\\\', 'n', '\\\\', 'n২০১৮', '\"', ',', '\"', 'page_4', '\"', ':', '\"', '২০১৮', '\\\\', 'n', '\\\\', 'nফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '৯', '\\\\', 'n', '\\\\', 'nক', 'ু', 'স', 'ু', 'ম', 'ঘ', 'ে', 'ঁ', 'ষ', 'ে', 'এস', 'ে', ',', 'হ', 'ে', 'স', 'ে', 'হ', 'ে', 'স', 'ে', 'ক', 'া', 'ছ', 'ে', 'দ', 'ী', 'ড', '়', 'া', 'ইয', '়', 'া', 'আদর', 'কর', 'ি', 'য', '়', 'া', 'জ', 'ি', 'জ', '্', 'ঞ', 'া', 'স', 'া', 'কর', 'ি', 'ল', ',', '“', 'ক', 'া', 'র', 'ব', 'ি', 'য', '়', 'ে', ',', 'ক', 'া', 'ক', 'া', '?', '\\\\', 'nআম', 'ি', 'বল', 'ি', 'ল', 'া', 'ম', ',', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'য', '়', 'ে', '।', '”', '\\\\', 'n', '\\\\', 'n', '“', 'ও', 'ঃ', 'প', 'ো', 'ড', '়', 'া', 'কপ', 'া', 'ল', ',', 'ফ', 'ু', 'ল', 'ে', 'র', '?', 'আম', 'ি', 'বল', 'ি', 'ক', 'ি', '!', 'আম', 'ি', 'ও', 'য', 'ে', 'এই', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'য', '়', 'ে', 'দ', 'ি', 'য', '়', 'ে', 'ছ', 'ি', '।', \"'\", '\\\\', 'n', '\\\\', 'n', '“', 'কই', '?', '\\\\', 'n', '\\\\', 'n', '“', 'এই', 'য', 'ে', 'ম', 'া', 'ল', 'া', 'গ', 'ে', 'খ', 'ে', 'ছ', 'ি', '।', \"'\", 'দ', 'ে', 'খ', 'ি', 'ল', 'া', 'ম', ',', 'স', 'ে', 'ই', 'ম', 'া', 'ল', 'া', 'য', '়', 'আম', 'া', 'র', 'বর', 'কন', '্', 'য', 'া', 'রহ', 'ি', 'য', '়', 'া', 'ছ', 'ে', '।', '[', '3', '\\\\', 'n', '\\\\', 'nশব', '্', 'দ', 'া', 'র', '্', 'থ', 'ও', 'ট', 'ী', 'ক', 'া', ':', 'কন', '্', 'য', 'া', 'ভ', 'া', 'রহস', '্', 'থ', '-', 'ব', 'ি', 'ব', 'া', 'হয', 'ো', 'গ', '্', 'য', 'া', 'কন', '্', 'য', 'া', 'ব', 'ি', 'য', '়', 'ে', 'দ', 'ে', 'ওয', '়', 'া', 'র', 'দ', 'া', 'য', '়', 'ি', 'থ', '্', 'ব', 'বহনক', 'া', 'র', 'ী', 'অর', '্', 'থ', 'ে', '।', '\\\\', 'nসন', '্', 'ন', '্', 'ধ', 'ে', 'র', '_', 'ব', 'ি', 'য', '়', 'ে', 'র', '।', 'কন', '্', 'য', 'া', 'কর', '্', 'থ', 'া', '-', 'কন', '্', 'য', 'া', 'র', 'অভ', 'ি', 'ভ', 'া', 'বক', '।', 'পথ', '্', 'র', 'া', 'সন', '-', 'প', 'া', 'থ', 'া', 'র', 'উপর', 'আসন', '।', 'অবগপ', '্', 'ঠনবথ', 'ী', '\\\\', 'n', '-', 'ঘ', 'ো', 'মট', 'া', 'দ', 'ে', 'ওয', '়', 'া', '।', 'ইয', '়', 'া', 'রক', 'ি', '-', 'বন', '্', 'ধ', 'ু', 'দ', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'ই', 'কর', 'া', 'চল', 'ে', 'এমন', 'আল', 'া', 'প', '।', 'সন', '্', 'ধ', '্', 'য', 'া', 'ঠ', 'া', 'ক', 'ু', 'র', 'া', 'ণ', 'ী', 'দ', 'ি', 'দ', 'ি', '-', 'এখ', 'া', 'ন', 'ে', '\\\\', 'nসন', '্', 'ধ', '্', 'য', 'া', 'ক', 'া', 'লক', 'ে', 'দ', 'ি', 'দ', 'ি', 'বল', 'ে', 'সম', '্', 'ব', 'ো', 'ধন', 'কর', 'া', 'হয', '়', 'ে', 'ছ', 'ে', '।', 'পর', 'ি', 'মল', '-', 'স', 'ু', 'গন', '্', 'ধ', '।', 'গন', '্', 'ধ', 'ো', 'প', 'া', 'ধ', '্', 'য', 'া', 'য', '়', '-', 'গন', '্', 'ধ', 'ে', 'র', 'র', 'া', 'জ', 'া', '\\\\', 'nব', 'ো', 'ঝ', 'া', 'থ', 'ে', '।', 'ক', 'ু', 'ল', 'া', 'চ', 'া', 'র', '্', 'য', '-', 'ক', 'ু', 'ল', 'ে', 'র', 'আচ', 'া', 'র', '্', 'য', 'ব', 'া', 'ব', 'ং', 'শ', 'ে', 'র', 'প', '্', 'রধ', 'া', 'ন', 'প', 'ু', 'র', 'ো', 'হ', 'ি', 'থ', '।', 'ব', 'া', 'ষ', '্', 'থ', 'ী', 'ম', 'া', 'ল', 'ি', '_', 'য', 'ে', 'ম', 'া', 'ল', 'ি', 'ইচ', '্', 'ছ', 'া', 'মথ', 'ো', '\\\\', 'nফ', 'ু', 'ল', 'ফ', 'ো', 'ট', 'া', 'থ', 'ে', 'প', 'া', 'র', 'ে', '।', 'খদ', '্', 'য', 'ো', 'থ', '-', 'জ', 'ো', 'ন', 'া', 'ক', 'ি', 'প', 'ো', 'ক', 'া', '।', 'এয', '়', 'ো', 'গণ', '-', 'সধব', 'া', 'ন', 'া', 'র', 'ী', '।', 'কমলক', 'া', 'ক', 'া', '-', '\\\\', 'nকমল', 'া', 'ক', 'া', 'ন', '্', 'থক', 'ে', 'ক', 'া', 'ক', 'া', 'বল', 'ে', 'সম', '্', 'ব', 'ো', 'ধন', 'কর', 'া', 'হয', '়', 'ে', 'ছ', 'ে', '।', '\\\\', 'n', '\\\\', 'nপ', 'া', 'ঠ', 'পর', 'ি', 'চ', 'ি', 'থ', 'ি', ':', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', 'চট', '্', 'ট', 'ো', 'প', 'া', 'ধ', '্', 'য', 'া', 'য', '়', 'ে', 'র', 'লঘ', '্', 'ু', 'রচন', 'া', '“', 'কমল', 'া', 'ক', 'া', 'ন', '্', 'থ', 'ে', 'র', 'দপ', '্', 'থর', '\\\\', '\"', 'গ', '্', 'রন', '্', 'থ', 'ে', 'র', 'নবম', 'স', 'ং', 'খ', '্', 'যক', 'ল', 'ে', 'খ', 'া', '\\\\', 'n', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '\\\\', '\"', '৷', 'এই', 'রচন', 'া', 'য', '়', 'হ', 'া', 'স', '্', 'যরস', 'ে', 'র', 'ম', 'া', 'ধ', '্', 'যম', 'ে', 'ব', 'ি', 'ভ', 'ি', 'ন', '্', 'ন', 'ফ', 'ু', 'ল', 'ে', 'র', 'ন', 'া', 'ম', ',', 'স', 'ে', 'ফ', 'ু', 'লগ', 'ু', 'ল', 'ো', 'র', 'গন', '্', 'ধ', 'ে', 'র', 'থ', 'া', 'রথম', '্', 'য', ',', '\\\\', 'nবর', '্', 'ণ', 'ে', 'র', 'রকমফ', 'ে', 'র', 'অথ', '্', 'যন', '্', 'থ', 'স', 'ং', 'ব', 'ে', 'দনশ', 'ী', 'লথ', 'া', 'র', 'সঙ', '্', 'গ', 'ে', 'থ', 'ু', 'ল', 'ে', 'ধর', 'ে', 'ছ', 'ে', 'ন', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', '।', 'কখন', 'ক', 'ো', 'ন', 'ফ', 'ু', 'ল', 'ফ', 'ো', 'ট', 'ে', 'স', 'ে', '\\\\', 'nপর', '্', 'যব', 'ে', 'ক', '্', 'ষণও', 'এই', 'রচন', 'া', 'য', '়', 'প', 'া', 'ওয', '়', 'া', 'য', 'া', 'য', '়', '।', 'ব', 'ি', 'য', '়', 'ে', '-', 'অন', 'ু', 'ষ', '্', 'ঠ', 'া', 'ন', 'ব', 'া', 'ঙ', 'া', 'ল', 'ি', 'র', 'জ', 'ী', 'বন', 'ে', ',', 'ব', 'ি', 'শ', 'ে', 'ষ', 'কর', 'ে', 'ব', 'া', 'ড', '়', 'ি', 'র', 'শ', 'ি', 'শ', 'ু', '-', 'ক', 'ি', 'শ', 'ো', 'র', '\\\\', 'nও', 'প', '্', 'রথ', 'ি', 'ব', 'ে', 'শ', 'ী', 'দ', 'ে', 'র', 'মধ', '্', 'য', 'ে', 'অথ', 'ী', 'ব', 'আনন', '্', 'দ', 'ন', 'ি', 'য', '়', 'ে', 'আস', 'ে', '।', 'এই', 'অন', 'ু', 'ষ', '্', 'ঠ', 'া', 'ন', 'ে', 'বর', '-', 'কন', 'ে', 'ক', 'ে', 'ন', '্', 'দ', '্', 'র', 'ে', 'থ', 'া', 'কল', 'ে', 'ও', 'বর', '-', 'কন', 'ে', 'র', '\\\\', 'nয', 'ু', 'ক', '্', 'থ', '।', 'ব', 'ি', 'য', '়', 'ে', 'অন', 'ু', 'ষ', '্', 'ঠ', 'া', 'ন', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'য', 'ু', 'ক', '্', 'থ', 'থ', 'া', 'ক', 'ে', 'ন', 'এমন', 'ন', 'া', 'ন', 'া', 'ব', '্', 'যক', '্', 'থ', 'ি', 'র', 'পর', 'ি', 'বর', '্', 'থ', 'ে', 'ব', 'ি', 'ভ', 'ি', 'ন', '্', 'ন', 'ফ', 'ু', 'ল', 'ে', 'র', 'উল', '্', 'ল', 'ে', 'খ', 'কর', 'ে', '\\\\', 'nঅস', 'া', 'ধ', 'া', 'রণ', 'দক', '্', 'ষথ', 'া', 'য', '়', 'বঙ', '্', 'ক', 'ি', 'মচন', '্', 'দ', '্', 'র', 'ব', 'া', 'ঙ', 'া', 'ল', 'ি', 'র', 'গ', 'া', 'হস', '্', 'থ', '্', 'য', 'একট', 'ি', 'অন', 'ু', 'ষ', '্', 'ঠ', 'া', 'নক', 'ে', 'আর', 'ো', 'আনন', '্', 'দদ', 'া', 'য', '়', 'ক', 'কর', 'ে', 'এখ', 'া', 'ন', 'ে', '\\\\', 'nউপস', '্', 'থ', 'া', 'পন', 'কর', 'ে', 'ছ', 'ে', 'ন', '।', 'এখ', 'া', 'ন', 'ে', 'ল', 'ে', 'খক', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'ক', 'ে', 'ব', 'া', 'স', '্', 'থব', 'জ', 'ী', 'বন', 'ে', 'উপস', '্', 'থ', 'া', 'পন', 'ে', 'অস', 'া', 'ধ', 'া', 'রণ', 'দক', '্', 'ষথ', 'া', 'র', 'পর', 'ি', 'চয', '়', '\\\\', 'n', '\\\\', 'nদ', 'ি', 'য', '়', 'ে', 'ছ', 'ে', 'ন', '।', 'থ', 'া', 'র', 'এই', 'রচন', 'া', 'ভঙ', '্', 'গ', 'ি', 'ব', 'া', 'ং', 'ল', 'া', 'গদ', '্', 'য', 'ব', 'ি', 'ক', 'া', 'শ', 'ে', 'র', 'ক', '্', 'ষ', 'ে', 'থ', '্', 'র', 'ে', 'গ', 'ু', 'র', 'ু', 'থ', 'ৃ', 'প', 'ূ', 'র', '্', 'ণ', 'ভ', 'ূ', 'ম', 'ি', 'ক', 'া', 'র', 'া', 'খ', 'ে', '।', '\\\\', 'n', '\\\\', 'nঅন', 'ু', 'শ', 'ী', 'লন', 'ী', '\\\\', 'n', '\\\\', 'n', '\\\\', 'n', '\\\\', 'n', '\\\\', 'n', '\\\\', 'nকর', '্', 'ম', '-', 'অন', 'ু', 'শ', 'ী', 'লন', '\\\\', 'n১', '.', 'প', 'া', 'ঠট', 'ি', 'থ', 'ে', 'য', 'ে', 'সবফ', 'ু', 'ল', 'ে', 'র', 'কথ', 'া', 'বল', 'া', 'হয', '়', 'ে', 'ছ', 'ে', 'স', 'ে', 'গ', 'ু', 'ল', 'ো', 'র', 'ন', 'া', 'ম', 'ওগন', '্', 'ধ', 'ে', 'র', 'পর', 'ি', 'চয', '়', 'দ', 'ি', 'য', '়', 'ে', 'একট', 'ি', 'চ', 'া', 'র', '্', 'ট', 'থ', 'ৈ', 'র', 'ি', 'কর', '।', '\\\\', 'n২', '.', 'ফ', 'ু', 'ল', 'ে', 'র', 'বহ', 'ু', 'ব', 'ি', 'ধ', 'ব', '্', 'যবহ', 'া', 'র', 'ল', 'ি', 'প', 'ি', 'বদ', '্', 'ধ', 'কর', 'ে', 'শ', '্', 'র', 'ে', 'ণ', 'ি', 'শ', 'ি', 'ক', '্', 'ষকক', 'ে', 'দ', 'ে', 'খ', 'া', 'ও', '।', '\\\\', 'n', '\\\\', 'nবহ', 'ু', 'ন', 'ি', 'র', '্', 'ব', 'া', 'চন', 'ি', 'প', '্', 'রশ', '্', 'ন', '\\\\', 'n', '\\\\', 'n১', '।', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', \"'\", 'গল', '্', 'প', 'ে', 'র', 'প', 'া', 'থ', '্', 'র', 'ক', 'ে', 'ছ', 'ি', 'ল', '?', '\\\\', 'nক', '.', 'মল', '্', 'ল', 'ি', 'ক', 'া', 'খ', '.', 'স', '্', 'থলপদ', '্', 'ম', '\\\\', 'nগ', '.', 'রজন', 'ী', 'গন', '্', 'ধ', 'া', 'ঘ', '.', 'ম', 'া', 'লথ', 'ী', '\\\\', 'n', '\\\\', 'nফর', '্', 'ম', 'া', '-', '২', ',', 'ম', 'া', 'ধ', '্', 'যম', 'ি', 'ক', 'ব', 'া', 'ং', 'ল', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', ':', '৯ম', '-', '১০', 'শ', '্', 'র', 'ে', 'ণ', 'ি', '\"', ',', '\"', 'page_5', '\"', ':', '\"', '১০', 'ম', 'া', 'ধ', '্', 'যম', 'ি', 'ক', 'ব', 'া', 'ং', 'ল', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', '\\\\', 'n', '\\\\', 'n২', '।', 'এ', 'গল', '্', 'প', 'ে', 'কন', '্', 'য', 'া', 'ক', 'ু', 'ল', 'বলথ', 'ে', 'ক', 'া', 'দ', 'ে', 'র', 'ব', 'ো', 'ঝ', 'া', 'ন', 'ো', 'হয', '়', 'ে', 'ছ', 'ে', '?', '\\\\', 'nক', '.', 'ভ', 'ো', 'মর', 'খ', '.', '.', 'ব', 'ৃ', 'ক', '্', 'ষ', '\\\\', 'n', '\\\\', 'nগ', '.', 'গ', 'া', 'ছপ', 'া', 'ল', 'া', 'ঘ', '.', 'ফ', 'ু', 'ল', '\\\\', 'nন', 'ি', 'চ', 'ে', 'র', 'উদ', '্', 'দ', 'ী', 'পকট', 'ি', 'পড', '়', 'ে', '৩', 'স', 'ং', 'খ', '্', 'যক', 'প', '্', 'রশ', '্', 'র', 'ে', 'র', 'উথ', '্', 'থর', 'দ', 'া', 'ও', ':', '\\\\', 'n', '\\\\', 'nজম', 'ি', 'দ', 'া', 'র', 'জন', 'া', 'র', '্', 'দন', 'ঘ', 'ো', 'ষ', 'ম', 'ে', 'য', '়', 'ে', 'র', 'ব', 'ি', 'য', '়', 'ে', 'দ', 'ি', 'থ', 'ে', 'গ', 'ি', 'য', '়', 'ে', 'প', 'া', 'থ', '্', 'র', 'খ', 'ু', 'ঁ', 'জ', 'ে', 'ব', 'ে', 'ড', '়', 'া', 'চ', '্', 'ছ', 'ে', 'ন', '।', 'অন', 'ে', 'ক', 'খ', 'ো', 'ঁ', 'জ', 'া', 'খ', 'ু', 'ঁ', 'জ', 'ি', 'র', '\\\\', 'nপর', 'অবশ', 'ে', 'ষ', 'ে', 'র', 'া', 'য', '়', 'ব', 'া', 'হ', 'া', 'দ', 'ু', 'র', 'শ', 'ু', 'ভ', 'া', 'শ', 'ি', 'স', 'চ', 'ৌ', 'ধ', 'ু', 'র', 'ী', 'র', 'একম', 'া', 'থ', '্', 'র', 'প', 'ু', 'থ', '্', 'র', 'দ', 'ে', 'ব', 'া', 'শ', 'ি', 'সক', 'ে', 'প', 'া', 'ওয', '়', 'া', 'গ', 'ে', 'ল', '।', 'র', 'ূ', 'প', 'ে', '\\\\', 'n', '-', 'গ', 'ু', 'ণ', 'ে', 'স', 'ে', 'অথ', 'ু', 'লন', 'ী', 'য', '়', '।', '\\\\', 'n', '\\\\', 'n৩', '।', 'উদ', '্', 'দ', 'ী', 'পক', 'ে', 'র', 'দ', 'ে', 'ব', 'া', 'শ', 'ি', 'স', 'ে', 'র', 'স', 'া', 'থ', 'ে', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '\\\\', '\"', 'গল', '্', 'প', 'ে', 'র', 'স', 'া', 'দ', 'ৃ', 'শ', '্', 'য', 'রয', '়', 'ে', 'ছ', 'ে', '-', '\\\\', 'n', '\\\\', 'n1', '.', 'গন', '্', 'ধর', 'া', 'জ', 'ে', 'র', '\\\\', 'n1', '.', 'গ', 'ো', 'ল', 'া', 'ব', 'ে', 'র', '\\\\', 'n111', '.', 'রজন', 'ী', 'গন', '্', 'ধ', 'া', 'র', '\\\\', 'nন', 'ি', 'চ', 'ে', 'র', 'ক', 'ো', 'নট', 'ি', 'সঠ', 'ি', 'ক', '?', '\\\\', 'nক', '.', '1', 'খ', '.', '1', '\\\\', 'nগ', '.', ',', '71', 'ঘ', '.', '11717', '\\\\', 'nস', 'ৃ', 'জনশ', 'ী', 'ল', 'প', '্', 'রশ', '্', 'ন', '\\\\', 'n', '\\\\', 'nম', 'ৌ', 'র', 'ী', 'একদ', 'ি', 'ন', 'ব', 'া', 'ব', 'া', 'র', 'ক', 'া', 'ছ', 'ে', 'ব', 'া', 'য', '়', 'ন', 'া', 'ধর', 'ে', 'ব', 'ো', 'ট', 'া', 'ন', 'ি', 'ক', '্', 'য', 'া', 'ল', 'গ', 'া', 'র', '্', 'ড', 'ে', 'ন', 'ে', 'ব', 'ে', 'ড', '়', 'া', 'থ', 'ে', 'য', 'া', 'ব', 'ে', '।', 'ব', 'া', 'ব', 'া', 'একদ', 'ি', 'ন', 'ওক', 'ে', '\\\\', 'nন', 'ি', 'য', '়', 'ে', 'ব', 'ে', 'ড', '়', 'া', 'থ', 'ে', 'গ', 'ে', 'ল', 'ে', 'স', 'ে', 'ভ', 'ী', 'ষণ', 'খ', 'ু', 'শ', 'ি', 'হয', '়', '।', 'ন', 'া', 'ন', 'া', 'জ', 'া', 'থ', 'ে', 'র', 'ফ', 'ু', 'ল', '-', 'ফল', 'ে', 'র', 'গ', 'া', 'ছ', 'ে', 'র', 'সম', 'া', 'র', 'ো', 'হ', 'দ', 'ে', 'খ', 'ে', 'স', 'ে', 'অভ', 'ি', 'ভ', 'ূ', 'থ', '\\\\', 'nহয', '়', 'ে', 'য', 'া', 'য', '়', '।', 'দ', 'ী', 'র', '্', 'ঘদ', 'ি', 'ন', 'স', 'ে', 'য', 'ে', 'সব', 'ফ', 'ু', 'ল', '-', 'ফল', 'ে', 'র', 'ন', 'া', 'ম', 'শ', 'ু', 'ন', 'ে', 'ছ', 'ে', 'স', 'ে', 'গ', 'ু', 'ল', 'ো', 'আজ', 'ন', 'ি', 'জ', 'চ', 'ো', 'খ', 'ে', 'দ', 'ে', 'খ', 'ে', 'খ', 'ু', 'বই', 'আনন', '্', 'দ', 'ি', 'থ', '\\\\', 'nহয', '়', '।', 'অবশ', 'ে', 'ষ', 'ে', 'স', 'ি', 'দ', '্', 'ধ', 'া', 'ন', '্', 'থ', 'ন', 'ে', 'য', '়', '-', 'ব', 'া', 'ড', '়', 'ি', 'র', 'আঙ', 'ি', 'ন', 'া', 'য', '়', 'ছ', 'ো', 'ট', '্', 'ট', 'একট', 'া', 'ব', 'া', 'গ', 'া', 'ন', 'করব', 'ে', '।', '\\\\', 'n', '\\\\', 'nক', '.', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', \"'\", 'গল', '্', 'প', 'ে', 'ক', 'ে', 'ঘটক', 'ে', 'র', 'দ', 'া', 'য', '়', 'ি', 'থ', '্', 'প', 'া', 'লন', 'কর', 'ে', '?', '\\\\', 'n', '\\\\', 'nখ', '.', 'ক', '্', 'ষ', 'ু', 'দ', '্', 'র', 'ব', 'ৃ', 'ক', '্', 'ষট', 'ি', 'ক', 'ে', 'ন', 'ব', 'ি', 'রক', '্', 'থ', 'হয', '়', 'ে', 'ছ', 'ি', 'ল', '?', '\\\\', 'n', '\\\\', 'nগ', '.', 'উদ', '্', 'দ', 'ী', 'পক', 'ে', 'র', 'ম', 'ৌ', 'র', 'ী', 'র', 'ভ', 'া', 'ল', 'ো', 'ল', 'া', 'গ', 'া', 'র', 'ব', 'ি', 'ষয', '়', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', \"'\", 'গল', '্', 'প', 'ে', 'র', 'স', 'া', 'দ', 'ৃ', 'শ', '্', 'য', 'প', 'ূ', 'র', '্', 'ণ', 'দ', 'ি', 'কট', 'ি', 'ব', '্', 'য', 'া', 'খ', '্', 'য', 'া', 'কর', '।', '\\\\', 'nঘ', '.', 'ম', 'ৌ', 'র', 'ী', 'র', 'ম', 'া', 'ঝ', 'ে', 'স', 'ৃ', 'ষ', '্', 'ট', 'প', '্', 'রথ', 'ি', 'ক', '্', 'র', 'ি', 'য', '়', 'া', 'ই', 'য', 'ে', 'ন', '“', 'ফ', 'ু', 'ল', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', '\\\\', '\"', 'গল', '্', 'প', 'ে', 'র', 'ম', 'ূ', 'ল', 'চ', 'ে', 'থন', 'া', '-', 'য', 'ু', 'ক', '্', 'থ', 'ি', 'সহ', 'ব', 'ু', 'ঝ', 'ি', 'য', '়', 'ে', 'ল', 'ে', 'খ', '।', '\\\\', 'n', '\\\\', 'n২০১৮', '\"', ',', '\"', 'page_6', '\"', ':', '\"', '২০১৮', '\\\\', 'n', '\\\\', 'nস', 'ু', 'ভ', 'া', '\\\\', 'nরব', 'ী', 'ন', '্', 'দ', '্', 'রন', 'া', 'থ', 'ঠ', 'া', 'ক', 'ু', 'র', '\\\\', 'n', '\\\\', 'n', '[', 'ল', 'ে', 'খক', '-', 'পর', 'ি', 'চ', 'ি', 'থ', 'ি', ':', 'রব', 'ী', 'ন', '্', 'দ', '্', 'রন', 'া', 'থ', 'ঠ', 'া', 'ক', 'ু', 'র', '২৫শ', 'ে', 'ব', 'ৈ', 'শ', 'া', 'খ', '১২৬৮', 'স', 'া', 'ল', 'ে', 'প', 'ে', 'ই', 'ম', 'ে', '১৮৬১', 'খ', 'ি', 'ষ', '্', 'ট', 'া', 'ব', '্', 'দ', ')', 'কলক', 'া', 'থ', 'া', 'র', '\\\\', 'nজ', 'ো', 'ড', '়', 'া', 'স', 'ী', 'ক', 'ো', 'র', 'ঠ', 'া', 'ক', 'ু', 'র', 'পর', 'ি', 'ব', 'া', 'র', 'ে', 'জন', '্', 'য', '্', 'রহণ', 'কর', 'ে', 'ন', '।', 'থ', 'া', 'র', 'প', 'ি', 'থ', 'া', 'মহর', '্', 'ষ', 'ি', 'দ', 'ে', 'ব', 'ে', 'ন', '্', 'দ', '্', 'রন', 'া', 'থ', 'ঠ', 'া', 'ক', 'ু', 'র', 'এব', 'ং', 'প', 'ি', 'থ', 'া', 'মহ', '\\\\', 'nপ', '্', 'র', 'ি', 'ন', '্', 'স', 'দ', '্', 'ব', 'া', 'রক', 'া', 'ন', 'া', 'থ', 'ঠ', 'া', 'ক', 'ু', 'র', '।', 'ব', 'ি', 'দ', '্', 'য', 'া', 'লয', '়', 'ে', 'র', 'আন', 'ু', 'ষ', '্', 'ঠ', 'া', 'ন', 'ি', 'ক', 'শ', 'ি', 'ক', '্', 'ষ', 'া', 'থ', 'ি', 'ন', 'ি', 'ল', 'া', 'ভ', 'কর', 'ে', 'নন', 'ি', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ে', 'র', 'ব', 'ি', 'চ', 'ি', 'থ', '্', 'র', 'ক', '্', 'ষ', 'ে', 'থ', '্', 'র', 'ে', '\\\\', 'nথ', 'া', 'র', 'পদচ', 'া', 'রণ', 'া', 'এক', 'ব', 'ি', 'স', '্', 'ময', '়', 'ে', 'র', 'ব', 'ি', 'ষয', '়', '।', 'থ', 'ি', 'ন', 'ি', 'ছ', 'ি', 'ল', 'ে', 'ন', 'প', '্', 'রক', 'ৃ', 'থ', 'অর', '্', 'থ', 'ে', 'ই', 'অস', 'া', 'ম', 'া', 'ন', '্', 'য', 'প', '্', 'রথ', 'ি', 'ভ', 'া', 'ধর', 'ব', '্', 'যক', '্', 'থ', 'ি', '।', 'ব', 'া', 'ল', '্', 'যক', 'া', 'ল', 'ে', 'ই', '\\\\', 'nথ', 'ী', 'র', 'কব', 'ি', 'প', '্', 'রথ', 'ি', 'ভ', 'া', 'র', 'উন', '্', 'ম', 'ে', 'ষ', 'ঘট', 'ে', '।', 'ম', 'া', 'থ', '্', 'র', 'পন', 'ে', 'র', 'ো', 'বছর', 'বয', '়', 'স', 'ে', 'থ', 'া', 'র', 'বনফ', 'ু', 'ল', 'ক', 'া', 'ব', '্', 'য', 'প', '্', 'রক', 'া', 'শ', 'ি', 'থ', 'হয', '়', '।', '১৯১৩', 'স', 'া', 'ল', 'ে', '\\\\', 'nরব', 'ী', 'ন', '্', 'দ', '্', 'রন', 'া', 'থ', 'গ', 'ী', 'থ', 'া', 'ঞ', '্', 'জল', 'ি', 'ক', 'া', 'ব', '্', 'য', 'ে', 'র', 'জন', '্', 'য', 'এশ', 'ী', 'য', '়', 'দ', 'ে', 'র', 'মধ', '্', 'য', 'ে', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ে', 'প', '্', 'রথম', 'ন', 'ো', 'ব', 'ে', 'ল', 'প', 'ু', 'রস', '্', 'ক', 'া', 'র', 'ল', 'া', 'ভ', 'কর', 'ে', 'ন', '।', 'বস', '্', 'থ', 'ু', 'থ', '\\\\', 'nথ', 'া', 'র', 'একক', 'স', 'া', 'ধন', 'া', 'য', '়', 'ব', 'া', 'ং', 'ল', 'া', 'ভ', 'া', 'ষ', 'া', 'ও', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'সকল', 'শ', 'া', 'খ', 'া', 'য', '়', 'দ', '্', 'র', 'ু', 'থ', 'উন', '্', 'নথ', 'ি', 'ল', 'া', 'ভ', 'কর', 'ে', 'এব', 'ং', 'ব', 'ি', 'শ', '্', 'বদরব', 'া', 'র', 'ে', '\\\\', 'nগ', 'ৌ', 'রব', 'ে', 'র', 'আসন', 'ে', 'প', '্', 'রথ', 'ি', 'ষ', '্', 'ঠ', 'ি', 'থ', 'হয', '়', '।', 'থ', 'ি', 'ন', 'ি', 'এক', 'া', 'ধ', 'া', 'র', 'ে', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ি', 'ক', ',', 'দ', 'া', 'র', '্', 'শন', 'ি', 'ক', ',', 'শ', 'ি', 'ক', '্', 'ষ', 'া', 'ব', 'ি', 'দ', ',', 'স', 'ু', 'রক', 'া', 'র', ',', 'ন', 'া', 'ট', '্', 'য', '\\\\', 'nপ', '্', 'রয', 'ো', 'জক', 'ও', 'অভ', 'ি', 'ন', 'ে', 'থ', 'া', '।', 'ক', 'া', 'ব', '্', 'য', ',', 'ছ', 'ো', 'টগল', '্', 'প', ',', 'উপন', '্', 'য', 'া', 'স', ',', 'ন', 'া', 'টক', ',', 'প', '্', 'রবন', '্', 'ধ', ',', 'গ', 'া', 'ন', 'ইথ', '্', 'য', 'া', 'দ', 'ি', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', 'ে', 'র', 'সকল', 'শ', 'া', 'খ', 'া', 'ই', 'থ', 'া', 'র', '\\\\', 'nঅবদ', 'া', 'ন', 'ে', 'সম', 'ৃ', 'দ', '্', 'ধ', '।', 'থ', 'া', 'র', 'অজস', '্', 'র', 'রচন', 'া', 'র', 'মধ', '্', 'য', 'ে', 'ম', 'া', 'নস', 'ী', ',', 'স', 'ো', 'ন', 'া', 'র', 'থর', 'ী', ',', 'চ', 'ি', 'থ', '্', 'র', 'া', ',', 'কল', '্', 'পন', 'া', ',', 'ক', '্', 'ষণ', 'ি', 'ক', 'া', ',', 'বল', 'া', 'ক', 'া', ',', 'প', 'ু', 'নস', '্', 'চ', ',', '\\\\', 'nচ', 'ো', 'খ', 'ে', 'র', 'ব', 'া', 'ল', 'ি', ',', 'গ', 'ো', 'র', 'া', ',', 'ঘর', 'ে', 'ব', 'া', 'ইর', 'ে', ',', 'য', 'ো', 'গ', 'া', 'য', 'ো', 'গ', ',', 'শ', 'ে', 'ষ', 'ে', 'র', 'কব', 'ি', 'থ', 'া', ',', 'ব', 'ি', 'সজর', '্', 'ন', ',', 'ড', 'া', 'কঘর', ',', 'রক', '্', 'থকরব', 'ী', ',', 'গল', '্', 'পগচ', '্', 'ছ', ',', '\\\\', 'nব', 'ি', 'চ', 'ি', 'থ', '্', 'র', 'প', '্', 'রবন', '্', 'ধ', 'ইথ', '্', 'য', 'া', 'দ', 'ি', 'ব', 'ি', 'শ', 'ে', 'ষভ', 'া', 'ব', 'ে', 'উল', '্', 'ল', 'ে', 'খয', 'ো', 'গ', '্', 'য', '।', '২২শ', 'ে', 'শ', '্', 'র', 'া', 'বণ', '১৩৪৮', 'স', 'া', 'ল', 'ে', 'ণ', 'ে', 'ই', 'আগস', '্', 'ট', '১৯৪১', 'খরষ', '্', 'ট', 'া', 'ব', '্', 'দ', ')', '\\\\', 'nকলক', 'া', 'থ', 'া', 'য', '়', 'ব', 'ি', 'শ', '্', 'বকব', 'ি', 'রব', 'ী', 'ন', '্', 'দ', '্', 'রন', 'া', 'থ', 'ঠ', 'া', 'ক', 'ু', 'র', 'শ', 'ে', 'ষ', 'ন', 'ি', 'ঃ', 'শ', '্', 'ব', 'া', 'স', 'থ', '্', 'য', 'া', 'গ', 'কর', 'ে', 'ন', '।', ']', '\\\\', 'n', '\\\\', 'nম', 'ে', 'য', '়', 'ে', 'ট', 'ি', 'র', 'ন', 'া', 'ম', 'যখন', 'স', 'ু', 'ভ', 'া', 'ষ', 'ি', 'ণ', 'ী', 'র', 'া', 'খ', 'া', 'হইয', '়', 'া', 'ছ', 'ি', 'ল', 'থখন', 'ক', 'ে', 'জ', 'া', 'ন', 'ি', 'থ', 'স', 'ে', 'ব', 'ো', 'ব', 'া', 'হইব', 'ে', '।', 'থ', 'া', 'হ', 'া', 'র', 'দ', 'ু', 'ট', 'ি', 'বড', '়', 'ো', '\\\\', 'nব', 'ো', 'নক', 'ে', 'স', 'ু', 'ক', 'ে', 'শ', 'ি', 'ন', 'ী', 'ও', 'স', 'ু', 'হ', 'া', 'স', 'ি', 'ন', 'ী', 'ন', 'া', 'ম', 'দ', 'ে', 'ওয', '়', 'া', 'হইয', '়', 'া', 'ছ', 'ি', 'ল', ',', 'থ', 'া', 'ই', 'ম', 'ি', 'ল', 'ে', 'র', 'অন', 'ু', 'র', 'ো', 'ধ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'ব', 'া', 'প', 'ছ', 'ো', 'ট', 'ো', '\\\\', 'nম', 'ে', 'য', '়', 'ে', 'ট', 'ি', 'র', 'ন', 'া', 'ম', 'স', 'ু', 'ভ', 'া', 'ষ', 'ি', 'ণ', 'ী', 'র', 'া', 'খ', 'ে', '।', 'এখন', 'সকল', 'ে', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'স', 'ং', 'ক', '্', 'ষ', 'ে', 'প', 'ে', 'স', 'ু', 'ভ', 'া', 'বল', 'ে', '।', '\\\\', 'n', '\\\\', 'nদম', '্', 'থরমথ', 'অন', 'ু', 'সন', '্', 'ধ', 'া', 'ন', 'ও', 'অর', '্', 'থব', '্', 'যয', '়', 'ে', 'বড', '়', 'ো', 'দ', 'ু', 'ট', 'ি', 'ম', 'ে', 'য', '়', 'ে', 'র', 'ব', 'ি', 'ব', 'া', 'হ', 'হইয', '়', 'া', 'গ', 'ে', 'ছ', 'ে', ',', 'এখন', 'ছ', 'ো', 'ট', 'ো', 'ট', 'ি', 'প', 'ি', 'থ', 'া', 'ম', 'া', 'থ', 'া', 'র', '\\\\', 'nন', 'ী', 'রব', 'হ', 'ৃ', 'দয', '়', 'ভ', 'া', 'র', 'ে', 'র', 'মথ', 'ো', 'ব', 'ি', 'র', 'া', 'জ', 'কর', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', '\\\\', 'n', '\\\\', 'nয', 'ে', 'কথ', 'া', 'কয', '়', 'ন', 'া', 'স', 'ে', 'য', 'ে', 'অন', 'ু', 'ভব', 'কর', 'ে', 'ইহ', 'া', 'সকল', 'ে', 'র', 'মন', 'ে', 'হয', '়', 'ন', 'া', ',', 'এইজন', '্', 'য', 'থ', 'া', 'হ', 'া', 'র', 'স', 'া', 'ক', '্', 'ষ', 'া', 'থ', 'ে', 'ই', 'সকল', 'ে', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'ভব', 'ি', 'ষ', '্', 'যৎ', 'সমন', '্', 'ধ', 'ে', 'দ', 'ু', 'শ', '্', 'চ', 'ি', 'ন', '্', 'থ', 'া', 'প', '্', 'রক', 'া', 'শ', 'কর', 'ি', 'থ', '।', 'স', 'ে', 'য', 'ে', 'ব', 'ি', 'ধ', 'া', 'থ', 'া', 'র', 'অভ', 'ি', 'শ', 'া', 'পস', '্', 'বর', 'ূ', 'প', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'প', 'ি', 'থ', 'ৃ', 'গ', 'ৃ', 'হ', 'ে', '\\\\', 'nআস', 'ি', 'য', '়', 'া', 'জন', '্', 'যগ', '্', 'রহণ', 'কর', 'ি', 'য', '়', 'া', 'ছ', 'ে', 'এ', 'কথ', 'া', 'স', 'ে', 'শ', 'ি', 'শ', 'ু', 'ক', 'া', 'ল', 'হইথ', 'ে', 'ব', 'ু', 'ঝ', 'ি', 'য', '়', 'া', 'লইয', '়', 'া', 'ছ', 'ি', 'ল', '।', 'থ', 'া', 'হ', 'া', 'র', 'ফল', 'এই', '\\\\', 'nহইয', '়', 'া', 'ছ', 'ি', 'ল', ',', 'স', 'া', 'ধ', 'া', 'রণ', 'ে', 'র', 'দ', 'ৃ', 'ষ', '্', 'ট', 'ি', 'পথ', 'হইথ', 'ে', 'স', 'ে', 'আপন', 'া', 'ক', 'ে', 'গ', 'ো', 'পন', 'কর', 'ি', 'য', '়', 'া', 'র', 'া', 'খ', 'ি', 'থ', 'ে', 'সর', '্', 'বদ', 'া', 'ই', 'চ', 'ে', 'ষ', '্', 'ট', 'া', 'কর', 'ি', 'থ', '।', '\\\\', 'nমন', 'ে', 'কর', 'ি', 'থ', ',', 'আম', 'া', 'ক', 'ে', 'সব', 'া', 'ই', 'ভ', 'ু', 'ল', 'ি', 'ল', 'ে', 'ব', 'া', 'চ', 'ি', '।', 'ক', 'ি', 'ন', '্', 'থ', 'ু', ',', 'ব', 'ে', 'দন', 'া', 'ক', 'ি', 'ক', 'ে', 'হ', 'কখন', 'ো', 'ভ', 'ো', 'ল', 'ে', '?', 'প', 'ি', 'থ', 'া', 'ম', 'া', 'থ', 'া', 'র', 'মন', 'ে', '\\\\', 'nস', 'ে', 'সর', '্', 'বদ', 'া', 'ই', 'জ', 'া', 'গর', '্', 'ক', 'ছ', 'ি', 'ল', '।', '\\\\', 'n', '\\\\', 'nব', 'ি', 'শ', 'ে', 'ষথ', ',', 'থ', 'া', 'হ', 'া', 'র', 'ম', 'া', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'ন', 'ি', 'জ', 'ে', 'র', 'একট', 'া', 'থ', '্', 'র', 'ু', 'ট', 'ি', 'স', '্', 'বর', 'ু', 'প', 'দ', 'ে', 'খ', 'ি', 'থ', 'ে', 'ন', ';', 'ক', 'ে', 'নন', 'া', ',', 'ম', 'া', 'থ', 'া', 'প', 'ু', 'থ', '্', 'র', 'অপ', 'ে', 'ক', '্', 'ষ', 'া', 'কন', '্', 'য', 'া', 'ক', 'ে', '\\\\', 'nন', 'ি', 'জ', 'ে', 'র', 'অ', 'ং', 'শর', '্', 'প', 'ে', 'দ', 'ে', 'খ', 'ে', 'ন', '-', 'কন', '্', 'য', 'া', 'র', 'ক', 'ো', 'ন', 'ো', 'অসম', '্', 'প', 'ূ', 'র', '্', 'ণথ', 'া', 'দ', 'ে', 'খ', 'ি', 'ল', 'ে', 'স', 'ে', 'ট', 'া', 'য', 'ে', 'ন', 'ব', 'ি', 'শ', 'ে', 'ষর', 'ূ', 'প', 'ে', 'ন', 'ি', 'জ', 'ে', 'র', 'লজ', '্', 'জ', 'া', 'র', '\\\\', 'nক', 'া', 'রণ', 'বল', 'ি', 'য', '়', 'া', 'মন', 'ে', 'কর', 'ে', 'ন', '।', 'বরঞ', '্', 'চ', ',', 'কন', '্', 'য', 'া', 'র', 'প', 'ি', 'থ', 'া', 'ব', 'া', 'ণ', 'ী', 'কণ', '্', 'ঠ', 'স', 'ু', 'ভ', 'া', 'ক', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'অন', '্', 'য', 'ম', 'ে', 'য', '়', 'ে', 'দ', 'ে', 'র', '\\\\', 'nঅপ', 'ে', 'ক', '্', 'ষ', 'া', 'য', 'ে', 'ন', 'একট', 'ু', 'ব', 'ে', 'শ', 'ি', 'ভ', 'া', 'ল', 'ো', 'ব', 'া', 'স', 'ি', 'থ', 'ে', 'ন', ';', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ম', 'া', 'থ', 'া', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'ন', 'ি', 'জ', 'ে', 'র', 'গর', '্', 'ভ', 'ে', 'র', 'কলঙ', '্', 'ক', 'জ', '্', 'ঞ', 'া', 'ন', 'কর', 'ি', 'য', '়', 'া', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'প', '্', 'রথ', 'ি', 'বড', '়', 'ো', 'ব', 'ি', 'রক', '্', 'থ', 'ছ', 'ি', 'ল', 'ে', 'ন', '।', 'স', 'ু', 'ভ', 'া', 'র', 'কথ', 'া', 'ছ', 'ি', 'ল', 'ন', 'া', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থ', 'া', 'হ', 'া', 'র', 'স', 'ু', 'দ', 'ী', 'র', '্', 'ঘপল', '্', 'পবব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', 'বড', '়', 'ো', 'বড', '়', 'ো', '\\\\', 'nদ', 'ু', 'ট', 'ি', 'ক', 'া', 'ল', 'ো', 'চ', 'ো', 'খ', 'ছ', 'ি', 'ল', '-', 'এব', 'ং', 'থ', 'া', 'হ', 'া', 'র', 'ওষ', '্', 'ঠ', 'া', 'ধর', 'ভ', 'া', 'ব', 'ে', 'র', 'আভ', 'া', 'সম', 'া', 'থ', '্', 'র', 'কচ', 'ি', 'ক', 'ি', 'শলয', '়', 'ে', 'র', 'মথ', 'ো', 'ক', 'ী', 'প', 'ি', 'য', '়', 'া', 'উঠ', 'ি', 'থ', '।', '\"', ',', '\"', 'page_7', '\"', ':', '\"', '১২', 'স', 'ু', 'ভ', 'া', '\\\\', 'n', '\\\\', 'nকথ', 'া', 'য', '়', 'আমর', 'া', 'য', 'ে', 'ভ', 'া', 'ব', 'প', '্', 'রক', 'া', 'শ', 'কর', 'ি', 'স', 'ে', 'ট', 'া', 'আম', 'া', 'দ', 'ি', 'গক', 'ে', 'অন', 'ে', 'কট', 'া', 'ন', 'ি', 'জ', 'ে', 'র', 'চ', 'ে', 'ষ', '্', 'ট', 'া', 'য', '়', 'গড', '়', 'ি', 'য', '়', 'া', 'লইথ', 'ে', 'হয', '়', ',', '\\\\', 'nকথকট', 'া', 'থর', '্', 'জম', 'া', 'কর', 'া', 'র', 'মথ', 'ো', ';', 'সকল', 'সময', '়', 'ে', 'ঠ', 'ি', 'ক', 'হয', '়', 'ন', 'া', ',', 'ক', '্', 'ষমথ', 'া', 'র', 'অভ', 'া', 'ব', 'ে', 'অন', 'ে', 'ক', 'সময', '়', 'ে', 'ভ', 'ু', 'লও', '\\\\', 'nহয', '়', '।', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ক', 'া', 'ল', 'ো', 'চ', 'ো', 'খক', 'ে', 'ক', 'ি', 'ছ', 'ু', 'থর', '্', 'জম', 'া', 'কর', 'ি', 'থ', 'ে', 'হয', '়', 'ন', 'া', 'মন', 'আপন', 'ি', 'থ', 'া', 'হ', 'া', 'র', 'উপর', 'ে', 'ছ', 'া', 'য', '়', 'া', 'ফ', 'ে', 'ল', 'ে', ';', '\\\\', 'nভ', 'া', 'ব', 'আপন', 'ি', 'থ', 'া', 'হ', 'া', 'র', 'উপর', 'ে', 'কখন', 'ো', 'প', '্', 'রস', 'া', 'র', 'ি', 'থ', 'কখন', 'ো', 'ম', 'ু', 'দ', 'ি', 'থ', 'হয', '়', ';', 'কখন', 'ো', 'উজ', '্', 'জ', '্', 'বলভ', 'া', 'ব', 'ে', 'জ', 'ু', 'ল', 'ি', 'য', '়', 'া', 'উঠ', 'ে', ',', '\\\\', 'nকখন', 'ো', 'ম', '্', 'ল', 'া', 'নভ', 'া', 'ব', 'ে', 'ন', 'ি', 'ব', 'ি', 'য', '়', 'া', 'আস', 'ে', ',', '\\\\', 'n', '\\\\', 'nকখন', 'ো', 'অন', '্', 'থম', 'া', 'ন', 'চন', '্', 'দ', '্', 'র', 'ে', 'র', 'মথ', 'ো', 'অন', 'ি', 'ম', 'ে', 'ষভ', 'া', 'ব', 'ে', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', 'থ', 'া', 'ক', 'ে', ',', 'কখন', 'ো', 'দ', '্', 'র', 'ু', 'থ', 'চঞ', '্', 'চল', 'ব', 'ি', 'দ', '্', 'য', 'ু', 'থ', 'ে', 'র', 'মথ', 'ো', '\\\\', 'nদ', 'ি', 'গ', '্', 'ব', 'ি', 'দ', 'ি', 'ক', 'ে', 'ঠ', 'ি', 'কর', 'ি', 'য', '়', 'া', 'উঠ', 'ে', '।', 'ম', 'ু', 'খ', 'ে', 'র', 'ভ', 'া', 'ব', 'ব', 'ৈ', 'আজন', '্', 'মক', 'া', 'ল', 'য', 'া', 'হ', 'া', 'র', 'অন', '্', 'য', 'ভ', 'া', 'ষ', 'া', 'ন', 'া', 'ই', 'থ', 'া', 'হ', 'া', 'র', 'চ', 'ো', 'খ', 'ে', 'র', 'ভ', 'া', 'ষ', 'া', '\\\\', 'nঅস', 'ী', 'ম', 'উদ', 'া', 'র', 'এব', 'ং', 'অথলস', '্', 'পর', '্', 'শ', 'গভ', 'ী', 'র', '-', 'অন', 'ে', 'কট', 'া', 'স', '্', 'বচ', '্', 'ছ', 'আক', 'া', 'শ', 'ে', 'র', 'মথ', 'ো', ',', 'উদয', '়', 'া', 'স', '্', 'থ', 'এব', 'ং', 'ছ', 'া', 'য', '়', 'া', 'ল', 'ো', 'ক', 'ে', 'র', '\\\\', 'nন', 'ি', 'স', '্', 'থব', '্', 'ধ', 'রঙ', '্', 'গভ', 'ূ', 'ম', 'ি', '।', 'এই', 'ব', 'া', 'ক', '্', 'যহ', 'ী', 'ন', 'মন', 'ু', 'ষ', '্', 'য', 'ে', 'র', 'মধ', '্', 'য', 'ে', 'ব', 'ৃ', 'হৎ', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'র', 'মথ', 'ো', 'একট', 'া', 'ব', 'ি', 'জন', 'মহথ', '্', 'ব', 'আছ', 'ে', '।', '\\\\', 'nএইজন', '্', 'য', 'স', 'া', 'ধ', 'া', 'রণ', 'ব', 'া', 'লকব', 'া', 'ল', 'ি', 'ক', 'া', 'র', 'া', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'একপ', '্', 'রক', 'া', 'র', 'ভয', '়', 'কর', 'ি', 'থ', ',', 'থ', 'া', 'হ', 'া', 'র', 'সহ', 'ি', 'থ', 'খ', 'ে', 'ল', 'া', 'কর', 'ি', 'থ', 'ন', 'া', '।', '\\\\', 'nস', 'ে', 'ন', 'ি', 'র', '্', 'জন', 'দ', '্', 'ব', 'ি', 'প', '্', 'রহর', 'ে', 'র', 'মথ', 'ো', 'শব', '্', 'দহ', 'ী', 'ন', 'এব', 'ং', 'সঙ', '্', 'গ', 'ী', 'হ', 'ী', 'ন', '।', '\\\\', 'n', '\\\\', 'nগ', '্', 'র', 'া', 'ম', 'ে', 'র', 'ন', 'া', 'ম', 'চথ', '্', 'থ', 'ী', 'প', 'ু', 'র', '।', 'নদ', 'ী', 'ট', 'ি', 'ব', 'া', 'ং', 'ল', 'া', 'দ', 'ে', 'শ', 'ে', 'র', 'একট', 'ি', 'ছ', 'ো', 'ট', 'ো', 'নদ', 'ী', ',', 'গ', 'ৃ', 'হস', '্', 'থঘর', 'ে', 'র', 'ম', 'ে', 'য', '়', 'ে', 'ট', 'ি', 'র', 'মথ', 'ো', ',', 'বহ', 'ু', 'দ', 'ূ', 'র', '\\\\', 'nপর', '্', 'যন', '্', 'থ', 'থ', 'া', 'হ', 'া', 'র', 'প', '্', 'রস', 'া', 'র', 'নহ', 'ে', ';', 'ন', 'ি', 'রলস', 'া', 'থন', '্', 'ব', 'ী', 'নদ', 'ী', 'ট', 'ি', 'আপন', 'ক', 'ু', 'ল', 'রক', '্', 'ষ', 'া', 'কর', 'ি', 'য', '়', 'া', 'ক', 'া', 'জ', 'কর', 'ি', 'য', '়', 'া', 'য', 'া', 'য', '়', ';', 'দ', 'ু', 'ই', '\\\\', 'nধ', 'া', 'র', 'ে', 'র', 'গ', '্', 'র', 'া', 'ম', 'ে', 'র', 'সকল', 'ে', 'রই', 'সঙ', '্', 'গ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'য', 'ে', 'ন', 'একট', 'া', '-', 'ন', 'া', '-', 'একট', 'া', 'সম', '্', 'পর', '্', 'ক', 'আছ', 'ে', '।', 'দ', 'ু', 'ই', 'ধ', 'া', 'র', 'ে', 'ল', 'ো', 'ক', 'া', 'লয', '়', 'এব', 'ং', '\\\\', 'nথব', 'ু', 'চ', '্', 'ছ', 'া', 'য', '়', 'া', 'ঘন', 'উচ', '্', 'চ', 'থট', ';', 'ন', 'ি', 'ম', '্', 'নথল', 'দ', 'ি', 'য', '়', 'া', 'গ', '্', 'র', 'া', 'মলক', '্', 'ষ', '্', 'ম', 'ী', 'স', '্', 'র', 'ো', 'থস', '্', 'থ', 'ি', 'ন', 'ী', 'আথ', '্', 'মব', 'ি', 'স', '্', 'ম', 'ৃ', 'থ', 'দ', '্', 'র', 'ু', 'থ', 'পদক', '্', 'ষ', 'ে', 'প', 'ে', 'প', '্', 'রফ', 'ু', 'ল', '্', 'ল', 'হ', 'ৃ', 'দয', '়', 'ে', '\\\\', 'nআপন', 'া', 'র', 'অস', 'ং', 'খ', '্', 'য', 'কল', '্', 'য', 'া', 'ণক', 'া', 'র', '্', 'ষ', 'ে', 'চল', 'ি', 'য', '়', 'া', 'ছ', 'ে', '।', '\\\\', 'n', '\\\\', 'nব', 'া', 'ণ', 'ী', 'কণ', '্', 'ঠ', 'ে', 'র', 'ঘর', 'নদ', 'ী', 'র', 'এক', 'ে', 'ব', 'া', 'র', 'ে', 'উপর', 'ে', 'ই', '।', 'থ', 'া', 'হ', 'া', 'র', 'ব', 'া', 'খ', 'া', 'র', 'ি', 'র', 'ব', 'ে', 'ড', '়', 'া', ',', 'আটচ', 'া', 'ল', 'া', ',', 'গ', 'ো', 'য', '়', 'া', 'লঘর', ',', 'ট', 'ে', 'ক', 'ি', 'শ', 'া', 'ল', 'া', ',', '\\\\', 'nখড', '়', 'ে', 'র', 'স', '্', 'থ', 'ু', 'প', ',', 'থ', 'ে', 'থ', 'ু', 'লথল', 'া', ',', 'আম', 'ক', 'ী', 'ঠ', 'া', 'ল', 'এব', 'ং', 'কল', 'া', 'র', 'ব', 'া', 'গ', 'া', 'ন', 'ন', 'ৌ', 'ক', 'া', 'ব', 'া', 'হ', 'ী', '-', 'ম', 'া', 'থ', '্', 'র', 'ে', 'রই', 'দ', 'ৃ', 'ষ', '্', 'ট', 'ি', 'আকর', '্', 'ষণ', 'কর', 'ে', '।', '\\\\', 'nএই', 'গ', 'া', 'র', '্', 'হস', '্', 'থ', '্', 'য', 'সচ', '্', 'ছলথ', 'া', 'র', 'মধ', '্', 'য', 'ে', 'ব', 'ো', 'ব', 'া', 'ম', 'ে', 'য', '়', 'ে', 'ট', 'ি', 'ক', 'া', 'হ', 'া', 'রও', 'নজর', 'ে', 'পড', '়', 'ে', 'ক', 'ি', 'ন', 'া', 'জ', 'া', 'ন', 'ি', 'ন', 'া', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ক', 'া', 'জকর', '্', 'ম', 'ে', '\\\\', 'nযখন', 'ি', 'অবসর', 'প', 'া', 'য', '়', 'থখন', 'ি', 'স', 'ে', 'এই', 'নদ', 'ী', 'থ', 'ী', 'র', 'ে', 'আস', 'ি', 'য', '়', 'া', 'বস', 'ে', '।', '\\\\', 'n', '\\\\', 'nপ', '্', 'রক', 'ৃ', 'থ', 'ি', 'য', 'ে', 'ন', 'থ', 'া', 'হ', 'া', 'র', 'ভ', 'া', 'ষ', 'া', 'র', 'অভ', 'া', 'ব', 'প', 'ূ', 'রণ', 'কর', 'ি', 'য', '়', 'া', 'দ', 'ে', 'য', '়', '।', 'য', 'ে', 'ন', 'থ', 'া', 'হ', 'া', 'র', 'হইয', '়', 'া', 'কথ', 'া', 'কয', '়', '।', 'নদ', 'ী', 'র', 'কলধ', '্', 'বন', 'ি', ',', '\\\\', 'nআন', '্', 'দ', 'ো', 'লন', '-', 'কম', '্', 'পন', 'ে', 'র', 'সহ', 'ি', 'থ', 'এক', 'হইয', '়', 'া', 'সম', 'ু', 'দ', '্', 'র', 'ে', 'র', 'থরঙ', '্', 'গর', 'া', 'শ', 'ি', 'র', 'ন', '্', 'য', 'া', 'য', '়', 'ব', 'া', 'ল', 'ি', 'ক', 'া', 'র', 'চ', 'ি', 'রন', 'ি', 'স', '্', 'থব', '্', 'ধ', 'হ', 'ৃ', 'দয', '়', '-', '\\\\', 'nউপক', 'ূ', 'ল', 'ে', 'র', 'ন', 'ি', 'কট', 'ে', 'আস', 'ি', 'য', '়', 'া', 'ভ', 'া', 'ঙ', 'ি', 'য', '়', 'া', 'পড', '়', 'ে', '।', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'র', 'এই', 'ব', 'ি', 'ব', 'ি', 'ধ', 'শব', '্', 'দ', 'এব', 'ং', 'ব', 'ি', 'চ', 'ি', 'থ', '্', 'র', 'গথ', 'ি', ',', 'ইহ', 'া', 'ও', 'ব', 'ো', 'ব', 'া', 'র', '\\\\', 'nভ', 'া', 'ষ', 'া', '-', 'বড', '়', 'ো', 'বড', '়', 'ো', 'চক', '্', 'ষ', 'ু', 'পল', '্', 'পবব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', 'স', 'ু', 'ভ', 'া', 'র', 'য', 'ে', 'ভ', 'া', 'ষ', 'া', 'থ', 'া', 'হ', 'া', 'রই', 'একট', 'া', 'ব', 'ি', 'শ', '্', 'বব', '্', 'য', 'া', 'প', 'ী', 'ব', 'ি', 'স', '্', 'থ', 'া', 'র', ';', 'ব', 'ি', 'ল', '্', 'ল', 'ি', 'রবপ', 'ূ', 'র', '্', 'ণ', '\\\\', 'nথ', 'ৃ', 'ণভ', 'ূ', 'ম', 'ি', 'হইথ', 'ে', 'শব', '্', 'দ', 'া', 'থ', 'ী', 'থ', 'নক', '্', 'ষথ', '্', 'রল', 'ো', 'ক', 'পর', '্', 'যন', '্', 'থ', 'ক', 'ে', 'বল', 'ইঙ', '্', 'গ', 'ি', 'থ', ',', 'ভঙ', '্', 'গ', 'ি', ',', 'স', 'ং', 'গ', 'ী', 'থ', ',', 'ক', '্', 'রন', '্', 'দন', 'এব', 'ং', 'দ', 'ী', 'র', '্', 'ঘন', 'ি', 'শ', '্', 'ব', 'া', 'স', '।', '\\\\', 'n', '\\\\', 'nএব', 'ং', 'মধ', '্', 'য', 'া', '্', 'ক', 'ে', 'যখন', 'ম', 'া', 'ঝ', 'ি', 'র', 'া', 'জ', 'ে', 'ল', 'ে', 'র', 'া', 'খ', 'া', 'ইথ', 'ে', 'য', 'া', 'ইথ', ',', 'গ', 'ৃ', 'হস', '্', 'থ', 'ে', 'র', 'া', 'ঘ', 'ু', 'ম', 'া', 'ইথ', ',', 'প', 'া', 'খ', 'ি', 'র', 'া', 'ড', 'া', 'ক', 'ি', 'থ', 'ন', 'া', ',', 'খ', 'ে', 'য', '়', 'া', '-', 'ন', 'ৌ', 'ক', 'া', '\\\\', 'nকর', 'ি', 'থ', ',', 'থখন', 'ব', 'ু', 'দ', '্', 'ধ', 'মহ', 'া', 'ক', 'া', 'শ', 'ে', 'র', 'থল', 'ে', 'ক', 'ে', 'বল', 'একট', 'ি', 'ব', 'ো', 'ব', 'া', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'এব', 'ং', 'একট', 'ি', 'ব', 'ো', 'ব', 'া', 'ম', 'ে', 'য', '়', 'ে', 'ম', 'ু', 'খ', 'া', 'ম', 'ু', 'খ', 'ি', '\\\\', 'nচ', 'ু', 'প', 'কর', 'ি', 'য', '়', 'া', 'বস', 'ি', 'য', '়', 'া', 'থ', 'া', 'ক', 'ি', 'থ_', 'একজন', 'স', 'ু', 'ব', 'ি', 'স', '্', 'থ', 'ী', 'র', '্', 'ণ', 'র', 'ৌ', 'দ', '্', 'র', 'ে', ',', 'আর', '-', 'একজন', 'ক', '্', 'ষ', 'ু', 'দ', '্', 'র', 'থর', 'ু', 'চ', '্', 'ছ', 'া', 'য', '়', 'া', 'য', '়', '।', '\\\\', 'n', '\\\\', 'n২০১৮', '\"', ',', '\"', 'page_8', '\"', ':', '\"', '২০১৮', '\\\\', 'n', '\\\\', 'nম', 'া', 'ধ', '্', 'যম', 'ি', 'ক', 'ব', 'া', 'ং', 'ল', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', '১৩', '\\\\', 'n', '\\\\', 'nস', 'ু', 'ভ', 'া', 'র', 'য', 'ে', 'গ', 'ু', 'ট', 'ি', 'কথক', 'অন', '্', 'থরঙ', '্', 'গ', 'বন', '্', 'ধ', 'ু', 'র', 'দল', 'ছ', 'ি', 'ল', 'ন', 'া', 'থ', 'া', 'হ', 'া', 'নহ', 'ে', '।', 'গ', 'ো', 'য', '়', 'া', 'ল', 'ে', 'র', 'দ', 'ু', 'ট', 'ি', 'গ', 'া', 'থ', 'ী', ',', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'ন', 'া', 'ম', '\\\\', 'nসর', '্', 'বশ', 'ী', 'ও', 'প', 'া', 'ঙ', '্', 'গ', 'ু', 'ল', 'ি', '।', 'স', 'ে', 'ন', 'া', 'ম', 'ব', 'া', 'ল', 'ি', 'ক', 'া', 'র', 'ম', 'ু', 'খ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'া', 'কখন', 'ো', 'শ', 'ু', 'ন', 'ে', 'ন', 'া', 'ই', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থ', 'া', 'হ', 'া', 'র', 'পদশব', '্', 'দ', 'থ', 'া', 'হ', 'া', 'র', 'া', '\\\\', 'nচ', 'ি', 'ন', 'ি', 'থ_', 'থ', 'া', 'হ', 'া', 'র', 'কথ', 'া', 'হ', 'ী', 'ন', 'একট', 'া', 'কর', 'ু', 'ণ', 'স', 'ু', 'র', 'ছ', 'ি', 'ল', ',', 'থ', 'া', 'হ', 'া', 'র', 'মর', '্', 'ম', 'থ', 'া', 'হ', 'া', 'র', 'া', 'ভ', 'া', 'ষ', 'া', 'র', 'অপ', 'ে', 'ক', '্', 'ষ', 'া', 'সহজ', 'ে', 'ব', 'ু', 'ঝ', 'ি', 'থ', '।', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'া', 'ম', 'া', 'ন', 'ু', 'ষ', 'ে', 'র', 'অপ', 'ে', 'ক', '্', 'ষ', 'া', 'ভ', 'া', 'ল', 'ো', 'ব', 'ু', 'ঝ', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', '।', '\\\\', 'n', '\\\\', 'nস', 'ু', 'ভ', 'া', 'গ', 'ো', 'য', '়', 'া', 'ল', 'ে', 'ঢ', 'ু', 'ক', 'ি', 'য', '়', 'া', 'দ', 'ু', 'ই', 'ব', 'া', 'হ', 'ু', 'র', 'ছ', 'া', 'র', 'া', 'সর', '্', 'বশ', 'ী', 'র', 'গ', '্', 'র', 'ী', 'ব', 'া', 'ব', 'ে', 'ষ', '্', 'টন', 'কর', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'র', 'ক', 'া', 'ন', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', 'আপন', 'া', 'র', '\\\\', 'nগণ', '্', 'ডদ', 'ে', 'শ', 'ঘর', '্', 'ষণ', 'কর', 'ি', 'থ', 'এব', 'ং', 'প', 'া', 'ঙ', '্', 'গ', 'ু', 'ল', 'ি', 'স', '্', 'ি', 'প', '্', 'দ', 'ৃ', 'ষ', '্', 'ট', 'ি', 'থ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'প', '্', 'রথ', 'ি', 'ন', 'ি', 'র', 'ী', 'ক', '্', 'ষণ', 'কর', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'র', 'গ', 'া', 'চ', 'া', 'ট', 'ি', 'থ', '।', '\\\\', 'nব', 'া', 'ল', 'ি', 'ক', 'া', 'দ', 'ি', 'ন', 'ে', 'র', 'মধ', '্', 'য', 'ে', 'ন', 'ি', 'য', '়', 'ম', 'ি', 'থ', 'থ', 'ি', 'নব', 'া', 'র', 'কর', 'ি', 'য', '়', 'া', 'গ', 'ো', 'য', '়', 'া', 'লঘর', 'ে', 'য', 'া', 'ইথ', ',', 'থ', 'া', 'হ', 'া', 'ছ', 'া', 'ড', '়', 'া', 'অন', 'ি', 'য', '়', 'ম', 'ি', 'থ', 'আগমনও', '\\\\', 'nছ', 'ি', 'ল', ';', 'গ', 'ৃ', 'হ', 'ে', 'য', 'ে', 'দ', 'ি', 'ন', 'ক', 'ো', 'ন', 'ো', 'কঠ', 'ি', 'ন', 'কথ', 'া', 'শ', 'ু', 'ন', 'ি', 'থ', 'স', 'ে', 'দ', 'ি', 'ন', 'স', 'ে', 'অসময', '়', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'এই', 'ম', 'ু', 'ক', 'বন', '্', 'ধ', 'ু', 'দ', 'ু', 'ট', 'ি', 'র', 'ক', 'া', 'ছ', 'ে', '\\\\', 'nআস', 'ি', 'থ', '-', 'থ', 'া', 'হ', 'া', 'র', 'সহ', 'ি', 'ষ', '্', 'ক', 'ু', 'থ', 'া', 'পর', 'ি', 'প', 'ূ', 'র', '্', 'ণ', 'ব', 'ি', 'ষ', 'া', 'দশ', 'া', 'স', '্', 'থ', 'দ', 'ৃ', 'ষ', '্', 'ট', 'ি', 'প', 'া', 'থ', 'হইথ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'া', 'ক', 'ী', '-', 'একট', 'া', 'অন', '্', 'ধ', 'অন', 'ু', 'ম', 'া', 'নশক', '্', 'থ', 'ি', 'র', '\\\\', 'nদ', '্', 'ব', 'া', 'র', 'া', 'ব', 'া', 'ল', 'ি', 'ক', 'া', 'র', 'মর', '্', 'মব', 'ে', 'দন', 'া', 'য', 'ে', 'ন', 'ব', 'ু', 'ঝ', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', ',', 'এব', 'ং', 'স', 'ু', 'ভ', 'া', 'র', 'গ', 'া', 'ঘ', 'ে', 'ঁ', 'ষ', 'ি', 'য', '়', 'া', 'আস', 'ি', 'য', '়', 'া', 'অল', '্', 'প', 'ে', 'অল', '্', 'প', 'ে', 'থ', 'া', 'হ', 'া', 'র', '\\\\', 'nব', 'া', 'হ', 'ু', 'থ', 'ে', 'শ', 'ি', 'ং', 'ঘষ', 'ি', 'য', '়', 'া', 'ঘষ', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'ন', 'ি', 'র', '্', 'ব', 'া', 'ক', 'ব', '্', 'য', 'া', 'ক', 'ু', 'লথ', 'া', 'র', 'সহ', 'ি', 'থ', 'স', 'া', 'ন', '্', 'থ', '্', 'বন', 'া', 'দ', 'ি', 'থ', 'ে', 'চ', 'ে', 'ষ', '্', 'ট', 'া', 'কর', 'ি', 'থ', '।', '\\\\', 'n', '\\\\', 'nইহ', 'া', 'র', 'া', 'ছ', 'া', 'ড', '়', 'া', 'ছ', 'া', 'গল', 'এব', 'ং', 'ব', 'ি', 'ড', '়', 'া', 'লশ', 'া', 'বকও', 'ছ', 'ি', 'ল', ';', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'সহ', 'ি', 'থ', 'স', 'ু', 'ভ', 'া', 'র', 'এর', 'ূ', 'প', 'সমকক', '্', 'ষভ', 'া', 'ব', 'ে', 'ম', 'ৈ', 'থ', '্', 'র', 'ী', '\\\\', 'nছ', 'ি', 'ল', 'ন', 'া', ',', 'থথ', 'া', 'প', 'ি', 'থ', 'া', 'হ', 'া', 'র', 'া', 'যথ', 'ে', 'ষ', '্', 'ট', 'আন', 'ু', 'গথ', '্', 'য', 'প', '্', 'রক', 'া', 'শ', 'কর', 'ি', 'থ', '।', 'ব', 'ি', 'ড', '়', 'া', 'লশ', 'ি', 'শ', 'ু', 'ট', 'ি', 'দ', 'ি', 'ন', 'ে', 'এব', 'ং', 'র', 'া', 'থ', '্', 'র', 'ে', 'যখন', '-', '\\\\', 'nথখন', 'স', 'ু', 'ভ', 'া', 'র', 'গরম', 'ক', 'ো', 'লট', 'ি', 'ন', 'ি', 'ঃ', 'স', 'ং', 'ক', 'ো', 'চ', 'ে', 'অধ', 'ি', 'ক', 'া', 'র', 'কর', 'ি', 'য', '়', 'া', 'স', 'ু', 'খন', 'ি', 'দ', '্', 'র', 'া', 'র', 'আয', '়', 'ো', 'জন', 'কর', 'ি', 'থ', 'এব', 'ং', 'স', 'ু', 'ভ', 'া', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'গ', '্', 'র', 'ী', 'ব', 'া', 'ও', 'প', 'ৃ', 'ষ', '্', 'ঠ', 'ে', 'ক', 'ো', 'মল', 'আঙ', '্', 'গ', 'ু', 'ল', 'ি', 'ব', 'ু', 'ল', 'া', 'ইয', '়', 'া', 'দ', 'ি', 'ল', 'ে', 'য', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'ন', 'ি', 'দ', '্', 'ব', 'া', 'কর', '্', 'ষণ', 'ে', 'র', 'ব', 'ি', 'শ', 'ে', 'ষ', 'সহ', 'া', 'য', '়', 'থ', 'া', 'হয', '়', ',', '\\\\', 'nইঙ', '্', 'গ', 'ি', 'থ', 'ে', 'এর', 'ু', 'প', 'অভ', 'ি', 'প', '্', 'র', 'া', 'য', '়', 'ও', 'প', '্', 'রক', 'া', 'শ', 'কর', 'ি', 'থ', '।', '\\\\', 'n', '\\\\', 'nউন', '্', 'নথ', 'শ', '্', 'র', 'ে', 'ণ', 'ি', 'র', 'জ', 'ী', 'ব', 'ে', 'র', 'মধ', '্', 'য', 'ে', 'স', 'ু', 'ভ', 'া', 'র', 'আর', 'ো', 'একট', 'ি', 'সঙ', '্', 'গ', 'ী', 'জ', 'ু', 'ট', 'ি', 'য', '়', 'া', 'ছ', 'ি', 'ল', '।', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থ', 'া', 'হ', 'া', 'র', 'সহ', 'ি', 'থ', 'ব', 'া', 'ল', 'ি', 'ক', 'া', 'র', 'ঠ', 'ি', 'ক', '\\\\', 'nক', 'ি', 'র', 'ূ', 'প', 'সম', '্', 'পর', '্', 'ক', 'ছ', 'ি', 'ল', 'থ', 'া', 'হ', 'া', 'ন', 'ি', 'র', '্', 'ণয', '়', 'কর', 'া', 'কঠ', 'ি', 'ন', ',', 'ক', 'া', 'রণ', ',', 'স', 'ে', 'ভ', 'া', 'ষ', 'া', 'ব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', 'জ', 'ী', 'ব', ';', 'স', 'ু', 'থর', 'া', 'ং', 'উভয', '়', 'ে', 'র', 'মধ', '্', 'য', 'ে', '\\\\', 'nসমভ', 'া', 'ষ', 'া', 'ছ', 'ি', 'ল', 'ন', 'া', '।', '\\\\', 'n', '\\\\', 'nগ', 'ৌ', 'স', 'া', 'ইদ', 'ে', 'র', 'ছ', 'ো', 'ট', 'ো', 'ছ', 'ে', 'ল', 'ে', 'ট', 'ি', '-', 'থ', 'া', 'হ', 'া', 'র', 'ন', 'া', 'ম', 'প', '্', 'রথ', 'া', 'প', '|', 'ল', 'ো', 'কট', 'ি', 'ন', 'ি', 'থ', 'া', 'ন', '্', 'থ', 'অকর', '্', 'মণ', '্', 'য', '।', 'স', 'ে', 'য', 'ে', 'ক', 'া', 'জকর', '্', 'ম', 'কর', 'ি', 'য', '়', 'া', '\\\\', 'nস', 'ং', 'স', 'া', 'র', 'ে', 'র', 'উন', '্', 'নথ', 'ি', 'কর', 'ি', 'থ', 'ে', 'যথ', '্', 'ব', 'ু', 'কর', 'ি', 'ব', 'ে', 'বহ', 'ু', 'চ', 'ে', 'ষ', '্', 'ট', 'া', 'র', 'পর', 'ব', 'া', 'প', '-', 'ম', 'া', 'স', 'ে', 'আশ', 'া', 'থ', '্', 'য', 'া', 'গ', 'কর', 'ি', 'য', '়', 'া', 'ছ', 'ে', 'ন', '।', 'অকর', '্', 'মণ', '্', 'য', '\\\\', 'nল', 'ো', 'ক', 'ে', 'র', 'একট', 'া', 'স', 'ু', 'ব', 'ি', 'ধ', 'া', 'এই', 'য', 'ে', ',', 'আথ', '্', 'ম', 'ী', 'য', '়', 'ল', 'ো', 'ক', 'ে', 'র', 'া', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'উপর', 'ে', 'ব', 'ি', 'রক', '্', 'থ', 'হয', '়', 'বট', 'ে', ',', 'ক', 'ি', 'ন', '্', 'থ', 'প', '্', 'র', 'া', 'য', '়', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'া', 'ন', 'ি', 'ঃ', 'সম', '্', 'পর', '্', 'ক', 'ল', 'ো', 'কদ', 'ে', 'র', 'প', '্', 'র', 'ি', 'য', '়', 'প', 'া', 'থ', '্', 'র', 'হয', '়', '-', 'ক', 'া', 'রণ', ',', 'ক', 'ো', 'ন', 'ো', 'ক', 'া', 'র', '্', 'ষ', 'ে', 'আবন', '্', 'ধ', 'ন', 'া', 'থ', 'া', 'ক', 'া', 'থ', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'া', 'সরক', 'া', 'র', 'ি', '\\\\', 'nসম', '্', 'পথ', '্', 'থ', 'ি', 'হইয', '়', 'া', 'দ', 'া', 'ঁ', 'ড', '়', 'া', 'য', '়', '।', 'শহর', 'ে', 'র', 'য', 'ে', 'মন', 'এক', '-', 'আধট', 'া', 'গ', 'ৃ', 'হসম', '্', 'পর', '্', 'কহ', 'ী', 'ন', 'সরক', 'া', 'র', 'ি', 'ব', 'া', 'গ', 'া', 'ন', 'থ', 'া', 'ক', 'া', 'আবশ', '্', 'যক', '\\\\', 'nথ', 'ে', 'মন', 'ি', 'গ', '্', 'র', 'া', 'ম', 'ে', 'দ', 'ু', 'ই', '-', 'চ', 'া', 'র', 'ি', 'ট', 'া', 'অকর', '্', 'মণ', '্', 'য', 'সরক', 'া', 'র', 'ি', 'ল', 'ো', 'ক', 'থ', 'া', 'ক', 'া', 'র', 'ব', 'ি', 'শ', 'ে', 'ষ', 'প', '্', 'রয', '়', 'ো', 'জন', '।', 'ক', 'া', 'জ', 'ে', '-', 'কর', '্', 'ম', 'ে', 'আম', 'ো', 'দ', 'ে', '-', '\\\\', 'nঅবসর', 'ে', 'য', 'ে', 'খ', 'া', 'ন', 'ে', 'একট', 'া', 'ল', 'ো', 'ক', 'কম', 'পড', '়', 'ে', 'স', 'ে', 'খ', 'া', 'ন', 'ে', 'ই', 'থ', 'া', 'হ', 'া', 'দ', 'ি', 'গক', 'ে', 'হ', 'া', 'থ', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', 'প', 'া', 'ওয', '়', 'া', 'য', 'া', 'য', '়', '।', '\\\\', 'n', '\\\\', 'nপ', '্', 'রথ', 'া', 'প', 'ে', 'র', 'প', '্', 'রধ', 'া', 'ন', 'শখ', '-', 'ছ', 'ি', 'প', 'ফ', 'ে', 'ল', 'ি', 'য', '়', 'া', 'ম', 'া', 'ছ', 'ধর', 'া', '।', 'ইহ', 'া', 'থ', 'ে', 'অন', 'ে', 'ক', 'সময', '়', 'সহজ', 'ে', 'ক', 'া', 'ট', 'া', 'ন', 'ো', 'য', 'া', 'য', '়', '।', 'অপর', 'া', 'হ', '্', 'র', 'ে', '\\\\', 'nনদ', 'ী', 'থ', 'ী', 'র', 'ে', 'ইহ', 'া', 'ক', 'ে', 'প', '্', 'র', 'া', 'য', '়', 'এই', 'ক', 'া', 'জ', 'ে', 'ন', 'ি', 'য', 'ু', 'ক', '্', 'থ', 'দ', 'ে', 'খ', 'া', 'য', 'া', 'ইথ', '|', 'এব', 'ং', 'এই', 'উপলক', '্', 'ষ', 'ে', 'স', 'ু', 'ভ', 'া', 'র', 'সহ', 'ি', 'থ', 'থ', 'া', 'হ', 'া', 'র', 'প', '্', 'র', 'া', 'য', '়', '\\\\', 'nস', 'া', 'ক', '্', 'ষ', 'া', 'ৎ', 'হইথ', '।', 'য', 'ে', '-', 'ক', 'ো', 'ন', 'ো', 'ক', 'া', 'জ', 'ে', 'ই', 'ন', 'ি', 'য', 'ু', 'ক', '্', 'থ', 'থ', 'া', 'ক', ',', 'একট', 'া', 'সঙ', '্', 'গ', 'ী', 'প', 'া', 'ইল', 'ে', 'প', '্', 'রথ', 'া', 'প', 'থ', 'া', 'ক', 'ে', 'ভ', 'া', 'ল', 'ো', '।', 'ম', 'া', 'ছ', '\\\\', 'nধর', 'া', 'র', 'সময', '়', 'ব', 'া', 'ক', '্', 'যহ', 'ী', 'ন', 'সঙ', '্', 'গ', 'ী', 'ই', 'সর', '্', 'ব', 'া', 'প', 'ে', 'ক', '্', 'ষ', 'া', 'শ', '্', 'র', 'ে', 'ষ', '্', 'ঠ', '-', 'এইজন', '্', 'য', 'প', '্', 'রথ', 'া', 'প', 'স', 'ু', 'ভ', 'া', 'র', 'মর', '্', 'য', 'া', 'দ', 'া', 'ব', 'ৃ', 'ঝ', 'ি', 'থ', '।', 'এইজন', '্', 'য', 'সকল', 'ে', 'ই', '\\\\', 'nস', 'ু', 'ভ', 'া', 'ক', 'ে', 'স', 'ু', 'ভ', 'া', 'বল', 'ি', 'থ', ',', 'প', '্', 'রথ', 'া', 'প', 'আর', '-', 'একট', 'ু', 'অথ', 'ি', 'র', 'ি', 'ক', '্', 'থ', 'আদর', 'স', 'ং', 'য', 'ো', 'গ', 'কর', 'ি', 'য', '়', 'া', 'স', 'ু', 'ভ', 'া', 'ক', 'ে', '“', 'স', 'ু', '*', 'বল', 'ি', 'য', '়', 'া', 'ড', 'া', 'ক', 'ি', 'থ', '।', '\"', ',', '\"', 'page_9', '\"', ':', '\"', '১৪', 'স', 'ু', 'ভ', 'া', '\\\\', 'n', '\\\\', 'nস', 'ু', 'ভ', 'া', 'থ', 'ে', 'থ', 'ু', 'লথল', 'া', 'য', '়', 'বস', 'ি', 'য', '়', 'া', 'থ', 'া', 'ক', 'ি', 'থ', 'এব', 'ং', 'প', '্', 'রথ', 'া', 'প', 'অনথ', 'ি', 'দ', 'ূ', 'র', 'ে', 'ছ', 'ি', 'প', 'ফ', 'ে', 'ল', 'ি', 'য', '়', 'া', 'জল', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', '\\\\', 'nথ', 'া', 'ক', 'ি', 'থ', '।', 'প', '্', 'রথ', 'া', 'প', 'ে', 'র', 'জন', '্', 'য', 'একট', 'ি', 'কর', 'ি', 'য', '়', 'া', 'প', 'া', 'ন', 'বর', 'া', 'দ', '্', 'দ', 'ছ', 'ি', 'ল', ',', 'স', 'ু', 'ভ', 'া', 'থ', 'া', 'হ', 'া', 'ন', 'ি', 'জ', 'ে', 'স', 'া', 'জ', 'ি', 'য', '়', 'া', 'আন', 'ি', 'থ', '।', 'এব', 'ং', '\\\\', 'nব', 'ো', 'ধ', 'কর', 'ি', 'অন', 'ে', 'কক', '্', 'ষণ', 'বস', 'ি', 'য', '়', 'া', 'বস', 'ি', 'য', '়', 'া', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', 'ইচ', '্', 'ছ', 'া', 'কর', 'ি', 'থ', ',', 'প', '্', 'রথ', 'া', 'প', 'ে', 'র', 'ক', 'ো', 'ন', 'ো', '-', 'একট', 'া', 'ব', 'ি', 'শ', 'ে', 'ষ', 'স', 'া', 'হ', 'া', 'য', '্', 'য', '\\\\', 'nকর', 'ি', 'থ', 'ে', ',', 'একট', 'া', '-', 'ক', 'ো', 'ন', 'ো', 'ক', 'া', 'জ', 'ে', 'ল', 'া', 'গ', 'ি', 'থ', 'ে', ',', 'ক', 'ো', 'ন', 'ো', 'মথ', 'ে', 'জ', 'া', 'ন', 'া', 'ইয', '়', 'া', 'দ', 'ি', 'থ', 'ে', 'য', 'ে', 'এই', 'প', 'ৃ', 'থ', 'ি', 'ব', 'ী', 'থ', 'ে', 'স', 'ে', 'ও', 'একজন', '\\\\', 'nকম', 'প', '্', 'রয', '়', 'ো', 'জন', 'ী', 'য', '়', 'ল', 'ো', 'ক', 'নহ', 'ে', '।', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'ক', 'ি', 'ছ', 'ু', 'ই', 'কর', 'ি', 'ব', 'া', 'র', 'ছ', 'ি', 'ল', 'ন', 'া', '।', 'থখন', 'স', 'ে', 'মন', 'ে', 'মন', 'ে', 'ব', 'ি', 'ধ', 'া', 'থ', 'া', 'র', 'ক', 'া', 'ছ', 'ে', '\\\\', 'nঅল', 'ৌ', 'ক', 'ি', 'ক', 'ক', '্', 'ষমথ', 'া', 'প', '্', 'র', 'া', 'র', '্', 'থন', 'া', 'কর', 'ি', 'থ', '-', 'মন', '্', 'থ', '্', 'রবল', 'ে', 'সহস', 'া', 'এমন', 'একট', 'া', 'আশ', '্', 'চর', '্', 'য', 'ক', 'া', 'ণ', '্', 'ড', 'ঘট', 'া', 'ইথ', 'ে', 'ইচ', '্', 'ছ', 'া', 'কর', 'ি', 'থ', '\\\\', 'nয', 'া', 'হ', 'া', 'দ', 'ে', 'খ', 'ি', 'য', '়', 'া', 'প', '্', 'রথ', 'া', 'প', 'আশ', '্', 'চর', '্', 'য', 'হইয', '়', 'া', 'য', 'া', 'ইথ', ',', 'বল', 'ি', 'থ', ',', '“', 'থ', 'া', 'ই', 'থ', 'ো', ',', 'আম', 'া', 'দ', 'ে', 'র', 'স', 'ু', 'ভ', 'ি', 'র', 'য', 'ে', 'এথ', 'ক', '্', 'ষমথ', 'া', 'থ', 'া', 'হ', 'া', '\\\\', 'nথ', 'ো', 'জ', 'া', 'ন', 'ি', 'থ', 'া', 'ম', 'ন', 'া', '।', \"'\", '\\\\', 'n', '\\\\', 'nমন', 'ে', 'কর', 'ো', ',', 'সভ', 'া', 'যদ', 'ি', 'জলক', 'ু', 'ম', 'া', 'র', 'ী', 'হইথ', ',', 'আস', '্', 'থ', 'ে', 'আস', '্', 'থ', 'ে', 'জল', 'হইথ', 'ে', 'উঠ', 'ি', 'য', '়', 'া', 'একট', 'া', 'স', 'া', 'প', 'ে', 'র', 'ম', 'া', 'থ', 'া', 'র', 'মণ', 'ি', 'ঘ', 'া', 'ট', 'ে', '\\\\', 'nর', 'া', 'খ', 'ি', 'য', '়', 'া', 'য', 'া', 'ইথ', ';', 'প', '্', 'রথ', 'া', 'প', 'থ', 'া', 'হ', 'া', 'র', 'থ', 'ু', 'চ', '্', 'ছ', 'ম', 'া', 'ছ', 'ধর', 'া', 'র', 'া', 'খ', 'ি', 'য', '়', 'া', 'স', 'ে', 'ই', 'ম', 'া', 'ন', 'ি', 'ক', 'লইয', '়', 'া', 'জল', 'ে', 'ড', 'ু', 'ব', 'ম', 'া', 'র', 'ি', 'থ', ';', 'এব', 'ং', 'প', 'া', 'থ', 'া', 'ল', 'ে', '\\\\', 'nগ', 'ি', 'য', '়', 'া', 'দ', 'ে', 'খ', 'ি', 'থ', ',', 'র', 'ূ', 'প', 'া', 'র', 'অট', '্', 'ট', 'া', 'ল', 'ি', 'ক', 'া', 'য', '়', 'স', 'ো', 'ন', 'া', 'র', 'প', 'া', 'লক', '্', 'ক', 'ে', '-', 'ক', 'ে', 'বস', 'ি', 'য', '়', 'া', '?', '_', 'আম', 'া', 'দ', 'ে', 'র', 'ব', 'া', 'ণ', 'ী', 'কষ', '্', 'ঠ', 'ে', 'র', 'ঘর', 'ে', 'র', 'স', 'ে', 'ই', 'ব', 'ো', 'ব', 'া', '\\\\', 'nম', 'ে', 'য', '়', 'ে', 'স', 'ু', '-', 'আম', 'া', 'দ', 'ে', 'র', 'স', 'ু', 'স', 'ে', 'ই', 'মণ', 'ি', 'দ', 'ী', 'প', '্', 'থ', 'গভ', 'ী', 'র', 'ন', 'ি', 'স', '্', 'থব', '্', 'ধ', 'প', 'া', 'থ', 'া', 'লপ', 'ু', 'র', 'ী', 'র', 'একম', 'া', 'থ', '্', 'র', 'র', 'া', 'জকন', '্', 'য', 'া', '।', 'থ', 'া', 'হ', 'া', 'ক', 'ি', 'হইথ', 'ে', '\\\\', 'nপ', 'া', 'র', 'ি', 'থ', 'ন', 'া', '।', 'থ', 'া', 'হ', 'া', 'ক', 'ি', 'এথই', 'অসম', '্', 'ভব', '।', 'আসল', 'ে', 'ক', 'ি', 'ছ', 'ু', 'ই', 'অসম', '্', 'ভব', 'নয', '়', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থব', 'ু', 'ও', 'স', 'ু', 'প', '্', 'রজ', 'া', 'শ', 'ূ', 'ন', '্', 'য', 'প', 'া', 'থ', 'া', 'ল', 'ে', 'র', '\\\\', 'nর', 'া', 'জব', 'ং', 'শ', 'ে', 'ন', 'া', 'জননয', '়', 'া', 'ব', 'া', 'ণ', 'ী', 'কণ', '্', 'ঠ', 'ে', 'র', 'ঘর', 'ে', 'আস', 'ি', 'য', '়', 'া', 'জন', '্', 'ন', 'ি', 'য', '়', 'া', 'ছ', 'ে', 'এব', 'ং', 'গ', 'ো', 'স', 'া', 'ইদ', 'ে', 'র', 'ছ', 'ে', 'ল', 'ে', 'প', '্', 'রথ', 'া', 'পক', 'ে', 'ক', 'ি', 'ছ', 'ু', 'থ', 'ে', 'ই', '\\\\', 'nআশ', '্', 'চর', '্', 'য', 'কর', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', 'ে', 'ছ', 'ে', 'ন', 'া', '।', '\\\\', 'n', '\\\\', 'nস', 'ু', 'ভ', 'া', 'র', 'বয', '়', 'স', 'ক', '্', 'রম', 'ে', 'ই', 'ব', 'া', 'ড', '়', 'ি', 'য', '়', 'া', 'উঠ', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', 'ক', '্', 'রম', 'ে', 'স', 'ে', 'য', 'ে', 'ন', 'আপন', 'া', 'ক', 'ে', 'আপন', 'ি', 'অন', 'ু', 'ভব', 'কর', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', '\\\\', 'nয', 'ে', 'ন', 'ক', 'ো', 'ন', 'ো', 'একট', 'া', 'প', 'ূ', 'র', '্', 'ণ', 'ি', 'ম', 'া', 'থ', 'ি', 'থ', 'ি', 'থ', 'ে', 'ক', 'ো', 'ন', 'ো', '-', 'একট', 'া', 'সম', 'ু', 'দ', '্', 'ব', 'হইথ', 'ে', 'একট', 'া', 'জ', 'ো', 'য', '়', 'া', 'র', 'ে', 'র', 'প', '্', 'র', 'ো', 'থ', 'আস', 'ি', 'য', '়', 'া', '\\\\', 'nথ', 'া', 'হ', 'া', 'র', 'অন', '্', 'থ', '-', 'র', 'া', 'আ', '্', 'ম', 'া', 'ক', 'ে', 'এক', 'ন', 'ৃ', 'থন', 'অন', 'ি', 'র', '্', 'বচন', 'ী', 'য', '়', 'চ', 'ে', 'থন', 'া', 'শক', '্', 'থ', 'ি', 'থ', 'ে', 'পর', 'ি', 'প', 'ূ', 'র', '্', 'ণ', 'কর', 'ি', 'য', '়', 'া', 'থ', 'ু', 'ল', 'ি', 'থ', 'ে', 'ছ', 'ে', '।', 'স', 'ে', 'আপন', 'া', 'ক', 'ে', '\\\\', 'nআপন', 'ি', 'দ', 'ে', 'খ', 'ি', 'থ', 'ে', 'ছ', 'ে', ',', 'ভ', 'া', 'ব', 'ি', 'থ', 'ে', 'ছ', 'ে', ',', 'প', '্', 'রশ', '্', 'ন', 'কর', 'ি', 'থ', 'ে', 'ছ', 'ে', ',', 'এব', 'ং', 'ব', 'ু', 'ঝ', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', 'ে', 'ছ', 'ে', 'ন', 'া', '।', '\\\\', 'n', '\\\\', 'nগভ', 'ী', 'র', 'প', 'ূ', 'র', '্', 'ণ', 'ি', 'ম', 'া', 'র', 'া', 'থ', '্', 'র', 'ে', 'স', 'ে', 'এক', '-', 'একদ', 'ি', 'ন', 'ধ', 'ী', 'র', 'ে', 'শয', '়', 'নগ', 'ৃ', 'হ', 'ে', 'র', 'দ', '্', 'ব', 'া', 'র', 'খ', 'ু', 'ল', 'ি', 'য', '়', 'া', 'ভয', '়', 'ে', 'ভয', '়', 'ে', 'ম', 'ু', 'খ', 'ব', 'া', 'ড', '়', 'া', 'ইয', '়', 'া', 'ব', 'া', 'হ', 'ি', 'র', 'ে', 'র', '\\\\', 'nদ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', 'দ', 'ে', 'খ', 'ে', 'প', 'ূ', 'র', '্', 'ণ', 'ি', 'ম', 'া', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'ও', 'স', 'ু', 'ভ', 'া', 'র', 'মথ', 'ো', 'এক', 'া', 'ক', 'ি', 'ন', 'ী', 'স', 'ু', 'প', '্', 'থ', 'জগথ', 'ে', 'র', 'উপর', 'জ', 'া', 'গ', 'ি', 'য', '়', 'া', 'বস', 'ি', 'য', '়', 'া', '-', '\\\\', 'nয', 'ৌ', 'বন', 'ে', 'র', 'রহস', '্', 'য', 'ে', 'প', 'ু', 'লক', 'ে', 'ব', 'ি', 'ষ', 'া', 'দ', 'ে', 'অস', 'ী', 'ম', 'ন', 'ি', 'র', '্', 'জনথ', 'া', 'র', 'এক', 'ে', 'ব', 'া', 'র', 'ে', 'শ', 'ে', 'ষ', 'স', 'ী', 'ম', 'া', 'পর', '্', 'যন', '্', 'থ', ',', 'এমন', '-', 'ক', 'ি', ',', 'থ', 'া', 'হ', 'া', '\\\\', 'nঅথ', 'ি', 'ক', '্', 'রম', 'কর', 'ি', 'য', '়', 'া', 'ও', 'ধম', '্', 'থম', '্', 'কর', 'ি', 'থ', 'ে', 'ছ', 'ে', ',', 'একট', 'ি', 'কথ', 'া', 'কহ', 'ি', 'থ', 'ে', 'প', 'া', 'র', 'ি', 'থ', 'ে', 'ছ', 'ে', 'ন', 'া', '।', 'এই', 'ন', 'ি', 'স', '্', 'থব', '্', 'ধ', 'ব', '্', 'য', 'া', 'ক', 'ু', 'ল', '\\\\', 'nপ', '্', 'রক', 'ৃ', 'থ', 'ি', 'র', 'প', '্', 'র', 'া', 'ন', '্', 'থ', 'ে', 'একট', 'ি', 'ন', 'ি', 'স', '্', 'থব', '্', 'ধ', 'ব', '্', 'য', 'া', 'ক', 'ু', 'ল', 'ব', 'া', 'ল', 'ি', 'ক', 'া', 'দ', 'া', 'ঁ', 'ড', '়', 'া', 'ইয', '়', 'া', '।', '\\\\', 'n', '\\\\', 'nএদ', 'ি', 'ক', 'ে', 'কন', '্', 'য', 'া', 'ভ', 'া', 'রগ', '্', 'রস', '্', 'থ', 'প', 'ি', 'থ', 'া', 'ম', 'া', 'থ', 'া', 'চ', 'ি', 'ন', '্', 'থ', 'ি', 'থ', 'হইয', '়', 'া', 'উঠ', 'ি', 'য', '়', 'া', 'ছ', 'ে', 'ন', '।', 'ল', 'ো', 'ক', 'ে', 'ও', 'ন', 'ি', 'ন', '্', 'দ', 'া', 'আরম', '্', 'ভ', 'কর', 'ি', 'য', '়', 'া', 'ছ', 'ে', '।', 'এমন', '-', 'ক', 'ি', ',', '\\\\', 'nএক', '-', 'ঘর', 'ে', 'কর', 'ি', 'ব', 'ে', 'এমন', 'জনরবও', 'শ', 'ু', 'ন', 'া', 'য', 'া', 'য', '়', '।', 'ব', 'া', 'ণ', 'ী', 'কষ', '্', 'ঠ', 'ে', 'র', 'সচ', '্', 'ছল', 'অবস', '্', 'থ', 'া', ',', 'দ', 'ু', 'ই', 'ব', 'ে', 'ল', 'া', 'ই', 'ম', 'া', 'ছভ', 'া', 'থ', 'খ', 'া', 'য', '়', ',', '\\\\', 'nএজন', '্', 'য', 'থ', 'া', 'হ', 'া', 'র', 'শথ', '্', 'র', 'ু', 'ছ', 'ি', 'ল', '।', '\\\\', 'n', '\\\\', 'n', '্', 'থ', '্', 'র', 'ী', 'প', 'ু', 'র', 'ু', 'ষ', 'ে', 'ব', 'ি', 'স', '্', 'থর', 'পর', 'া', 'মর', '্', 'শ', 'হইল', '।', 'ক', 'ি', 'ছ', 'ু', 'দ', 'ি', 'ন', 'ে', 'র', 'মথ', 'ো', 'ব', 'া', 'ণ', 'ী', 'ব', 'ি', 'দ', 'ে', 'শ', 'ে', 'গ', 'ে', 'ল', '।', '\\\\', 'n', '\\\\', 'n২০১৮', '\"', ',', '\"', 'page_10', '\"', ':', '\"', '২০১৮', '\\\\', 'n', '\\\\', 'nম', 'া', 'ধ', '্', 'যম', 'ি', 'ক', 'ব', 'া', 'ং', 'ল', 'া', 'স', 'া', 'হ', 'ি', 'থ', '্', 'য', '১৫', '\\\\', 'n', '\\\\', 'nব', 'ি', 'দ', 'ে', 'শয', 'া', 'থ', '্', 'র', 'া', 'র', 'উদ', '্', 'য', 'ো', 'গ', 'হইথ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'ক', 'ু', 'য', '়', 'া', 'শ', 'া', '-', 'ঢ', 'া', 'ক', 'া', 'প', '্', 'রভ', 'া', 'থ', 'ে', 'র', 'মথ', 'ো', 'স', 'ু', 'ভ', 'া', 'র', 'সমস', '্', 'থ', 'হ', 'ৃ', 'দয', '়', 'অশ', '্', 'র', 'ু', 'ব', 'া', 'ষ', '্', 'প', 'ে', '\\\\', 'nএক', 'ে', 'ব', 'া', 'র', 'ে', 'ভর', 'ি', 'য', '়', 'া', 'গ', 'ে', 'ল', '।', 'একট', 'া', 'অন', 'ি', 'র', '্', 'দ', 'ি', 'ষ', '্', 'ট', 'আশঙ', '্', 'ক', 'া', '-', 'বশ', 'ে', 'স', 'ে', 'ক', 'ি', 'ছ', 'ু', 'দ', 'ি', 'ন', 'হইথ', 'ে', 'ক', '্', 'রম', 'া', 'গথ', 'ন', 'ি', 'র', '্', 'ব', 'া', 'ক', '্', 'জন', '্', 'থর', '\\\\', 'nমথ', 'ো', 'থ', 'া', 'হ', 'া', 'র', 'ব', 'া', 'প', '-', 'ম', 'া', 'য', '়', 'ে', 'র', 'সঙ', '্', 'গ', 'ে', 'সঙ', '্', 'গ', 'ে', 'ফ', 'ি', 'র', 'ি', 'থ', '-', 'ড', 'া', 'গর', 'চক', '্', 'ষ', 'ু', 'ম', 'ে', 'ল', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'ম', 'ু', 'খ', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', '\\\\', 'nক', 'ী', '-', 'একট', 'া', 'ব', 'ু', 'ঝ', 'ি', 'থ', 'ে', 'চ', 'ে', 'ষ', '্', 'ট', 'া', 'কর', 'ি', 'থ', ',', 'ক', 'ি', 'ন', '্', 'থ', 'ু', 'থ', 'া', 'হ', 'া', 'র', 'া', 'ক', 'ি', 'ছ', 'ু', 'ব', 'ু', 'ঝ', 'া', 'ইয', '়', 'া', 'বল', 'ি', 'থ', 'ে', 'ন', 'ন', 'া', '।', '\\\\', 'n', '\\\\', 'nইথ', 'ি', 'মধ', '্', 'য', 'ে', 'একদ', 'ি', 'ন', 'অপর', 'া', 'হ', '্', 'ন', 'ছ', 'ি', 'প', 'ফ', 'ে', 'ল', 'ি', 'য', '়', 'া', 'প', '্', 'রথ', 'া', 'প', 'হ', 'া', 'স', 'ি', 'য', '়', 'া', 'কহ', 'ি', 'ল', ',', '“', 'ক', 'ী', 'র', 'ে', 'স', 'ু', ',', 'থ', 'ো', 'র', 'ন', 'া', 'ক', 'ি', 'বর', 'প', 'া', 'ওয', '়', 'া', '\\\\', 'nগ', 'ে', 'ছ', 'ে', ',', 'থ', 'ু', 'ই', 'ব', 'ি', 'য', '়', 'ে', 'করথ', 'ে', 'য', 'া', 'চ', '্', 'ছ', 'ি', 'স', '?', 'দ', 'ে', 'খ', 'ি', 'স', 'আম', 'া', 'দ', 'ে', 'র', 'ভ', 'ু', 'ল', 'ি', 'স', 'ন', 'ে', '।', '”', 'বল', 'ি', 'য', '়', 'া', 'আব', 'া', 'র', 'ম', 'া', 'ছ', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'মন', 'ো', 'য', 'ো', 'গ', '\\\\', 'nকর', 'ি', 'ল', '।', '\\\\', 'n', '\\\\', 'nমর', '্', 'মব', 'ি', 'দ', '্', 'ধ', 'হর', 'ি', 'ণ', 'ী', 'ব', '্', 'য', 'া', 'ধ', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'য', 'ে', 'মন', 'কর', 'ি', 'য', '়', 'া', 'থ', 'া', 'ক', 'া', 'য', '়', ',', 'ন', 'ী', 'রব', 'ে', 'বল', 'ি', 'থ', 'ে', 'থ', 'া', 'ক', 'ে', '“', 'আম', 'ি', 'থ', 'ো', 'ম', 'া', 'র', 'ক', 'া', 'ছ', 'ে', '\\\\', 'nক', 'ী', 'দ', 'ো', 'ষ', 'কর', 'ি', 'য', '়', 'া', 'ছ', 'ি', 'ল', 'া', 'ম', \"'\", ',', 'স', 'ু', 'ভ', 'া', 'থ', 'ে', 'মন', 'ি', 'কর', 'ি', 'য', '়', 'া', 'প', '্', 'রথ', 'া', 'প', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'ল', ';', 'স', 'ে', 'দ', 'ি', 'ন', 'গ', 'া', 'ছ', 'ে', 'র', 'থল', 'া', 'য', '়', 'আর', '\\\\', 'nবস', 'ি', 'ল', 'ন', 'া', '।', 'ব', 'া', 'ণ', 'ী', 'কণ', '্', 'ঠ', 'ন', 'ি', 'দ', '্', 'র', 'া', 'হইথ', 'ে', 'উঠ', 'ি', 'য', '়', 'া', 'শয', '়', 'নগ', 'ৃ', 'হ', 'ে', 'থ', 'া', 'ম', 'া', 'ক', 'খ', 'া', 'ইথ', 'ে', 'ছ', 'ি', 'ল', 'ে', 'ন', ',', 'স', 'ু', 'ভ', 'া', 'থ', 'া', 'হ', 'া', 'র', 'প', 'া', 'য', '়', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', '\\\\', 'nবস', 'ি', 'য', '়', 'া', 'থ', 'া', 'হ', 'া', 'র', 'ম', 'ু', 'খ', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'য', '়', 'া', 'ক', 'ী', 'দ', 'ি', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', 'অবশ', 'ে', 'ষ', 'ে', 'থ', 'া', 'হ', 'া', 'ক', 'ে', 'স', 'া', 'ন', '্', 'থ', '্', 'বন', 'া', 'দ', 'ি', 'থ', 'ে', 'গ', 'ি', 'য', '়', 'া', 'ব', 'া', 'ণ', 'ী', 'কষ', '্', 'ঠ', 'ে', 'র', '\\\\', 'nশ', 'ু', 'ষ', '্', 'ক', 'কপ', 'ো', 'ল', 'ে', 'অশ', '্', 'র', 'ু', 'গড', '়', 'া', 'ইয', '়', 'া', 'পড', '়', 'ি', 'ল', '।', '\\\\', 'n', '\\\\', 'nক', 'া', 'ল', 'কল', 'ি', 'ক', 'া', 'থ', 'া', 'য', '়', 'য', 'া', 'ইব', 'া', 'র', 'দ', 'ি', 'ন', 'স', '্', 'থ', 'ি', 'র', 'হইয', '়', 'া', 'ছ', 'ে', '।', 'স', 'ু', 'ভ', 'া', 'গ', 'ো', 'য', '়', 'া', 'লঘর', 'ে', 'থ', 'া', 'হ', 'া', 'র', 'ব', 'া', 'ল', '্', 'য', '-', 'সখ', 'ী', 'দ', 'ে', 'র', 'ক', 'া', 'ছ', 'ে', 'ব', 'ি', 'দ', 'া', 'য', '়', '\\\\', 'nলইথ', 'ে', 'গ', 'ে', 'ল', ',', 'থ', 'া', 'হ', 'া', 'দ', 'ি', 'গক', 'ে', 'স', '্', 'বহস', '্', 'থ', 'ে', 'খ', 'া', 'ওয', '়', 'া', 'ইয', '়', 'া', ',', 'গল', 'া', 'ধর', 'ি', 'য', '়', 'া', 'একব', 'া', 'র', 'দ', 'ু', 'ই', 'চ', 'ো', 'খ', 'ে', 'যথ', 'প', 'া', 'র', 'ে', 'কথ', 'া', 'ভর', 'ি', 'য', '়', 'া', '\\\\', 'nথ', 'া', 'হ', 'া', 'দ', 'ে', 'র', 'ম', 'ু', 'খ', 'ে', 'র', 'দ', 'ি', 'ক', 'ে', 'চ', 'া', 'হ', 'ি', 'ল', '-', 'দ', 'ু', 'ই', 'ন', 'ে', 'থ', '্', 'রপল', '্', 'লব', 'হইথ', 'ে', 'টপ', 'ৃ', 'টপ', 'ৃ', 'কর', 'ি', 'য', '়', 'া', 'অশ', '্', 'র', 'া', 'জল', 'পড', '়', 'থ', 'ে', 'ল', 'া', 'গ', 'ি', 'ল', '।', '\\\\', 'n', '\\\\', 'nশম', '্', 'পশয', '্', 'য', 'া', 'য', '়', 'ল', 'ু', 'ট', 'া', 'ইয', '়', 'া', 'পড', '়', 'ি', 'ল', '-', 'য', 'ে', 'ন', 'ধরণ', 'ী', 'ক', 'ে', ',', 'এই', 'প', '্', 'রক', 'া', 'ণ', '্', 'ড', 'ম', 'ূ', 'ক', 'ম', 'া', 'নবথ', 'া', 'ক', 'ে', 'দ', 'ু', 'ই', 'ব', 'া', 'হ', 'ু', 'থ', 'ে', 'ধর', 'ি', 'য', '়', 'া', 'বল', 'ি', 'থ', 'ে', '\\\\', 'nচ', 'া', 'হ', 'ে', ',', '“', 'থ', 'ু', 'ম', 'ি', 'আম', 'া', 'ক', 'ে', 'য', 'া', 'ইথ', 'ে', 'দ', 'ি', 'য', '়', 'ো', 'ন', 'া', ',', 'ম', 'া', '।', 'আম', 'া', 'র', 'মথ', 'ো', 'দ', 'ু', 'ট', 'ি', 'ব', 'া', 'হ', 'ু', 'ব', 'া', 'ড', '়', 'া', 'ইয', '়', 'া', 'থ', 'ু', 'ম', 'ি', 'ও', 'আম', 'া', 'ক', 'ে', 'ধর', 'ি', 'য', '়', 'া', '\\\\', 'nর', 'া', 'খ', 'ো', '।', '0', '[', 'স', 'ং', 'ক', '্', 'ষ', 'ি', 'প', '্', 'থ', ']', '\\\\', 'n', '\\\\', 'nশব', '্', 'দ', 'া', 'র', '্', 'থ', 'ও', 'ট', 'ী', 'ক', 'া', ':', 'গর', '্', 'ভ', 'ে', 'র', 'কলঙ', '্', 'ক', '-', 'সন', '্', 'থ', 'া', 'ন', 'হ', 'ি', 'স', 'ে', 'ব', 'ে', 'কলঙ', '্', 'ক', ',', 'গর', '্', 'ভ', 'হল', 'ো', 'ম', 'া', 'য', '়', 'ে', 'র', 'প', 'ে', 'ট', 'য', 'ে', 'ব', '্', 'যক', '্', 'থ', 'ি', 'ব', 'া', 'বন', '্', 'থক', 'ে', '\\\\', 'nপর', 'ি', 'ব', 'া', 'র', 'ে', 'ন', 'ে', 'থ', 'ি', 'ব', 'া', 'চক', 'হ', 'ি', 'স', 'ে', 'ব', 'ে', 'দ', 'ে', 'খ', 'া', 'হয', '়', 'থ', 'া', 'হল', 'ো', 'কলঙ', '্', 'ক', '।', 'স', 'ু', 'দ', 'ী', 'র', '্', 'ঘ', 'পল', '্', 'পবব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', '_', 'বড', '়', 'প', 'া', 'থ', 'া', 'ব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', ',', 'দ', 'ী', 'র', '্', 'ঘ', 'হল', 'ো', '\\\\', 'nবড', '়', ',', '“', 'স', 'ু', '”', 'য', 'ু', 'ক', '্', 'থ', 'হয', '়', 'ে', \"'\", 'বড', '়', \"'\", 'ক', 'ে', 'ব', 'ি', 'শ', 'ে', 'ষ', 'া', 'য', '়', 'ি', 'থ', 'কর', 'া', 'হয', '়', 'ে', 'ছ', 'ে', '।', 'পল', '্', 'লব', 'হল', 'ো', 'প', 'া', 'থ', 'া', '।', 'এখ', 'া', 'ন', 'ে', 'চ', 'ো', 'খ', 'ে', 'র', 'প', 'া', 'থ', 'া', 'হ', 'ি', 'স', 'ে', 'ব', 'ে', '\\\\', 'nব', '্', 'যবহ', 'ৃ', 'থ', 'হয', '়', 'ে', 'ছ', 'ে', '।', 'ওষ', '্', 'ঠ', 'া', 'ধর', '-', 'ওষ', '্', 'ঠ', 'এব', 'ং', 'অধর', ',', 'উপর', 'ে', 'র', 'ও', 'ন', 'ি', 'চ', 'ে', 'র', 'ঠ', 'ো', 'ট', '[', 'ওষ', '্', 'ঠ', '+', 'অধর', '_', 'ওয', '্', 'ঠ', 'া', 'ধর', ']', 'ক', 'ি', 'শলয', '়', '\\\\', 'n', '-', 'গ', 'া', 'ছ', 'ে', 'র', 'নথ', 'ু', 'ন', 'প', 'া', 'থ', 'া', '।', 'থর', '্', 'জম', 'া', '_', 'অন', 'ু', 'ব', 'া', 'দ', ',', 'এক', 'ভ', 'া', 'ষ', 'া', 'থ', 'ে', 'ক', 'ে', 'অন', '্', 'য', 'ভ', 'া', 'ষ', 'া', 'য', '়', 'বল', 'া', 'ব', 'া', 'ল', 'ে', 'খ', 'া', '।', 'অন', '্', 'থম', 'া', 'ন', '-', 'ড', 'ু', 'বন', '্', 'থ', ',', '\\\\', 'nড', 'ু', 'ব', 'ে', 'য', 'া', 'চ', '্', 'ছ', 'ে', 'এমন', ',', 'চন', '্', 'দ', '্', 'র', '-', 'স', 'ূ', 'র', '্', 'য', 'ে', 'র', 'পশ', '্', 'চ', 'ি', 'ম', 'দ', 'ি', 'ক', 'ে', 'অদ', 'ৃ', 'শ', '্', 'য', 'অবস', '্', 'থ', 'া', '।', 'অন', 'ি', 'ম', 'ে', 'ষ', '-', 'অপলক', ',', 'পলকহ', 'ী', 'ন', ',', 'উদয', '়', 'া', 'স', '্', 'থ', '-', 'উদয', '়', '\\\\', 'n', '+', 'অস', '্', 'থ', 'উদয', '়', 'া', 'স', '্', 'থ', ',', 'আব', 'ি', 'র', '্', 'ভ', 'া', 'ব', 'ও', 'থ', 'ি', 'র', 'ো', 'ভ', 'া', 'ব', ',', 'উঠ', 'া', 'ও', 'ড', 'ু', 'ব', 'া', '।', 'ছ', 'া', 'য', '়', 'া', 'ল', 'ো', 'ক', '-', 'ছ', 'া', 'য', '়', 'া', '+', 'আল', 'ো', 'ক', '-', 'ছ', 'া', 'য', '়', 'া', 'ল', 'ো', 'ক', '।', 'ক', 'ো', 'ন', 'ো', '\\\\', 'nবন', '্', 'থর', 'ওপর', 'আল', 'ো', 'পড', '়', 'ল', 'ে', 'য', 'ে', 'প', '্', 'রথ', 'ি', 'ব', 'ি', 'স', '্', 'ব', 'হয', '়', 'থ', 'া', 'হল', 'ো', 'ছ', 'া', 'য', '়', 'া', '।', 'ব', 'ি', 'জন', 'মহথ', '্', 'ব', '-', 'ব', 'ি', 'জন', '-', 'জনশ', 'ূ', 'ন', '্', 'য', ',', 'ন', 'ি', 'র', '্', 'জন', '।', 'মহথ', '্', 'থ', '\\\\', 'n_', 'অবদ', 'া', 'ন', '।', 'ব', 'ি', 'জন', 'মহথ', '্', 'ব', '-', 'ক', 'ো', 'ল', 'া', 'হলম', 'ু', 'ক', '্', 'থ', 'প', '্', 'রক', 'ৃ', 'থ', 'ি', 'র', 'অবস', '্', 'থ', 'া', 'র', 'য', 'ে', 'আকর', '্', 'ষণ', 'ী', 'য', '়', 'দ', 'ি', 'ক', '।', 'থন', '্', 'ব', 'ী', '-', 'ক', '্', 'ষ', 'ী', 'ণ', 'ও', 'স', 'ু', 'গঠ', 'ি', 'থ', '\\\\', 'nঅঙ', '্', 'গব', 'ি', 'শ', 'ি', 'ষ', '্', 'ট', '।', 'ব', 'া', 'খ', 'া', 'র', 'ি', '-', 'ক', 'ী', 'ধ', 'ে', 'র', 'দ', 'ু', 'দ', 'ি', 'ক', 'ে', 'দ', 'ু', 'প', '্', 'র', 'া', 'ন', '্', 'থ', 'ে', 'ঝ', 'ু', 'ল', 'ি', 'য', '়', 'ে', 'ব', 'ো', 'ঝ', 'া', 'বহন', 'ে', 'র', 'ব', 'া', 'শ', 'ে', 'র', 'ফ', 'া', 'ল', 'ি', '।', 'ট', 'ে', 'ক', 'ি', 'শ', 'া', 'ল', 'া', '-', 'য', 'ে', '\\\\', 'nঘর', 'ে', 'ট', 'ে', 'ক', 'ি', 'র', 'া', 'খ', 'া', 'হয', '়', '।', 'ট', 'ে', 'ক', 'ি', 'হল', 'ো', 'ধ', 'া', 'ন', 'থ', 'ে', 'ক', 'ে', 'চ', 'া', 'ল', 'থ', 'ৈ', 'র', 'ি', 'র', 'ল', 'ো', 'কজ', 'যন', '্', 'থ', '্', 'র', '।', 'এখন', 'ো', 'খ', '্', 'র', 'া', 'ম', 'ী', 'ণ', 'জ', 'ী', 'বন', 'ে', 'অন', 'ে', 'ক', '\\\\', 'nব', 'া', 'ড', '়', 'ি', 'থ', 'ে', 'ট', 'ে', 'ক', 'ি', 'র', 'ঘর', 'আছ', 'ে', '।', 'গ', 'া', 'র', '্', 'হস', '্', 'থ', '্', 'য', 'সচ', '্', 'ছলথ', 'া', '-', 'প', 'া', 'র', 'ি', 'ব', 'া', 'র', 'ি', 'ক', 'দ', 'ৈ', 'নন', '্', 'দ', 'ি', 'ন', '\"', '}']\nSentences of the first section: ['{ \"page_1\": \"ফুলের বিবাহ\\\\n\\\\nবঙ্কিমচন্দ্র চট্টোপাধ্যায়\\\\n\\\\n[লেখক-পরিচিথি : বঙ্কিমচন্দ্র চট্টোপাধ্যায় ২৬শে জুন ১৮৩৮ সালে পশ্চিমবঙ্গের চব্বিশ পরগনা জেলার\\\\nঅন্থর্গথ কীঠালপাড়া গ্রামে জন্মগ্রহণ করেন।', 'থিনি ১৮৫৮ সালে কলকাথা বিশ্ববিদ্যালয় থেকে বি.এ.পরীক্ষায়\\\\nউথ্থীর্ণ হন এবং সে বছরই ডেপুটি ম্যাজিস্ট্রেট ও ডেপুটি কালেক্টর পদে চাকরিথে নিযুক্থ হন।', 'বঙ্কিমচন্দ্র\\\\nথেথ্রিশ বছর একই পদে চাকরি করে ১৮৯১ সালে অবসর গ্রহণ করেন।', 'থিনি পাঠ্যাবস্থায়ই সাহিথ্যচর্চা\\\\nশুরু করেন।', 'থার অসামান্য কৃথিথ্ব প্রকাশ পেয়েছে পাশ্চাথ্য ভাবাদর্শে বাংলা উপন্যাস রচনার পথিকৃৎ হিসেবে।', '\\\\n১৮৬৫ সালে প্রকাশিথ থার প্রথম বাংলা উপন্যাস দুর্গেশনন্দিনী বাংলা কথাসাহিথ্যে এক নবদিগন্থ উন্মোচন\\\\nকরে।', 'থার অন্যান্য উপন্যাস হলো : কপালকুগুলা, মৃণালিনী, বিষবৃক্ষ, ইন্দিরা, মুগলাঙ্গুরীয়, রাধারানী, চন্দ্রশেখর,\\\\nরজনী, কৃষ্কান্থের উইল, রাজসিংহ, আনন্দমঠ, দেবী চৌধুরানী ও সীথারাম।', 'প্রবন্ধ সাহিথ্যেও বঙ্কিমচন্দ্র\\\\nকৃথিথ্ব দেখিয়েছেন।', 'কমলাকান্থের দণ্থর, লোকরহস্য, কৃষ্ণ চরিথ্র ইথ্যাদি থার উল্লেখযোগ্য প্রবন্ধগরন্থ।', '\\\\nবঙ্কিমচন্দ্র চট্টোপাধ্যায় ১৮৯৪ সালের ৮ই এপ্রিল মৃথ্যুবরণ করেন |]\\\\n\\\\nবৈশাখ মাস বিবাহের মাস।', 'আমি ১লা বৈশাখে নসী বাবুর ফুলবাগানে বসিয়া একটি বিবাহ\\\\nদেখিলাম।', 'ভবিষ্যৎ বরকন্যাদিগের শিক্ষার্থ লিখিয়া রাখিথেছি।', '\\\\n\\\\nমল্লিকা ফুলের বিবাহ।', 'বৈকাল-শৈশব অবসানপ্রায়, কলিকা-কন্যা বিবাহযোগ্যা হইয়া আসিল।', 'কন্যার\\\\nপিথা বড়লোক নহে, ক্ষুদ্র বৃক্ষ, থাহাথে আবার অনেকগুলি কন্যাভারপ্রস্থ।', 'সম্বন্ধের অনেক কথা\\\\nহইথেছিল, কিন্থু কোনটা স্থির হয় নাই।', 'উদ্যানের রাজা স্থলপদ্ম নির্দোষ পাথ্র বটে, কিন্থু ঘর বড় উচু,\\\\nস্থলপদ্ম অথ দূর নামিল না।', 'জবা এ বিবাহে অসম্মথ ছিল না, কিন্থু জবা বড় রাগী, কন্যাক্থা\\\\nপিছাইলেন।', 'গন্ধরাজ পাথ্র ভালো, কিন্থু বড় দেমাগ, প্রায় থাহার বর পাওয়া যায় না।', 'এইরূপ\\\\nঅব্যবস্থার সময়ে ভ্রমররাজ ঘটক হইয়া মন্রিকা- বৃক্ষসদনে উপস্থিথ হইলেন।', 'থিনি আসিয়া বলিলেন,\\\\n€গুণ্!', 'গুণ্!', 'গুণ্ মেয়ে আছে?', '\\\\n\\\\nমন্লিকাবৃক্ষ পাথা নাড়িয়া সায় দিলেন, “আছে!', 'ভ্রমর পথ্রাসন গ্রহণ করিয়া বলিলেন, “গুণ্ গুণ্ গুণ!', '\\\\nগুণ্ গুণাগুণ্!', 'মেয়ে দেখিব |”\\\\n\\\\nবৃক্ষ, শাখা নথ করিয়া মুদিথনয়না অবগুষ্ঠনবথী কন্যা দেখাইলেন।', '\\\\nভ্রমর একবার বৃক্ষকে প্রদক্ষিণ করিয়া আসিয়া বলিলেন, “গুণৃ!', 'গুণৃ!', 'গুণৃ!', 'গুণ দেখিথে চাই।', 'ঘোমটা খোল।', '”\\\\n\\\\nলজ্জাশীলা কন্যা কিছুথেই ঘোম্টা খুলে না।', 'বৃক্ষ বলিলেন, “আমার মেয়েগুলি বড় লাজুক।', 'থুমি\\\\nএকটু অপেক্ষা কর, আমি মুখ দেখাইথেছি।', '”\\\\n\\\\n২০১৮\", \"page_2\": \"২০১৮\\\\n\\\\nফুলের বিবাহ ্\\\\n\\\\nভ্রমর ভোৌ করিয়া স্থলপদ্মের বৈঠকখানায় গিয়া রাজপুথ্রের সঙ্গে ইয়ারকি করিথে বসিলেন।', 'এদিকে\\\\nমল্পিকার সন্ধ্যাঠাকুরাণী-দিদি আসিয়া থাহাকে কথ বুঝাইথে লাগিল -_ বলিল, “দিদি, একবার ঘোম্টা\\\\nখোল _ নইলে,বর আসিবে না _ লক্ষ্মী আমার, চাদ আমার, সোনা আমার, ইথ্যাদি।', \"' কলিকা কথবার\\\\nঘাড় নাড়িল, কথবার রাগ করিয়া মুখ ঘুরাইল, কথবার বলিল, 'ঠান্দিদি, থুই যা!\", 'কিন্থু শেষে\\\\nসন্ধ্যার ঘ্লিঞ্ধ স্বভাবে মুগ্ধ হইয়া মুখ খুলিল।', 'থখন ঘটক মহাশয় ভৌ করিয়া রাজবাড়ী হইথে নামিয়া\\\\nআসিয়া ঘটকালীথে মন দিলেন।', 'কন্যার পরিমলে মুগ্ধ হইয়া বলিলেন, “গুণ্ গুণ্ গুণ্ গুণ গুণাগুণ্!', '\\\\nকন্যা গুণবথী বটে।', 'ঘরে মধু কথ?', '\\\\n\\\\nকন্যাকর্থা বৃক্ষ বলিলেন, “ফর্দ দিবেন, কড়ায় গণ্ডায় বুঝাইয়া দিবে।', \"' ভ্রমর বলিলেন, 'গুণ্ গুণ্,\\\\nআপনার অনেক গুণ - ঘটকালীটা?\", '\\\\n\\\\nকন্যাকর্থা শাখা নাড়িয়া সায় দিল, “থাও হবে।', '”\\\\n\\\\nভ্রমর-“বলি ঘটকালীর কিছু আগাম দিলে হয় না?', 'নগদ দান বড় গুণ-গুণ্ গুণ্ গুণ্।', '*\\\\n\\\\n্ষু্ বৃক্ষটি থখন বিরক্থ হইয়া, সকল শাখা নাড়িয়া বলিল, “আগে বরের কথা বল - বর কে?', \"'\\\\nভ্রমর-“বর অথি সুপাথ্র।\", '_ থার অনেক গুণ-ণৃ-ণ্।', '”\\\\n\\\\nএসকল কথোপকথন মনুষ্যে শুনিথে পায় না, আমি কেবল দিব্য কর্ণ পাইয়াই এ সকল শুনিথেছিলাম।', '\\\\nআমি শুনিথে লাগিলাম, কুলাচার্য মহাশয়, পাখা ঝাড়িয়া, ছয় পা ছড়াইয়া গোলাবের মহিমা কীর্থন\\\\nকরিথেছিলেন।', \"বলিথেছিলেন যে, গোলাব বংশ বড় কুলীন; কেন না, ইহারা “ফুলে' মেল।\", 'যদি\\\\nবল, সকল ফুলই ফুলে, থথাপিগোলাবের গৌরব অধিক; কেন না, ইহারা সাক্ষাৎ বাঞ্চামালীর সন্থান;\\\\nথাহার স্বহস্থরোপিথ | যদি বল, এ ফুলে কাটা আছে, কোন্ কুলে বা কোন্ ফুলে নাই?', '\\\\n\\\\nযাহা হউক, ঘটকরাজ কোনরুপে সম্বন্ধ স্থির করিয়া, বৌ করিয়া উড়িয়া গিয়া, গোলাব বাবুর\\\\nবাড়িথে খবর দিলেন।', 'গোলাব, থখন বাথাসের সঙ্গে নাচিয়া নাচিয়া, হাসিয়া হাসিয়া, লাফাইয়া\\\\nলাফাইয়া খেলা করিথেছিল, বিবাহের নাম শুনিয়া অহোদিথ হইয়া কন্যার বয়স জিজ্ঞাসা করিল।', '\\\\nভ্রমর বলিল, “আজি কালি ফুটিবে।', '”\\\\n\\\\nগোধুলি লগ্ন উপস্থিথ, গোলাব বিবাহে যাথ্রার উদ্যোগ করিথে লাগিলেন।', 'উচ্চিঙ্গড়া নহবৎ বাজাইথে\\\\nনা।', 'খদ্যোথেরা ঝাড় ধরিল; আকাশে থারাবাজি হইথে লাগিল।', 'কোকিল আগে আগে ফুকরাইথে\\\\nলাগিল।', 'অনেক বরযাথ্রী চলিল; স্বয়ং রাজকুমার স্থলপদ্ম দিবাবসানে অসুস্থকর বলিয়া আসিথে\\\\nপারিলেন না, কিন্থু জবাগোষ্ঠী - শ্বেথ জবা, রক্থ জবা, জরদ জবা প্রভৃথি সবংশে আসিয়াছিল।', '\\\\nকরবীদের দল, সেকেলে রাজাদিগের মথ বড় উচ্চ ডালে চড়িয়া আসিয়া উপস্থিথ হইল।', 'সেঁউথি\", \"page_3\": \"৮ মাধ্যমিক বাংলা সাহিথ্য\\\\n\\\\nনীথবর হইবে বলিয়া, সাজিয়া আসিয়া দুলিথে লাগিল।', 'গরদের জোড় পরিয়া চাপা আসিয়া\\\\nদীড়াইল _ উগ্ব গন্ধ ছুটিথে লাগিল।', 'গন্ধরাজেরা বড় বাহার দিয়া, দলে দলে আসিয়া, গন্ধ বিলাইয়া\\\\nদেশ মাথাইথে লাগিল।', 'অশোক নেশায় লাল হইয়া আসিয়া উপস্থিথ; সঙ্গে একপাল পিপ্ড়া মোসায়েব\\\\nহইয়া আসিয়াছে; থাহাদের গুণের সঙ্গে সম্বন্ধ নাই, কিন্থ দাথের জ্বালা বড়-কোন্ বিবাহে না এরুপ\\\\nবরযাথ্রী জোটে, আর কোন্ বিবাহে না থাহারা হুল ফুটাইয়া বিবাদ বাধায়?', 'কুরুবক কুটজ প্রভৃথি\\\\nআরও অনেক বরযাথ্রী আসিয়াছিলেন, ঘটক মহাশয়ের কাছে থাহাদের পরিচয় শুনিবেন।', 'সর্বথ্রই থিনি\\\\nযাথায়াথ করেন এবং কিছু কিছু মধু পাইয়া থাকেন।', '\\\\n\\\\nআমারও নিমন্থ্রণ ছিল, আমিও গেলাম।', 'দেখি, বরপক্ষের বড় বিপদ।', 'বাথাস বাহকের বায়না\\\\nলুকাইলেন, কেহ খুঁজিয়া পায় না।', 'দেখিলাম, বর বরযাথ্রী,সকলে অবাক হইয়া স্থিরভাবে দীড়াইয়া\\\\nআছেন।', 'মল্লিকাদিগের কুল যায় দেখিয়া, আমিই বাহকের কার্য স্বীকার করিলাম।', 'বর, বরযাথ্রী\\\\nসকলকে থুলিয়া লইয়া মল্পিকাপুরে গেলাম।', '\\\\n\\\\nসুখের হাসি হাসিথেছে।', 'দেখিলাম, পাথায় পাথায় জড়াজড়ি, গন্ধের ভাণ্ডারে ছড়াছড়ি পড়িয়া গিয়াছে\\\\n_রূপের ভারে সকলে ভাঙ্গিয়া পড়িথেছে।', 'যুখি, মালথী, বকুল, রজনীগন্ধা প্রভৃথি এয়োগণ স্থ্রী-আচার\\\\nকরিয়া বরণ করিল।', 'দেখিলাম, পুরোহিথ উপস্থিথ; নসী বাবুর নবমব্ধীয়া কন্যা (জীবন্থ কুসুমরূপিণী)\\\\nকুসুমলথা সূচ সুথা লইয়া দীড়াইয়া আছে; কন্যাকর্থা কন্যা সম্প্রদান করিলেন; পুরোহিথ মহাশয়\\\\nদুইজনকে এক সুথায় গাথিয়া গাটছড়া বাঁধিয়া দিলেন।', '\\\\n\\\\nথখন বরকে বাসর-ঘরে লইয়া গেল।', 'কথ যে রসময়ী মধুময়ী সুন্দরী সেখানে বরকে ঘিরিয়া বসিল,\\\\nথাহা কি বলিব।', 'প্রাচীনা ঠাকুরাণীদিদি টগর সাদা প্রাণে বাধা রসিকথা করিথে করিথে শুকাইয়া\\\\nউঠিলেন।', 'রঙ্গণের রাঙ্গামুখে হাসি ধরে না।', 'যুই, কন্যের সই, কন্যের কাছে গিয়া শুইল; রজনীগন্ধাকে\\\\nবর থাড়কা রাক্ষসী বলিয়া কথ থামাসা করিল; বকুল একে বালিকা, থাথে যথ গুণ, থথ রুপ নহে;\\\\nএককোণে গিয়া চুপ করিয়া বসিয়া রহিল; আর ঝুম্কা ফুল বড় মানুষের গৃহিণীর মথ মোটা নীল শাড়ি\\\\nছড়াইয়া জমকাইয়া বসিল।', 'থখন-\\\\n\\\\n“কমলকাকা-ওঠ বাড়ি যাই- রাথ হয়েছে, ও কি, ঢুলে পড়বে যে?', 'কুসুমলথা এই কথা বলিয়া আমার\\\\nগা ঠেলিথেছিল; - চমক হইলে, দেখিলাম কিছুই নাই।', 'সেই পুষ্পবাসর কোথায় মিশিল?', '- মনে\\\\nকরিলাম, সংসার অনিথ্যই বটে এই আছে এই নাই।', 'সে রম্য বাসর কোথায় গেল,_ সেই\\\\nহাস্যমুখী শুভ্রস্মিথসুধাময়ী পুষ্পসুন্দরীসকল কোথায় গেল?', 'যেখানে সব যাইবে, সেইখানে- স্মৃথির\\\\nদর্পণথলে, ভূথসাগরগর্ভে।', 'যেখানে রাজা প্রজা, পর্বথ সমুদ্র, গ্রহ নক্ষথ্রাদি গিয়াছে বা যাইবে,\\\\nসেইখানে - ধ্বংসপুরে!', 'এই বিবাহের ন্যায় সব শৃন্যে মিশাইবে, সব বাথাসে গলিয়া যাইবে।', '\\\\nকুসুম বলিল, “ওঠ না-কি কচ্চো?', '\\\\n\\\\nআমি বলিলাম, “দূর পাগলি, আমি বিয়ে দিচ্ছিলাম 1”\\\\n\\\\n২০১৮\", \"page_4\": \"২০১৮\\\\n\\\\nফুলের বিবাহ ৯\\\\n\\\\nকুসুম ঘেঁষে এসে, হেসে হেসে কাছে দীড়াইয়া আদর করিয়া জিজ্ঞাসা করিল, “কার বিয়ে, কাকা?', '\\\\nআমি বলিলাম, “ফুলের বিয়ে।', '”\\\\n\\\\n“ওঃ পোড়া কপাল, ফুলের?', 'আমি বলি কি!', 'আমিও যে এই ফুলের বিয়ে দিয়েছি।', \"'\\\\n\\\\n“কই?\", '\\\\n\\\\n“এই যে মালা গেখেছি।', \"' দেখিলাম, সেই মালায় আমার বর কন্যা রহিয়াছে।\", '[3\\\\n\\\\nশব্দার্থ ও টীকা : কন্যাভারহস্থ - বিবাহযোগ্যা কন্যা বিয়ে দেওয়ার দায়িথ্ব বহনকারী অর্থে।', '\\\\nসন্ন্ধের _ বিয়ের।', 'কন্যাকর্থা - কন্যার অভিভাবক।', 'পথ্রাসন - পাথার উপর আসন।', 'অবগপ্ঠনবথী\\\\n- ঘোমটা দেওয়া।', 'ইয়ারকি - বন্ধুদের সঙ্গেই করা চলে এমন আলাপ।', 'সন্ধ্যাঠাকুরাণী দিদি - এখানে\\\\nসন্ধ্যাকালকে দিদি বলে সম্বোধন করা হয়েছে।', 'পরিমল - সুগন্ধ।', 'গন্ধোপাধ্যায় - গন্ধের রাজা\\\\nবোঝাথে।', 'কুলাচার্য - কুলের আচার্য বা বংশের প্রধান পুরোহিথ।', 'বাষ্থীমালি _ যে মালি ইচ্ছামথো\\\\nফুল ফোটাথে পারে।', 'খদ্যোথ - জোনাকি পোকা।', 'এয়োগণ - সধবা নারী।', 'কমলকাকা -\\\\nকমলাকান্থকে কাকা বলে সম্বোধন করা হয়েছে।', '\\\\n\\\\nপাঠ পরিচিথি : বঙ্কিমচন্দ্র চট্টোপাধ্যায়ের লঘ্ুরচনা “কমলাকান্থের দপ্থর\\\\\" গ্রন্থের নবম সংখ্যক লেখা\\\\n“ফুলের বিবাহ\\\\\" ৷ এই রচনায় হাস্যরসের মাধ্যমে বিভিন্ন ফুলের নাম, সে ফুলগুলোর গন্ধের থারথম্য,\\\\nবর্ণের রকমফের অথ্যন্থ সংবেদনশীলথার সঙ্গে থুলে ধরেছেন বঙ্কিমচন্দ্র।', 'কখন কোন ফুল ফোটে সে\\\\nপর্যবেক্ষণও এই রচনায় পাওয়া যায়।', 'বিয়ে-অনুষ্ঠান বাঙালির জীবনে, বিশেষ করে বাড়ির শিশু-কিশোর\\\\nও প্রথিবেশীদের মধ্যে অথীব আনন্দ নিয়ে আসে।', 'এই অনুষ্ঠানে বর-কনে কেন্দ্রে থাকলেও বর-কনের\\\\nযুক্থ।', 'বিয়ে অনুষ্ঠানের সঙ্গে যুক্থ থাকেন এমন নানা ব্যক্থির পরিবর্থে বিভিন্ন ফুলের উল্লেখ করে\\\\nঅসাধারণ দক্ষথায় বঙ্কিমচন্দ্র বাঙালির গাহস্থ্য একটি অনুষ্ঠানকে আরো আনন্দদায়ক করে এখানে\\\\nউপস্থাপন করেছেন।', 'এখানে লেখক প্রকৃথিকে বাস্থব জীবনে উপস্থাপনে অসাধারণ দক্ষথার পরিচয়\\\\n\\\\nদিয়েছেন।', 'থার এই রচনাভঙ্গি বাংলা গদ্য বিকাশের ক্ষেথ্রে গুরুথৃপূর্ণ ভূমিকা রাখে।', '\\\\n\\\\nঅনুশীলনী\\\\n\\\\n \\\\n\\\\n \\\\n\\\\nকর্ম-অনুশীলন\\\\n১. পাঠটিথে যেসবফুলের কথা বলা হয়েছে সেগুলোর নাম ওগন্ধের পরিচয় দিয়ে একটি চার্ট থৈরি কর।', '\\\\n২. ফুলের বহুবিধ ব্যবহার লিপিবদ্ধ করে শ্রেণি শিক্ষককে দেখাও।', '\\\\n\\\\nবহুনির্বাচনি প্রশ্ন\\\\n\\\\n১।', \"“ফুলের বিবাহ' গল্পের পাথ্র কে ছিল?\", '\\\\nক. মল্লিকা খ. স্থলপদ্ম\\\\nগ. রজনীগন্ধা ঘ. মালথী\\\\n\\\\nফর্মা-২, মাধ্যমিক বাংলা সাহিথ্য: ৯ম-১০ শ্রেণি\", \"page_5\": \"১০ মাধ্যমিক বাংলা সাহিথ্য\\\\n\\\\n২।', 'এ গল্পে কন্যাকুল বলথে কাদের বোঝানো হয়েছে?', '\\\\nক. ভোমর খ.. বৃক্ষ\\\\n\\\\nগ. গাছপালা ঘ. ফুল\\\\nনিচের উদ্দীপকটি পড়ে ৩ সংখ্যক প্রশ্রের উথ্থর দাও :\\\\n\\\\nজমিদার জনার্দন ঘোষ মেয়ের বিয়ে দিথে গিয়ে পাথ্র খুঁজে বেড়াচ্ছেন।', 'অনেক খোঁজাখুঁজির\\\\nপর অবশেষে রায়বাহাদুর শুভাশিস চৌধুরীর একমাথ্র পুথ্র দেবাশিসকে পাওয়া গেল।', 'রূপে\\\\n-গুণে সে অথুলনীয়।', '\\\\n\\\\n৩।', 'উদ্দীপকের দেবাশিসের সাথে “ফুলের বিবাহ\\\\\" গল্পের সাদৃশ্য রয়েছে -\\\\n\\\\n1. গন্ধরাজের\\\\n1. গোলাবের\\\\n111. রজনীগন্ধার\\\\nনিচের কোনটি সঠিক?', '\\\\nক. 1 খ. 1\\\\nগ., 71 ঘ. 11717\\\\nসৃজনশীল প্রশ্ন\\\\n\\\\nমৌরী একদিন বাবার কাছে বায়না ধরে বোটানিক্যাল গার্ডেনে বেড়াথে যাবে।', 'বাবা একদিন ওকে\\\\nনিয়ে বেড়াথে গেলে সেভীষণ খুশি হয়।', 'নানা জাথের ফুল-ফলের গাছের সমারোহ দেখে সে অভিভূথ\\\\nহয়েযায়।', 'দীর্ঘদিন সে যেসব ফুল-ফলের নাম শুনেছে সেগুলো আজ নিজ চোখে দেখে খুবই আনন্দিথ\\\\nহয়।', 'অবশেষে সিদ্ধান্থ নেয় - বাড়ির আঙিনায় ছোট্ট একটা বাগান করবে।', \"\\\\n\\\\nক. “ফুলের বিবাহ' গল্পে কে ঘটকের দায়িথ্ পালন করে?\", '\\\\n\\\\nখ. ক্ষুদ্র বৃক্ষটি কেন বিরক্থ হয়েছিল?', \"\\\\n\\\\nগ. উদ্দীপকের মৌরীর ভালোলাগার বিষয়ের সঙ্গে “ফুলের বিবাহ' গল্পের সাদৃশ্য পূর্ণ দিকটি ব্যাখ্যা কর।\", '\\\\nঘ. মৌরীর মাঝে সৃষ্ট প্রথিক্রিয়াই যেন “ফুলের বিবাহ\\\\\" গল্পের মূল চেথনা - যুক্থিসহ বুঝিয়ে লেখ।', '\\\\n\\\\n২০১৮\", \"page_6\": \"২০১৮\\\\n\\\\nসুভা\\\\nরবীন্দ্রনাথ ঠাকুর\\\\n\\\\n[লেখক -পরিচিথি : রবীন্দ্রনাথ ঠাকুর ২৫শে বৈশাখ ১২৬৮ সালে পেই মে ১৮৬১ খিষ্টাব্দ) কলকাথার\\\\nজোড়াসীকোর ঠাকুর পরিবারে জন্য্রহণ করেন।', 'থার পিথা মহর্ষি দেবেন্দ্রনাথ ঠাকুর এবং পিথামহ\\\\nপ্রিন্স দ্বারকানাথ ঠাকুর।', 'বিদ্যালয়ের আনুষ্ঠানিক শিক্ষা থিনি লাভ করেননি, কিন্থু সাহিথ্যের বিচিথ্র ক্ষেথ্রে\\\\nথার পদচারণা এক বিস্ময়ের বিষয়।', 'থিনি ছিলেন প্রকৃথ অর্থেই অসামান্য প্রথিভাধর ব্যক্থি।', 'বাল্যকালেই\\\\nথীর কবিপ্রথিভার উন্মেষ ঘটে।', 'মাথ্র পনেরো বছর বয়সে থার বনফুল কাব্য প্রকাশিথ হয়।', '১৯১৩ সালে\\\\nরবীন্দ্রনাথ গীথাঞ্জলি কাব্যের জন্য এশীয়দের মধ্যে সাহিথ্যে প্রথম নোবেল পুরস্কার লাভ করেন।', 'বস্থুথ\\\\nথার একক সাধনায় বাংলা ভাষা ও সাহিথ্য সকল শাখায় দ্রুথ উন্নথি লাভ করে এবং বিশ্বদরবারে\\\\nগৌরবের আসনে প্রথিষ্ঠিথ হয়।', 'থিনি একাধারে সাহিথ্যিক, দার্শনিক, শিক্ষাবিদ, সুরকার, নাট্য\\\\nপ্রযোজক ও অভিনেথা।', 'কাব্য, ছোটগল্প, উপন্যাস, নাটক, প্রবন্ধ, গান ইথ্যাদি সাহিথ্যের সকল শাখাই থার\\\\nঅবদানে সমৃদ্ধ।', 'থার অজস্র রচনার মধ্যে মানসী, সোনার থরী, চিথ্রা, কল্পনা, ক্ষণিকা, বলাকা, পুনস্চ,\\\\nচোখের বালি, গোরা, ঘরে বাইরে, যোগাযোগ, শেষের কবিথা, বিসজর্ন, ডাকঘর, রক্থকরবী, গল্পগচ্ছ,\\\\nবিচিথ্র প্রবন্ধ ইথ্যাদি বিশেষভাবে উল্লেখযোগ্য।', '২২শে শ্রাবণ ১৩৪৮ সালে ণেই আগস্ট ১৯৪১ খরষ্টাব্দ)\\\\nকলকাথায় বিশ্বকবি রবীন্দ্রনাথ ঠাকুর শেষ নিঃশ্বাস থ্যাগ করেন।', ']\\\\n\\\\nমেয়েটির নাম যখন সুভাষিণী রাখা হইয়াছিল থখন কে জানিথ সে বোবা হইবে।', 'থাহার দুটি বড়ো\\\\nবোনকে সুকেশিনী ও সুহাসিনী নাম দেওয়া হইয়াছিল, থাই মিলের অনুরোধে থাহার বাপ ছোটো\\\\nমেয়েটির নাম সুভাষিণী রাখে।', 'এখন সকলে থাহাকে সংক্ষেপে সুভা বলে।', '\\\\n\\\\nদম্থরমথ অনুসন্ধান ও অর্থব্যয়ে বড়ো দুটি মেয়ের বিবাহ হইয়া গেছে, এখন ছোটোটি পিথামাথার\\\\nনীরব হৃদয়ভারের মথো বিরাজ করিথেছে।', '\\\\n\\\\nযে কথা কয় না সে যে অনুভব করে ইহা সকলের মনে হয় না, এইজন্য থাহার সাক্ষাথেই সকলে\\\\nথাহার ভবিষ্যৎ সমন্ধে দুশ্চিন্থা প্রকাশ করিথ।', 'সে যে বিধাথার অভিশাপস্বরূপে থাহার পিথৃগৃহে\\\\nআসিয়া জন্যগ্রহণ করিয়াছে এ কথা সে শিশুকাল হইথে বুঝিয়া লইয়াছিল।', 'থাহার ফল এই\\\\nহইয়াছিল, সাধারণের দৃষ্টিপথ হইথে সে আপনাকে গোপন করিয়া রাখিথে সর্বদাই চেষ্টা করিথ।', '\\\\nমনে করিথ, আমাকে সবাই ভুলিলে বাচি।', 'কিন্থু, বেদনা কি কেহ কখনো ভোলে?', 'পিথামাথার মনে\\\\nসে সর্বদাই জাগর্ক ছিল।', '\\\\n\\\\nবিশেষথ, থাহার মা থাহাকে নিজের একটা থ্রুটিস্বরুপ দেখিথেন; কেননা, মাথা পুথ্র অপেক্ষা কন্যাকে\\\\nনিজের অংশর্পে দেখেন- কন্যার কোনো অসম্পূর্ণথা দেখিলে সেটা যেন বিশেষরূপে নিজের লজ্জার\\\\nকারণ বলিয়া মনে করেন।', 'বরঞ্চ, কন্যার পিথা বাণীকণ্ঠ সুভাকে থাহার অন্য মেয়েদের\\\\nঅপেক্ষা যেন একটু বেশি ভালোবাসিথেন; কিন্থু মাথা থাহাকে নিজের গর্ভের কলঙ্ক জ্ঞান করিয়া\\\\nথাহার প্রথি বড়ো বিরক্থ ছিলেন।', 'সুভার কথা ছিল না, কিন্থু থাহার সুদীর্ঘপল্পববিশিষ্ট বড়ো বড়ো\\\\nদুটি কালো চোখ ছিল-এবং থাহার ওষ্ঠাধর ভাবের আভাসমাথ্র কচি কিশলয়ের মথো কীপিয়া উঠিথ।', '\", \"page_7\": \"১২ সুভা\\\\n\\\\nকথায় আমরা যে ভাব প্রকাশ করি সেটা আমাদিগকে অনেকটা নিজের চেষ্টায় গড়িয়া লইথে হয়,\\\\nকথকটা থর্জমা করার মথো; সকল সময়ে ঠিক হয় না, ক্ষমথার অভাবে অনেক সময়ে ভুলও\\\\nহয়।', 'কিন্থু কালো চোখকে কিছু থর্জমা করিথে হয় না মন আপনি থাহার উপরে ছায়া ফেলে;\\\\nভাব আপনি থাহার উপরে কখনো প্রসারিথ কখনো মুদিথ হয়; কখনো উজ্জ্বলভাবে জুলিয়া উঠে,\\\\nকখনো ম্লানভাবে নিবিয়া আসে,\\\\n\\\\nকখনো অন্থমান চন্দ্রের মথো অনিমেষভাবে চাহিয়া থাকে, কখনো দ্রুথ চঞ্চল বিদ্যুথের মথো\\\\nদিগ্বিদিকে ঠিকরিয়া উঠে।', 'মুখের ভাব বৈ আজন্মকাল যাহার অন্য ভাষা নাই থাহার চোখের ভাষা\\\\nঅসীম উদার এবং অথলস্পর্শ গভীর- অনেকটা স্বচ্ছ আকাশের মথো, উদয়াস্থ এবং ছায়ালোকের\\\\nনিস্থব্ধ রঙ্গভূমি।', 'এই বাক্যহীন মনুষ্যের মধ্যে বৃহৎ প্রকৃথির মথো একটা বিজন মহথ্ব আছে।', '\\\\nএইজন্য সাধারণ বালকবালিকারা থাহাকে একপ্রকার ভয় করিথ, থাহার সহিথ খেলা করিথ না।', '\\\\nসে নির্জন দ্বিপ্রহরের মথো শব্দহীন এবং সঙ্গীহীন।', '\\\\n\\\\nগ্রামের নাম চথ্থীপুর।', 'নদীটি বাংলাদেশের একটি ছোটো নদী, গৃহস্থঘরের মেয়েটির মথো, বহুদূর\\\\nপর্যন্থ থাহার প্রসার নহে; নিরলসা থন্বী নদীটি আপন কুল রক্ষা করিয়া কাজ করিয়া যায়; দুই\\\\nধারের গ্রামের সকলেরই সঙ্গে থাহার যেন একটা-না-একটা সম্পর্ক আছে।', 'দুই ধারে লোকালয় এবং\\\\nথবুচ্ছায়াঘন উচ্চ থট; নিম্নথল দিয়া গ্রামলক্ষ্মী স্রোথস্থিনী আথ্মবিস্মৃথ দ্রুথ পদক্ষেপে প্রফুল্ল হৃদয়ে\\\\nআপনার অসংখ্য কল্যাণকার্ষে চলিয়াছে।', '\\\\n\\\\nবাণীকণ্ঠের ঘর নদীর একেবারে উপরেই।', 'থাহার বাখারির বেড়া, আটচালা, গোয়ালঘর, টেকিশালা,\\\\nখড়ের স্থুপ, থেথুলথলা, আম কীঠাল এবং কলার বাগান নৌকাবাহী-মাথ্রেরই দৃষ্টি আকর্ষণ করে।', '\\\\nএই গার্হস্থ্য সচ্ছলথার মধ্যে বোবা মেয়েটি কাহারও নজরে পড়ে কি না জানি না, কিন্থু কাজকর্মে\\\\nযখনি অবসর পায় থখনি সে এই নদীথীরে আসিয়া বসে।', '\\\\n\\\\nপ্রকৃথি যেন থাহার ভাষার অভাব পূরণ করিয়া দেয়।', 'যেন থাহার হইয়া কথা কয়।', 'নদীর কলধ্বনি,\\\\nআন্দোলন-কম্পনের সহিথ এক হইয়া সমুদ্রের থরঙ্গরাশির ন্যায় বালিকার চিরনিস্থব্ধ হৃদয়-\\\\nউপকূলের নিকটে আসিয়া ভাঙিয়া পড়ে।', 'প্রকৃথির এই বিবিধ শব্দ এবং বিচিথ্র গথি, ইহাও বোবার\\\\nভাষা - বড়ো বড়ো চক্ষুপল্পববিশিষ্ট সুভার যে ভাষা থাহারই একটা বিশ্বব্যাপী বিস্থার; বিল্লিরবপূর্ণ\\\\nথৃণভূমি হইথে শব্দাথীথ নক্ষথ্রলোক পর্যন্থ কেবল ইঙ্গিথ, ভঙ্গি, সংগীথ, ক্রন্দন এবং দীর্ঘনিশ্বাস।', '\\\\n\\\\nএবং মধ্যা্কে যখন মাঝিরা জেলেরা খাইথে যাইথ, গৃহস্থেরা ঘুমাইথ, পাখিরা ডাকিথ না, খেয়া-নৌকা\\\\nকরিথ,থখন বুদ্ধ মহাকাশের থলে কেবল একটি বোবা প্রকৃথি এবং একটি বোবা মেয়ে মুখামুখি\\\\nচুপ করিয়া বসিয়া থাকিথ_ একজন সুবিস্থীর্ণ রৌদ্রে, আর-একজন ক্ষুদ্র থরুচ্ছায়ায়।', '\\\\n\\\\n২০১৮\", \"page_8\": \"২০১৮\\\\n\\\\nমাধ্যমিক বাংলা সাহিথ্য ১৩\\\\n\\\\nসুভার যে গুটিকথক অন্থরঙ্গ বন্ধুর দল ছিল না থাহা নহে।', 'গোয়ালের দুটি গাথী, থাহাদের নাম\\\\nসর্বশী ও পাঙ্গুলি।', 'সে নাম বালিকার মুখে থাহারা কখনো শুনে নাই, কিন্থু থাহার পদশব্দ থাহারা\\\\nচিনিথ_ থাহার কথাহীন একটা করুণ সুর ছিল, থাহার মর্ম থাহারা ভাষার অপেক্ষা সহজে বুঝিথ।', '\\\\nথাহারা মানুষের অপেক্ষা ভালো বুঝিথে পারিথ।', '\\\\n\\\\nসুভা গোয়ালে ঢুকিয়া দুই বাহুর ছারা সর্বশীর গ্রীবা বেষ্টন করিয়া থাহার কানের কাছে আপনার\\\\nগণ্ডদেশ ঘর্ষণ করিথ এবং পাঙ্গুলি স্িপ্দৃষ্টিথে থাহার প্রথি নিরীক্ষণ করিয়া থাহার গা চাটিথ।', '\\\\nবালিকা দিনের মধ্যে নিয়মিথ থিনবার করিয়া গোয়ালঘরে যাইথ, থাহা ছাড়া অনিয়মিথ আগমনও\\\\nছিল; গৃহে যে দিন কোনো কঠিন কথা শুনিথ সে দিন সে অসময়ে থাহার এই মুক বন্ধু দুটির কাছে\\\\nআসিথ- থাহার সহিষ্কুথাপরিপূর্ণ বিষাদশাস্থ দৃষ্টিপাথ হইথে থাহারা কী-একটা অন্ধ অনুমানশক্থির\\\\nদ্বারা বালিকার মর্মবেদনা যেন বুঝিথে পারিথ, এবং সুভার গা ঘেঁষিয়া আসিয়া অল্পে অল্পে থাহার\\\\nবাহুথে শিং ঘষিয়া ঘষিয়া থাহাকে নির্বাক ব্যাকুলথার সহিথ সান্থ্বনা দিথে চেষ্টা করিথ।', '\\\\n\\\\nইহারা ছাড়া ছাগল এবং বিড়ালশাবকও ছিল; কিন্থু থাহাদের সহিথ সুভার এরূপ সমকক্ষভাবে মৈথ্রী\\\\nছিল না, থথাপি থাহারা যথেষ্ট আনুগথ্য প্রকাশ করিথ।', 'বিড়ালশিশুটি দিনে এবং রাথ্রে যখন-\\\\nথখন সুভার গরম কোলটি নিঃসংকোচে অধিকার করিয়া সুখনিদ্রার আয়োজন করিথ এবং সুভা\\\\nথাহার গ্রীবা ও পৃষ্ঠে কোমল আঙ্গুলি বুলাইয়া দিলে যে থাহার নিদ্বাকর্ষণের বিশেষ সহায়থা হয়,\\\\nইঙ্গিথে এরুপ অভিপ্রায়ও প্রকাশ করিথ।', '\\\\n\\\\nউন্নথ শ্রেণির জীবের মধ্যে সুভার আরো একটি সঙ্গী জুটিয়াছিল।', 'কিন্থু থাহার সহিথ বালিকার ঠিক\\\\nকিরূপ সম্পর্ক ছিল থাহা নির্ণয় করা কঠিন, কারণ, সে ভাষাবিশিষ্ট জীব; সুথরাং উভয়ের মধ্যে\\\\nসমভাষা ছিল না।', '\\\\n\\\\nগৌসাইদের ছোটো ছেলেটি-থাহার নাম প্রথাপ | লোকটি নিথান্থ অকর্মণ্য।', 'সে যে কাজকর্ম করিয়া\\\\nসংসারের উন্নথি করিথে যথ্বু করিবে বহু চেষ্টার পর বাপ-মা সে আশা থ্যাগ করিয়াছেন।', 'অকর্মণ্য\\\\nলোকের একটা সুবিধা এই যে, আথ্মীয় লোকেরা থাহাদের উপরে বিরক্থ হয় বটে, কিন্থ প্রায়\\\\nথাহারা নিঃসম্পর্ক লোকদের প্রিয়পাথ্র হয়-কারণ,কোনো কার্ষে আবন্ধ না থাকাথে থাহারা সরকারি\\\\nসম্পথ্থি হইয়া দাঁড়ায়।', 'শহরের যেমন এক-আধটা গৃহসম্পর্কহীন সরকারি বাগান থাকা আবশ্যক\\\\nথেমনি গ্রামে দুই-চারিটা অকর্মণ্য সরকারি লোক থাকার বিশেষ প্রয়োজন।', 'কাজে-কর্মে আমোদে-\\\\nঅবসরে যেখানে একটা লোক কম পড়ে সেখানেই থাহাদিগকে হাথের কাছে পাওয়া যায়।', '\\\\n\\\\nপ্রথাপের প্রধান শখ- ছিপ ফেলিয়া মাছ ধরা।', 'ইহাথে অনেক সময় সহজে কাটানো যায়।', 'অপরাহ্রে\\\\nনদীথীরে ইহাকে প্রায় এই কাজে নিযুক্থ দেখা যাইথ | এবং এই উপলক্ষে সুভার সহিথ থাহার প্রায়\\\\nসাক্ষাৎ হইথ।', 'যে-কোনো কাজেই নিযুক্থ থাক, একটা সঙ্গী পাইলে প্রথাপ থাকে ভালো।', 'মাছ\\\\nধরার সময় বাক্যহীন সঙ্গীই সর্বাপেক্ষা শ্রেষ্ঠ- এইজন্য প্রথাপ সুভার মর্যাদা বৃঝিথ।', 'এইজন্য সকলেই\\\\nসুভাকে সুভা বলিথ, প্রথাপ আর- একটু অথিরিক্থ আদর সংযোগ করিয়া সুভাকে “সু* বলিয়া ডাকিথ।', '\", \"page_9\": \"১৪ সুভা\\\\n\\\\nসুভা থেথুলথলায় বসিয়া থাকিথ এবং প্রথাপ অনথিদূরে ছিপ ফেলিয়া জলের দিকে চাহিয়া\\\\nথাকিথ।', 'প্রথাপের জন্য একটি করিয়া পান বরাদ্দ ছিল, সুভা থাহা নিজে সাজিয়া আনিথ।', 'এবং\\\\nবোধ করি অনেকক্ষণ বসিয়া বসিয়া চাহিয়া ইচ্ছা করিথ, প্রথাপের কোনো-একটা বিশেষ সাহায্য\\\\nকরিথে, একটা-কোনো কাজে লাগিথে,কোনোমথে জানাইয়া দিথে যে এই পৃথিবীথে সেও একজন\\\\nকম প্রয়োজনীয় লোক নহে।', 'কিন্থু কিছুই করিবার ছিল না।', 'থখন সে মনে মনে বিধাথার কাছে\\\\nঅলৌকিক ক্ষমথা প্রার্থনা করিথ- মন্থ্রবলে সহসা এমন একটা আশ্চর্য কাণ্ড ঘটাইথে ইচ্ছা করিথ\\\\nযাহা দেখিয়া প্রথাপ আশ্চর্য হইয়া যাইথ, বলিথ, “থাই থো, আমাদের সুভির যে এথ ক্ষমথা থাহা\\\\nথো জানিথাম না।', \"'\\\\n\\\\nমনে করো, সভা যদি জলকুমারী হইথ, আস্থে আস্থে জল হইথে উঠিয়া একটা সাপের মাথার মণি ঘাটে\\\\nরাখিয়া যাইথ; প্রথাপ থাহার থুচ্ছ মাছ ধরা রাখিয়া সেই মানিক লইয়া জলে ডুব মারিথ; এবং পাথালে\\\\nগিয়া দেখিথ, রূপার অট্টালিকায় সোনার পালক্কে-কে বসিয়া?\", '_ আমাদের বাণীকষ্ঠের ঘরের সেই বোবা\\\\nমেয়ে সু- আমাদের সু সেই মণিদীপ্থ গভীর নিস্থব্ধ পাথালপুরীর একমাথ্র রাজকন্যা।', 'থাহা কি হইথে\\\\nপারিথ না।', 'থাহা কি এথই অসম্ভব।', 'আসলে কিছুই অসম্ভব নয়, কিন্থু থবুও সু প্রজাশূন্য পাথালের\\\\nরাজবংশে না জননয়া বাণীকণ্ঠের ঘরে আসিয়া জন্নিয়াছে এবং গোসাইদের ছেলে প্রথাপকে কিছুথেই\\\\nআশ্চর্য করিথে পারিথেছে না।', '\\\\n\\\\nসুভার বয়স ক্রমেই বাড়িয়া উঠিথেছে।', 'ক্রমে সে যেন আপনাকে আপনি অনুভব করিথে পারিথেছে।', '\\\\nযেন কোনো একটা পূর্ণিমাথিথিথে কোনো-একটা সমুদ্ব হইথে একটা জোয়ারের প্রোথ আসিয়া\\\\nথাহার অন্থ-রাআ্মাকে এক নৃথন অনির্বচনীয় চেথনাশক্থিথে পরিপূর্ণ করিয়া থুলিথেছে।', 'সে আপনাকে\\\\nআপনি দেখিথেছে,ভাবিথেছে, প্রশ্ন করিথেছে, এবং বুঝিথে পারিথেছে না।', '\\\\n\\\\nগভীর পূর্ণিমারাথ্রেসে এক-একদিন ধীরে শয়নগৃহের দ্বার খুলিয়া ভয়ে ভয়ে মুখ বাড়াইয়া বাহিরের\\\\nদিকে চাহিয়া দেখে পূর্ণিমাপ্রকৃথিও সুভার মথো একাকিনী সুপ্থ জগথের উপর জাগিয়া বসিয়া-\\\\nযৌবনের রহস্যে পুলকে বিষাদে অসীম নির্জনথার একেবারে শেষ সীমা পর্যন্থ, এমন-কি, থাহা\\\\nঅথিক্রম করিয়াও ধম্থম্ করিথেছে, একটি কথা কহিথে পারিথেছে না।', 'এই নিস্থব্ধ ব্যাকুল\\\\nপ্রকৃথির প্রান্থে একটি নিস্থব্ধ ব্যাকুল বালিকা দাঁড়াইয়া।', '\\\\n\\\\nএদিকে কন্যাভারগ্রস্থ পিথামাথা চিন্থিথ হইয়া উঠিয়াছেন।', 'লোকেও নিন্দা আরম্ভ করিয়াছে।', 'এমন-কি,\\\\nএক-ঘরে করিবে এমন জনরবও শুনা যায়।', 'বাণীকষ্ঠের সচ্ছল অবস্থা, দুই বেলাই মাছভাথ খায়,\\\\nএজন্য থাহার শথ্রু ছিল।', '\\\\n\\\\n্থ্রীপুরুষে বিস্থর পরামর্শ হইল।', 'কিছুদিনের মথো বাণী বিদেশে গেল।', '\\\\n\\\\n২০১৮\", \"page_10\": \"২০১৮\\\\n\\\\nমাধ্যমিক বাংলা সাহিথ্য ১৫\\\\n\\\\nবিদেশযাথ্রার উদ্যোগ হইথে লাগিল।', 'কুয়াশা-ঢাকা প্রভাথের মথো সুভার সমস্থ হৃদয় অশ্রুবাষ্পে\\\\nএকেবারে ভরিয়া গেল।', 'একটা অনির্দিষ্ট আশঙ্কা-বশে সে কিছুদিন হইথে ক্রমাগথ নির্বাক্ জন্থর\\\\nমথো থাহার বাপ-মায়ের সঙ্গে সঙ্গে ফিরিথ- ডাগর চক্ষু মেলিয়া থাহাদের মুখের দিকে চাহিয়া\\\\nকী-একটা বুঝিথে চেষ্টা করিথ, কিন্থু থাহারা কিছু বুঝাইয়া বলিথেন না।', '\\\\n\\\\nইথিমধ্যে একদিন অপরাহ্ন ছিপ ফেলিয়া প্রথাপ হাসিয়া কহিল, “কী রে সু, থোর নাকি বর পাওয়া\\\\nগেছে,থুই বিয়ে করথে যাচ্ছিস?', 'দেখিস আমাদের ভুলিস নে।', '” বলিয়া আবার মাছের দিকে মনোযোগ\\\\nকরিল।', \"\\\\n\\\\nমর্মবিদ্ধ হরিণী ব্যাধের দিকে যেমন করিয়া থাকায়, নীরবে বলিথে থাকে “আমি থোমার কাছে\\\\nকী দোষ করিয়াছিলাম', সুভা থেমনি করিয়া প্রথাপের দিকে চাহিল; সেদিন গাছের থলায় আর\\\\nবসিল না।\", 'বাণীকণ্ঠ নিদ্রা হইথে উঠিয়া শয়নগৃহে থামাক খাইথেছিলেন, সুভা থাহার পায়ের কাছে\\\\nবসিয়া থাহার মুখের দিকে চাহিয়া কীদিথে লাগিল।', 'অবশেষে থাহাকে সান্থ্বনা দিথে গিয়া বাণীকষ্ঠের\\\\nশুষ্ক কপোলে অশ্রু গড়াইয়া পড়িল।', '\\\\n\\\\nকাল কলিকাথায় যাইবার দিন স্থির হইয়াছে।', 'সুভা গোয়ালঘরে থাহার বাল্য-সখীদের কাছে বিদায়\\\\nলইথে গেল, থাহাদিগকে স্বহস্থে খাওয়াইয়া, গলা ধরিয়া একবার দুই চোখে যথ পারে কথা ভরিয়া\\\\nথাহাদের মুখের দিকে চাহিল- দুই নেথ্রপল্লব হইথে টপৃটপৃ করিয়া অশ্রাজল পড়থে লাগিল।', '\\\\n\\\\nশম্পশয্যায় লুটাইয়া পড়িল- যেন ধরণীকে, এই প্রকাণ্ড মূক মানবথাকে দুই বাহুথে ধরিয়া বলিথে\\\\nচাহে, “থুমি আমাকে যাইথে দিয়ো না, মা।', 'আমার মথো দুটি বাহু বাড়াইয়া থুমিও আমাকে ধরিয়া\\\\nরাখো।', '0 [সংক্ষিপ্থ]\\\\n\\\\nশব্দার্থ ও টীকা : গর্ভের কলঙ্ক - সন্থান হিসেবে কলঙ্ক, গর্ভ হলো মায়ের পেট যে ব্যক্থি বা বন্থকে\\\\nপরিবারে নেথিবাচক হিসেবে দেখা হয় থা হলো কলঙ্ক।', \"সুদীর্ঘ পল্পববিশিষ্ট _ বড় পাথাবিশিষ্ট, দীর্ঘ হলো\\\\nবড়, “সু” যুক্থ হয়ে 'বড়'কে বিশেষায়িথ করা হয়েছে।\", 'পল্লব হলো পাথা।', 'এখানে চোখের পাথা হিসেবে\\\\nব্যবহৃথ হয়েছে।', 'ওষ্ঠাধর - ওষ্ঠ এবং অধর, উপরের ও নিচের ঠোট [ওষ্ঠ+অধর _ ওয্ঠাধর] কিশলয়\\\\n- গাছের নথুন পাথা।', 'থর্জমা _ অনুবাদ, এক ভাষা থেকে অন্য ভাষায় বলা বা লেখা।', 'অন্থমান - ডুবন্থ,\\\\nডুবে যাচ্ছে এমন, চন্দ্র-সূর্যের পশ্চিম দিকে অদৃশ্য অবস্থা।', 'অনিমেষ -অপলক, পলকহীন,উদয়াস্থ - উদয়\\\\n+ অস্থ উদয়াস্থ, আবির্ভাব ও থিরোভাব, উঠা ও ডুবা।', 'ছায়ালোক - ছায়া + আলোক - ছায়ালোক।', 'কোনো\\\\nবন্থর ওপর আলো পড়লে যে প্রথিবিস্ব হয় থা হলো ছায়া।', 'বিজন মহথ্ব - বিজন - জনশূন্য, নির্জন।', 'মহথ্থ\\\\n_ অবদান।', 'বিজন মহথ্ব - কোলাহলমুক্থ প্রকৃথির অবস্থার যে আকর্ষণীয় দিক।', 'থন্বী - ক্ষীণ ও সুগঠিথ\\\\nঅঙ্গবিশিষ্ট।', 'বাখারি - কীধের দুদিকে দুপ্রান্থে ঝুলিয়ে বোঝা বহনের বাশের ফালি।', 'টেকিশালা - যে\\\\nঘরে টেকি রাখা হয়।', 'টেকি হলো ধান থেকে চাল থৈরির লোকজ যন্থ্র।', 'এখনো খ্রামীণ জীবনে অনেক\\\\nবাড়িথে টেকির ঘর আছে।']\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import json\n\n# Assuming tokenized_data is a dictionary or list with tokenized and sentence-split content\n# Example structure of tokenized_data:\n# tokenized_data = {\"sentence_1\": [\"This\", \"is\", \"an\", \"example\"], \"sentence_2\": [\"Another\", \"sentence\"]}\n\n# Save tokenized data to a JSON file\nwith open('tokenized_data.json', 'w', encoding='utf-8') as f:\n    json.dump(tokenized_data, f, ensure_ascii=False, indent=4)\n\nprint(\"Tokenized data saved to 'tokenized_data.json'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:32:35.513735Z","iopub.execute_input":"2025-02-05T10:32:35.514273Z","iopub.status.idle":"2025-02-05T10:32:35.522638Z","shell.execute_reply.started":"2025-02-05T10:32:35.514230Z","shell.execute_reply":"2025-02-05T10:32:35.521253Z"}},"outputs":[{"name":"stdout","text":"Tokenized data saved to 'tokenized_data.json'\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import nltk\nimport json\nimport re\n\n# Download necessary NLTK data (if not already done)\nnltk.download('punkt')\n\n# Load the tokenized data from the file (from Task 7)\nwith open('tokenized_data.json', 'r', encoding='utf-8') as f:\n    tokenized_data = json.load(f)\n\n# Define simple POS tagging rules using regular expressions\ndef pos_tag(tokens):\n    pos_tags = []\n    \n    for token in tokens:\n        # Rule for nouns (e.g., words starting with capital letter for place names, proper nouns)\n        if re.match(r'^[A-Zঅ-হ]+$', token):  # Check for capitalized or Bangla words\n            pos_tags.append((token, 'NOUN'))  # Example: Proper noun or place name\n        # Rule for verbs (e.g., words ending with specific patterns like 'ছিলাম', 'হলো')\n        elif re.match(r'.*(ছিল|হলো|যাবো|করবো)$', token):\n            pos_tags.append((token, 'VERB'))  # Example: Verb ending in 'ছিল', 'হলো'\n        # Rule for adjectives (e.g., descriptive words)\n        elif re.match(r'.*(সুন্দর|দ্রুত|বড়)$', token):  # Example: adjectives like 'সুন্দর', 'বড়'\n            pos_tags.append((token, 'ADJ'))\n        # Rule for stopwords (e.g., common function words like 'এবং', 'এ')\n        elif token in ['এবং', 'এ', 'হয়', 'তবে', 'এই']:\n            pos_tags.append((token, 'STOPWORD'))\n        else:\n            # Default POS tag as NOUN for unknown words\n            pos_tags.append((token, 'NOUN'))\n    \n    return pos_tags\n\n# Apply POS tagging to each section's tokens\npos_tagged_data = {}\nfor section, data in tokenized_data.items():\n    tokens = data[\"tokens\"]\n    tagged_tokens = pos_tag(tokens)  # Generate (token, tag) pairs\n    pos_tagged_data[section] = tagged_tokens\n\n# Save the POS tagged data\nwith open('pos_tagged_data.json', 'w', encoding='utf-8') as f:\n    json.dump(pos_tagged_data, f, ensure_ascii=False, indent=4)\n\n# Sample output for checking\nprint(\"POS Tagged Data for Section 1:\", pos_tagged_data[\"section_001\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:37:27.864429Z","iopub.execute_input":"2025-02-05T10:37:27.864995Z","iopub.status.idle":"2025-02-05T10:37:27.878716Z","shell.execute_reply.started":"2025-02-05T10:37:27.864961Z","shell.execute_reply":"2025-02-05T10:37:27.877306Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nPOS Tagged Data for Section 1: [('আমি', 'NOUN'), ('বাংলাদেশ', 'NOUN'), ('গিয়েছিলাম', 'NOUN'), ('গত', 'NOUN'), ('সপ্তাহে', 'NOUN'), ('এবং', 'STOPWORD'), ('মাঠে', 'NOUN'), ('খেলা', 'NOUN'), ('হয়েছিলো', 'NOUN')]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import nltk\nimport json\nimport re\n\n# Download necessary NLTK data (if not already done)\nnltk.download('punkt')\n\n# Example tokenized data (from Task 7)\n# You can load this from the file where your tokens are stored\ntokenized_data = {\n    \"section_001\": {\n        \"tokens\": [\n            \"আমি\", \"বাংলাদেশ\", \"গিয়েছিলাম\", \"গত\", \"সপ্তাহে\", \"এবং\", \"মাঠে\", \"খেলা\", \"হয়েছিলো\"\n        ]\n    }\n}\n\n# Define simple POS tagging rules using regular expressions\ndef pos_tag(tokens):\n    pos_tags = []\n    \n    for token in tokens:\n        # Rule for nouns (e.g., words starting with capital letter for place names, proper nouns)\n        if re.match(r'^[A-Zঅ-হ]+$', token):  # Check for capitalized or Bangla words\n            pos_tags.append((token, 'NOUN'))  # Example: Proper noun or place name\n        # Rule for verbs (e.g., words ending with specific patterns like 'ছিলাম', 'হলো')\n        elif re.match(r'.*(ছিল|হলো|যাবো|করবো)$', token):\n            pos_tags.append((token, 'VERB'))  # Example: Verb ending in 'ছিল', 'হলো'\n        # Rule for adjectives (e.g., descriptive words)\n        elif re.match(r'.*(সুন্দর|দ্রুত|বড়)$', token):  # Example: adjectives like 'সুন্দর', 'বড়'\n            pos_tags.append((token, 'ADJ'))\n        # Rule for stopwords (e.g., common function words like 'এবং', 'এ')\n        elif token in ['এবং', 'এ', 'হয়', 'তবে', 'এই']:\n            pos_tags.append((token, 'STOPWORD'))\n        else:\n            # Default POS tag as NOUN for unknown words\n            pos_tags.append((token, 'NOUN'))\n    \n    return pos_tags\n\n# Apply POS tagging to each section's tokens\npos_tagged_data = {}\nfor section, data in tokenized_data.items():\n    tokens = data[\"tokens\"]\n    tagged_tokens = pos_tag(tokens)  # Generate (token, tag) pairs\n    pos_tagged_data[section] = tagged_tokens\n\n# Save the POS tagged data\nwith open('pos_tagged_data.json', 'w', encoding='utf-8') as f:\n    json.dump(pos_tagged_data, f, ensure_ascii=False, indent=4)\n\n# Sample output for checking\nprint(\"POS Tagged Data for Section 1:\", pos_tagged_data[\"section_001\"])\n","metadata":{"execution":{"iopub.status.busy":"2025-02-05T10:30:00.374497Z","iopub.execute_input":"2025-02-05T10:30:00.375032Z","iopub.status.idle":"2025-02-05T10:30:01.567989Z","shell.execute_reply.started":"2025-02-05T10:30:00.374992Z","shell.execute_reply":"2025-02-05T10:30:01.566710Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nPOS Tagged Data for Section 1: [('আমি', 'NOUN'), ('বাংলাদেশ', 'NOUN'), ('গিয়েছিলাম', 'NOUN'), ('গত', 'NOUN'), ('সপ্তাহে', 'NOUN'), ('এবং', 'STOPWORD'), ('মাঠে', 'NOUN'), ('খেলা', 'NOUN'), ('হয়েছিলো', 'NOUN')]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"pip install tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:38:07.801968Z","iopub.execute_input":"2025-02-05T10:38:07.802360Z","iopub.status.idle":"2025-02-05T10:38:12.462391Z","shell.execute_reply.started":"2025-02-05T10:38:07.802329Z","shell.execute_reply":"2025-02-05T10:38:12.460901Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from transformers import pipeline\n\n# Initialize a simple pipeline\nnlp = pipeline(\"sentiment-analysis\")\n\n# Test the pipeline\nresult = nlp(\"I love using Hugging Face Transformers!\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:38:14.072815Z","iopub.execute_input":"2025-02-05T10:38:14.073257Z","iopub.status.idle":"2025-02-05T10:38:50.180922Z","shell.execute_reply.started":"2025-02-05T10:38:14.073225Z","shell.execute_reply":"2025-02-05T10:38:50.179758Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f576137f279b445999e0e78e37496f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03243b1ec5ff44f282d4428301fc217d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56d9aafb3ab4681a9ea1e854dd1f92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f583405b5a164f969751eb517c75d8ac"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[{'label': 'POSITIVE', 'score': 0.9971315860748291}]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:07:37.653847Z","iopub.execute_input":"2025-02-05T11:07:37.654313Z","iopub.status.idle":"2025-02-05T11:07:42.040517Z","shell.execute_reply.started":"2025-02-05T11:07:37.654273Z","shell.execute_reply":"2025-02-05T11:07:42.039204Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"pip install 'transformers[tf-cpu]'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:07:45.563354Z","iopub.execute_input":"2025-02-05T11:07:45.563728Z","iopub.status.idle":"2025-02-05T11:09:39.058996Z","shell.execute_reply.started":"2025-02-05T11:07:45.563699Z","shell.execute_reply":"2025-02-05T11:09:39.057025Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[tf-cpu] in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[tf-cpu]) (4.67.1)\nCollecting keras<2.16,>2.9 (from transformers[tf-cpu])\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting tensorflow-cpu<2.16,>2.9 (from transformers[tf-cpu])\n  Downloading tensorflow_cpu-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting onnxconverter-common (from transformers[tf-cpu])\n  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\nCollecting tf2onnx (from transformers[tf-cpu])\n  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\nCollecting tensorflow-text<2.16 (from transformers[tf-cpu])\n  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nCollecting keras-nlp<0.14.0,>=0.3.1 (from transformers[tf-cpu])\n  Downloading keras_nlp-0.12.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting tensorflow-probability<0.24 (from transformers[tf-cpu])\n  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[tf-cpu]) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[tf-cpu]) (4.12.2)\nRequirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (0.1.7)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (1.4.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (13.9.4)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (0.1.8)\nRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (0.3.6)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[tf-cpu]) (2.4.1)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu])\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (2.5.0)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu])\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (1.68.1)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu])\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-cpu<2.16,>2.9->transformers[tf-cpu])\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.24->transformers[tf-cpu]) (4.4.2)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.24->transformers[tf-cpu]) (3.1.0)\nRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text<2.16->transformers[tf-cpu]) (0.16.1)\nCollecting tensorflow<2.16,>=2.15.0 (from tensorflow-text<2.16->transformers[tf-cpu])\n  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common->transformers[tf-cpu]) (1.17.0)\nINFO: pip is looking at multiple versions of onnxconverter-common to determine which version is compatible with other requirements. This could take a while.\nCollecting onnxconverter-common (from transformers[tf-cpu])\n  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[tf-cpu]) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[tf-cpu]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[tf-cpu]) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[tf-cpu]) (2024.12.14)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.45.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (1.2.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.1.3)\nRequirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text<2.16->transformers[tf-cpu]) (2.17.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (0.0.8)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[tf-cpu]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[tf-cpu]) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers[tf-cpu]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers[tf-cpu]) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (2.18.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (1.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers[tf-cpu]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp<0.14.0,>=0.3.1->transformers[tf-cpu]) (0.1.2)\nINFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\nCollecting tf-keras>=2.14.1 (from tensorflow-hub>=0.13.0->tensorflow-text<2.16->transformers[tf-cpu])\n  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.0.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>2.9->transformers[tf-cpu]) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras_nlp-0.12.1-py3-none-any.whl (570 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_cpu-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, keras, tensorboard, ml-dtypes, tensorflow, tf-keras, tensorflow-text, tf2onnx, tensorflow-probability, tensorflow-cpu, onnxconverter-common, keras-nlp\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.17.0\n    Uninstalling wrapt-1.17.0:\n      Successfully uninstalled wrapt-1.17.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.5.0\n    Uninstalling keras-3.5.0:\n      Successfully uninstalled keras-3.5.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n  Attempting uninstall: tf-keras\n    Found existing installation: tf_keras 2.17.0\n    Uninstalling tf_keras-2.17.0:\n      Successfully uninstalled tf_keras-2.17.0\n  Attempting uninstall: tensorflow-text\n    Found existing installation: tensorflow-text 2.17.0\n    Uninstalling tensorflow-text-2.17.0:\n      Successfully uninstalled tensorflow-text-2.17.0\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.24.0\n    Uninstalling tensorflow-probability-0.24.0:\n      Successfully uninstalled tensorflow-probability-0.24.0\n  Attempting uninstall: keras-nlp\n    Found existing installation: keras-nlp 0.18.1\n    Uninstalling keras-nlp-0.18.1:\n      Successfully uninstalled keras-nlp-0.18.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.15.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 keras-nlp-0.12.1 ml-dtypes-0.3.2 onnxconverter-common-1.13.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-cpu-2.15.1 tensorflow-estimator-2.15.0 tensorflow-probability-0.23.0 tensorflow-text-2.15.0 tf-keras-2.15.1 tf2onnx-1.16.1 wrapt-1.14.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"pip install 'transformers[torch]'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:10:11.233834Z","iopub.execute_input":"2025-02-05T11:10:11.234222Z","iopub.status.idle":"2025-02-05T11:10:15.782081Z","shell.execute_reply.started":"2025-02-05T11:10:11.234192Z","shell.execute_reply":"2025-02-05T11:10:15.780624Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.5.1+cu121)\nRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.2.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[torch]) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[torch]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[torch]) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers[torch]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers[torch]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers[torch]) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"pip install 'transformers[flax]'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:12:44.610186Z","iopub.execute_input":"2025-02-05T11:12:44.610646Z","iopub.status.idle":"2025-02-05T11:13:15.435077Z","shell.execute_reply.started":"2025-02-05T11:12:44.610611Z","shell.execute_reply":"2025-02-05T11:13:15.433715Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[flax] in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[flax]) (4.67.1)\nCollecting jax<=0.4.13,>=0.4.1 (from transformers[flax])\n  Downloading jax-0.4.13.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting jaxlib<=0.4.13,>=0.4.1 (from transformers[flax])\n  Downloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\nCollecting flax<=0.7.0,>=0.4.1 (from transformers[flax])\n  Downloading flax-0.7.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting optax<=0.1.4,>=0.0.8 (from transformers[flax])\n  Downloading optax-0.1.4-py3-none-any.whl.metadata (12 kB)\nCollecting scipy<1.13.0 (from transformers[flax])\n  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<=0.7.0,>=0.4.1->transformers[flax]) (1.1.0)\nRequirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax<=0.7.0,>=0.4.1->transformers[flax]) (0.6.4)\nRequirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<=0.7.0,>=0.4.1->transformers[flax]) (0.1.71)\nRequirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<=0.7.0,>=0.4.1->transformers[flax]) (13.9.4)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<=0.7.0,>=0.4.1->transformers[flax]) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers[flax]) (2024.9.0)\nRequirement already satisfied: ml_dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax<=0.4.13,>=0.4.1->transformers[flax]) (0.3.2)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax<=0.4.13,>=0.4.1->transformers[flax]) (3.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers[flax]) (2.4.1)\nRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax<=0.1.4,>=0.0.8->transformers[flax]) (1.4.0)\nRequirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax<=0.1.4,>=0.0.8->transformers[flax]) (0.1.88)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[flax]) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[flax]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[flax]) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[flax]) (2024.12.14)\nINFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\nCollecting chex>=0.1.5 (from optax<=0.1.4,>=0.0.8->transformers[flax])\n  Downloading chex-0.1.87-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.85-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.84-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.83-py3-none-any.whl.metadata (17 kB)\n  Downloading chex-0.1.82-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax<=0.1.4,>=0.0.8->transformers[flax]) (0.12.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<=0.7.0,>=0.4.1->transformers[flax]) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<=0.7.0,>=0.4.1->transformers[flax]) (2.18.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[flax]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers[flax]) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers[flax]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers[flax]) (2024.2.0)\nRequirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax<=0.7.0,>=0.4.1->transformers[flax]) (1.11.0)\nINFO: pip is looking at multiple versions of orbax-checkpoint to determine which version is compatible with other requirements. This could take a while.\nCollecting orbax-checkpoint (from flax<=0.7.0,>=0.4.1->transformers[flax])\n  Downloading orbax_checkpoint-0.11.2-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.11.1-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.11.0-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.10.3-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.10.2-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.10.1-py3-none-any.whl.metadata (1.9 kB)\n  Downloading orbax_checkpoint-0.10.0-py3-none-any.whl.metadata (1.9 kB)\nINFO: pip is still looking at multiple versions of orbax-checkpoint to determine which version is compatible with other requirements. This could take a while.\n  Downloading orbax_checkpoint-0.9.1-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.9.0-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.8.0-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.6.3-py3-none-any.whl.metadata (1.8 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading orbax_checkpoint-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.6.1-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.6.0-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.23-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.22-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.21-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.20-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.19-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.18-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.17-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.16-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax<=0.7.0,>=0.4.1->transformers[flax]) (1.6.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax<=0.7.0,>=0.4.1->transformers[flax]) (3.20.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers[flax]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax<=0.7.0,>=0.4.1->transformers[flax]) (0.1.2)\nRequirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax<=0.7.0,>=0.4.1->transformers[flax]) (6.4.5)\nRequirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax<=0.7.0,>=0.4.1->transformers[flax]) (3.21.0)\nDownloading flax-0.7.0-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jaxlib-0.4.13-cp310-cp310-manylinux2014_x86_64.whl (71.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading optax-0.1.4-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chex-0.1.82-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orbax_checkpoint-0.5.16-py3-none-any.whl (217 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.0/217.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: jax\n  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518770 sha256=b79366cde341bb8a6e5d79455366941b19a5fca719c6732e6381692a414fde22\n  Stored in directory: /root/.cache/pip/wheels/f3/7a/25/f297f69029b5e4064e4736a0c4b3996a44cc27781c120bcb99\nSuccessfully built jax\nInstalling collected packages: scipy, jaxlib, jax, chex, orbax-checkpoint, optax, flax\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.4.33\n    Uninstalling jaxlib-0.4.33:\n      Successfully uninstalled jaxlib-0.4.33\n  Attempting uninstall: jax\n    Found existing installation: jax 0.4.33\n    Uninstalling jax-0.4.33:\n      Successfully uninstalled jax-0.4.33\n  Attempting uninstall: chex\n    Found existing installation: chex 0.1.88\n    Uninstalling chex-0.1.88:\n      Successfully uninstalled chex-0.1.88\n  Attempting uninstall: orbax-checkpoint\n    Found existing installation: orbax-checkpoint 0.6.4\n    Uninstalling orbax-checkpoint-0.6.4:\n      Successfully uninstalled orbax-checkpoint-0.6.4\n  Attempting uninstall: optax\n    Found existing installation: optax 0.2.4\n    Uninstalling optax-0.2.4:\n      Successfully uninstalled optax-0.2.4\n  Attempting uninstall: flax\n    Found existing installation: flax 0.8.5\n    Uninstalling flax-0.8.5:\n      Successfully uninstalled flax-0.8.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chex-0.1.82 flax-0.7.0 jax-0.4.13 jaxlib-0.4.13 optax-0.1.4 orbax-checkpoint-0.5.16 scipy-1.12.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"pip install git+https://github.com/huggingface/transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:13:21.829931Z","iopub.execute_input":"2025-02-05T11:13:21.830304Z","iopub.status.idle":"2025-02-05T11:13:59.804988Z","shell.execute_reply.started":"2025-02-05T11:13:21.830266Z","shell.execute_reply":"2025-02-05T11:13:59.803678Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-8l36r68_\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-8l36r68_\n  Resolved https://github.com/huggingface/transformers to commit d8080d55c789acea91c40300da6deee849cd8f77\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.49.0.dev0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.49.0.dev0) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.49.0.dev0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.49.0.dev0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.49.0.dev0) (2024.2.0)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10678087 sha256=495fc9418828fa5067c1329d370e88e88f219f8314cb6829c10976bfead564ec\n  Stored in directory: /tmp/pip-ephem-wheel-cache-aie3n5hg/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed transformers-4.49.0.dev0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:14:05.887409Z","iopub.execute_input":"2025-02-05T11:14:05.887831Z","iopub.status.idle":"2025-02-05T11:14:05.896127Z","shell.execute_reply.started":"2025-02-05T11:14:05.887797Z","shell.execute_reply":"2025-02-05T11:14:05.894199Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-1fbf8a8a95e4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-66-1fbf8a8a95e4>, line 1)","output_type":"error"}],"execution_count":66},{"cell_type":"code","source":"from transformers import pipeline\n\n# Initialize sentiment analysis pipeline\nsentiment_analyzer = pipeline('sentiment-analysis')\n\n# Perform sentiment analysis on the input text\nresult = sentiment_analyzer('বিদেশযাত্রার উদ্যোগ হইতে লাগিল ।')\n\n# Print the result\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:14:25.547025Z","iopub.execute_input":"2025-02-05T11:14:25.547442Z","iopub.status.idle":"2025-02-05T11:14:25.855663Z","shell.execute_reply.started":"2025-02-05T11:14:25.547407Z","shell.execute_reply":"2025-02-05T11:14:25.854173Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"[{'label': 'POSITIVE', 'score': 0.533724308013916}]\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import re\nimport json\n\n# Step 1: Define a simple Bangla-specific tokenizer\ndef bangla_tokenizer(text):\n    # This regex splits the text into words and punctuation\n    tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n    return tokens\n\n# Step 2: Handle special tokens like numbers or emoticons\ndef handle_special_tokens(tokens):\n    # Keep numbers as tokens\n    tokens = [t if t.isdigit() else t for t in tokens]\n    # Example: Keep emoticons as special tokens (optional)\n    special_tokens = {\":)\", \":(\"}\n    tokens = [t if t not in special_tokens else f\"EMOTICON_{t}\" for t in tokens]\n    return tokens\n\n# Step 3: Sentence Splitting based on Bangla sentence markers (like \"।\", \"!\", \"?\")\ndef bangla_sentence_splitter(text):\n    # Split sentences on Bangla full stop, exclamation mark, or question mark\n    sentences = re.split(r'([।!?])', text)  # Keep the punctuation\n    sentences = [s.strip() + mark for s, mark in zip(sentences[::2], sentences[1::2])]  # Merge punctuation with sentence\n    return sentences\n\n# Step 4: Validate the output (e.g., handle abbreviations or decimal numbers)\ndef validate_output(sentences):\n    # Handle abbreviations or decimal numbers if needed\n    sentences = [s.replace(\"বিশ্ববিদ্যালয়.\", \"বিশ্ববিদ্যালয়।\") for s in sentences]  # Example for abbreviation handling\n    return sentences\n\n# Step 5: Process each section in the normalized data\nnormalized_data = {}  # Assuming this contains the text from Task 5, replace this with the actual data\n\n# Example normalized data (replace with your actual data)\nnormalized_data = {\n    \"section_001\": \"আমি বাংলাদেশ গিয়েছিলাম। সেখানে অনেক কিছু দেখেছি!\",\n    \"section_002\": \"বিশ্ববিদ্যালয়। আমি ভালো আছি :)\"\n}\n\n# Tokenizing and splitting sentences\ntokenized_data = {}\n\nfor section_id, section_text in normalized_data.items():\n    tokens = bangla_tokenizer(section_text)  # Tokenize the text\n    tokens = handle_special_tokens(tokens)  # Handle special tokens\n    sentences = bangla_sentence_splitter(section_text)  # Split the text into sentences\n    validated_sentences = validate_output(sentences)  # Validate sentences\n    \n    # Store the result\n    tokenized_data[section_id] = {\n        \"tokens\": tokens,\n        \"sentences\": validated_sentences\n    }\n\n# Save the tokenized data to a JSON file\nwith open('tokenized_data.json', 'w', encoding='utf-8') as f:\n    json.dump(tokenized_data, f, ensure_ascii=False, indent=4)\n\n# Save sentence boundaries to a separate file (optional)\nsentence_boundaries = {}\nfor section_id, section_text in normalized_data.items():\n    sentences = bangla_sentence_splitter(section_text)\n    validated_sentences = validate_output(sentences)\n    \n    sentence_boundaries[section_id] = validated_sentences\n\n# Save sentence boundaries to a file\nwith open('sentence_boundaries.json', 'w', encoding='utf-8') as f:\n    json.dump(sentence_boundaries, f, ensure_ascii=False, indent=4)\n\n# Print sample output for the first section (optional)\nprint(\"Tokens of the first section:\", tokenized_data[\"section_001\"][\"tokens\"])\nprint(\"Sentences of the first section:\", tokenized_data[\"section_001\"][\"sentences\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:40:22.763508Z","iopub.execute_input":"2025-02-05T10:40:22.763961Z","iopub.status.idle":"2025-02-05T10:40:22.778441Z","shell.execute_reply.started":"2025-02-05T10:40:22.763930Z","shell.execute_reply":"2025-02-05T10:40:22.777339Z"}},"outputs":[{"name":"stdout","text":"Tokens of the first section: ['আম', 'ি', 'ব', 'া', 'ং', 'ল', 'া', 'দ', 'ে', 'শ', 'গ', 'ি', 'য', '়', 'ে', 'ছ', 'ি', 'ল', 'া', 'ম', '।', 'স', 'ে', 'খ', 'া', 'ন', 'ে', 'অন', 'ে', 'ক', 'ক', 'ি', 'ছ', 'ু', 'দ', 'ে', 'খ', 'ে', 'ছ', 'ি', '!']\nSentences of the first section: ['আমি বাংলাদেশ গিয়েছিলাম।', 'সেখানে অনেক কিছু দেখেছি!']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import json\nimport re\nfrom nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\n\n# Function to perform POS tagging using NLTK or another library\ndef pos_tagging(text):\n    # Tokenize the text\n    tokens = word_tokenize(text)\n    \n    # Perform POS tagging\n    tagged_tokens = pos_tag(tokens)  # Replace with a Bangla POS tagger if available\n    \n    return tagged_tokens\n\n# Load tokenized data from Task 7 (example)\nwith open('tokenized_data.json', 'r', encoding='utf-8') as f:\n    tokenized_data = json.load(f)\n\n# Apply POS tagging for each section\npos_tagged_data = {}\nfor section_id, section_data in tokenized_data.items():\n    section_text = \" \".join(section_data['tokens'])\n    \n    # Get POS tags for the section text\n    tagged_tokens = pos_tagging(section_text)\n    \n    # Store the tagged tokens (token, POS tag)\n    pos_tagged_data[section_id] = tagged_tokens\n\n# Save POS tagged data to a new JSON file\nwith open('pos_tagged_data.json', 'w', encoding='utf-8') as f:\n    json.dump(pos_tagged_data, f, ensure_ascii=False, indent=4)\n\nprint(\"POS tagging complete. Data saved to 'pos_tagged_data.json'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:40:37.022601Z","iopub.execute_input":"2025-02-05T10:40:37.023025Z","iopub.status.idle":"2025-02-05T10:40:37.039204Z","shell.execute_reply.started":"2025-02-05T10:40:37.022992Z","shell.execute_reply":"2025-02-05T10:40:37.037664Z"}},"outputs":[{"name":"stdout","text":"POS tagging complete. Data saved to 'pos_tagged_data.json'.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"pip install spacy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:40:53.161778Z","iopub.execute_input":"2025-02-05T10:40:53.162229Z","iopub.status.idle":"2025-02-05T10:40:57.654678Z","shell.execute_reply.started":"2025-02-05T10:40:53.162196Z","shell.execute_reply":"2025-02-05T10:40:57.653356Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!pip install spacy\n!python -m spacy download xx_ent_wiki_sm  # or en_core_web_sm if xx_ent_wiki_sm is not available\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:41:34.863934Z","iopub.execute_input":"2025-02-05T10:41:34.864358Z","iopub.status.idle":"2025-02-05T10:41:50.053281Z","shell.execute_reply.started":"2025-02-05T10:41:34.864329Z","shell.execute_reply":"2025-02-05T10:41:50.051531Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting xx-ent-wiki-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.7.0/xx_ent_wiki_sm-3.7.0-py3-none-any.whl (11.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from xx-ent-wiki-sm==3.7.0) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.10.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.27.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.12.14)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->xx-ent-wiki-sm==3.7.0) (0.1.2)\nInstalling collected packages: xx-ent-wiki-sm\nSuccessfully installed xx-ent-wiki-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('xx_ent_wiki_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import spacy\nfrom sklearn.metrics import precision_recall_fscore_support\nimport json\n\n# Step 1: Load the pre-trained NER model (make sure the model is downloaded correctly)\ntry:\n    nlp = spacy.load(\"xx_ent_wiki_sm\")  # A multilingual model (substitute with a Bangla model if available)\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    exit()\n\n# Step 2: Function to perform Named Entity Recognition\ndef extract_entities(text):\n    doc = nlp(text)\n    entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n    return entities\n\n# Step 3: Sample text for testing\nsample_text = \"ভ্রমর ভোৌ করিয়া স্থলপদ্মের বৈঠকখানায় গিয়া রাজপুত্রের সঙ্গে ইয়ারকি করিতে বসিলেন।\"\n\n# Step 4: Extract entities\nentities = extract_entities(sample_text)\n\n# Step 5: Display extracted entities\nprint(f\"Extracted Entities: {entities}\")\n\n# Step 6: Save the annotated data in JSON format\nner_annotated_data = {\n    \"section_1\": entities\n}\nwith open(\"ner_annotated_data.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(ner_annotated_data, f, ensure_ascii=False, indent=4)\n\n# Step 7: Evaluate performance (use ground truth and predictions)\n# Example ground truth and predicted data\nground_truth = [(\"ভ্রমর\", \"PERSON\"), (\"রাজপুত্র\", \"PERSON\")]\npredictions = [(\"ভ্রমর\", \"PERSON\"), (\"রাজপুত্র\", \"PERSON\")]\n\n# Extract labels from ground truth and predictions\ntrue_labels = [label for _, label in ground_truth]\npred_labels = [label for _, label in predictions]\n\n# Step 8: Calculate Precision, Recall, F1-Score\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n\n# Step 9: Output the performance evaluation metrics\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1-Score: {f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:47:21.766222Z","iopub.execute_input":"2025-02-05T10:47:21.766722Z","iopub.status.idle":"2025-02-05T10:47:24.657234Z","shell.execute_reply.started":"2025-02-05T10:47:21.766684Z","shell.execute_reply":"2025-02-05T10:47:24.655978Z"}},"outputs":[{"name":"stdout","text":"Extracted Entities: [{'text': 'ভোৌ', 'label': 'MISC'}, {'text': 'ইয়ারকি করিতে বসিলেন', 'label': 'MISC'}]\nPrecision: 1.0\nRecall: 1.0\nF1-Score: 1.0\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport json\n\n# Load the tokenized data (Task 7)\nwith open('tokenized_data.json', 'r', encoding='utf-8') as f:\n    tokenized_data = json.load(f)\n\n# Extract text from tokenized data for keyphrase extraction\ndocuments = []\nfor section, data in tokenized_data.items():\n    # Assuming 'tokens' key contains the tokenized words\n    document = \" \".join(data['tokens'])  # Adjust according to actual structure\n    documents.append(document)\n\n# Apply TF-IDF Vectorizer\nvectorizer = TfidfVectorizer(stop_words='english', max_features=10)  # Limit to top 10 keyphrases\nX = vectorizer.fit_transform(documents)\n\n# Get top keyphrases for each document\nfeature_names = vectorizer.get_feature_names_out()\ntop_keyphrases = []\nfor doc in range(X.shape[0]):\n    sorted_indices = X[doc, :].toarray()[0].argsort()[::-1]\n    top_doc_keyphrases = [feature_names[i] for i in sorted_indices[:10]]  # Top 10 keyphrases\n    top_keyphrases.append(top_doc_keyphrases)\n\n# Output the keyphrases\nfor idx, keyphrases in enumerate(top_keyphrases):\n    print(f\"Document {idx+1} Keyphrases: {', '.join(keyphrases)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:48:10.044884Z","iopub.execute_input":"2025-02-05T10:48:10.045448Z","iopub.status.idle":"2025-02-05T10:48:10.065476Z","shell.execute_reply.started":"2025-02-05T10:48:10.045392Z","shell.execute_reply":"2025-02-05T10:48:10.063550Z"}},"outputs":[{"name":"stdout","text":"Document 1 Keyphrases: অন, আম, লয়, বব, আছ\nDocument 2 Keyphrases: লয়, বব, আছ, আম, অন\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"\nimport json\n\n# Sample tokenized data (Replace with actual Task 7 output)\n\n\n# Load the tokenized data (Task 7)\nwith open('tokenized_data.json', 'r', encoding='utf-8') as f:\n    tokenized_data = json.load(f)\n\n# Predefined affixes and roots\nroots = [\"খেল\", \"সত্য\", \"কলম\", \"ভাল\", \"বাসা\", \"অপেক্ষা\"]\nprefixes = [\"অ-\", \"অপ-\", \"পূর্ব-\", \"অতঃ\"]\nsuffixes = [\"-টা\", \"-টি\", \"-তা\", \"-ন\", \"-ই\", \"-র\", \"-এ\"]\n\n# Function to perform morphological analysis\ndef analyze_morphology(tokens):\n    results = []\n    for token in tokens:\n        root = \"\"\n        prefix = \"\"\n        suffix = \"\"\n        \n        # Check for prefix\n        for p in prefixes:\n            if token.startswith(p):\n                prefix = p\n                token = token[len(p):]\n                break\n        \n        # Check for suffix\n        for s in suffixes:\n            if token.endswith(s):\n                suffix = s\n                token = token[:-len(s)]\n                break\n        \n        # Check for root (remaining token after prefix/suffix removal)\n        if token in roots:\n            root = token\n        else:\n            # Handle case where the root is not directly found (e.g., due to sandhi, reduplication)\n            root = token  # This is a basic placeholder; handle specific cases here\n        \n        results.append({\n            \"original_word\": token,\n            \"root\": root,\n            \"prefix\": prefix,\n            \"suffix\": suffix\n        })\n    return results\n\n# Analyzing morphological structure for all sections in the tokenized data\nall_results = {}\nfor section, data in tokenized_data.items():\n    tokens = data[\"tokens\"]\n    all_results[section] = analyze_morphology(tokens)\n\n# Print out the morphological analysis\nfor section, analysis in all_results.items():\n    print(f\"Section: {section}\")\n    for item in analysis:\n        print(f\"Original Word: {item['original_word']}, Root: {item['root']}, Prefix: {item['prefix']}, Suffix: {item['suffix']}\")\n    print(\"\\n\")\n\n# Optionally, save the results to a JSON file for further review\nwith open(\"morphological_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(all_results, f, ensure_ascii=False, indent=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:50:59.850420Z","iopub.execute_input":"2025-02-05T10:50:59.850957Z","iopub.status.idle":"2025-02-05T10:50:59.866351Z","shell.execute_reply.started":"2025-02-05T10:50:59.850918Z","shell.execute_reply":"2025-02-05T10:50:59.864943Z"}},"outputs":[{"name":"stdout","text":"Section: section1\nOriginal Word: খেলাটা, Root: খেলাটা, Prefix: , Suffix: \nOriginal Word: অসত্য, Root: অসত্য, Prefix: , Suffix: \nOriginal Word: কলম, Root: কলম, Prefix: , Suffix: \nOriginal Word: ভাল, Root: ভাল, Prefix: , Suffix: \n\n\nSection: section2\nOriginal Word: খেলা, Root: খেলা, Prefix: , Suffix: \nOriginal Word: বাসা, Root: বাসা, Prefix: , Suffix: \nOriginal Word: অপেক্ষা, Root: অপেক্ষা, Prefix: , Suffix: \n\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import json\n\n# Load the tokenized data (Task 7)\nwith open('tokenized_data.json', 'r', encoding='utf-8') as f:\n    tokenized_data = json.load(f)\n\n# Predefined affixes and roots\nroots = [\"খেল\", \"সত্য\", \"কলম\", \"ভাল\", \"বাসা\", \"অপেক্ষা\"]\nprefixes = [\"অ-\", \"অপ-\", \"পূর্ব-\", \"অতঃ\"]\nsuffixes = [\"-টা\", \"-টি\", \"-তা\", \"-ন\", \"-ই\", \"-র\", \"-এ\"]\n\n# Function to perform morphological analysis\ndef analyze_morphology(tokens):\n    results = []\n    for token in tokens:\n        root = \"\"\n        prefix = \"\"\n        suffix = \"\"\n        \n        # Check for prefix\n        for p in prefixes:\n            if token.startswith(p):\n                prefix = p\n                token = token[len(p):]  # Remove prefix\n                break\n        \n        # Check for suffix\n        for s in suffixes:\n            if token.endswith(s):\n                suffix = s\n                token = token[:-len(s)]  # Remove suffix\n                break\n        \n        # Check for root (remaining token after prefix/suffix removal)\n        if token in roots:\n            root = token\n        else:\n            # Handle case where the root is not directly found (e.g., due to sandhi, reduplication)\n            root = token  # This is a basic placeholder; handle specific cases here\n        \n        results.append({\n            \"original_word\": token,\n            \"root\": root,\n            \"prefix\": prefix,\n            \"suffix\": suffix\n        })\n    return results\n\n# Analyzing morphological structure for all sections in the tokenized data\nall_results = {}\nfor section, data in tokenized_data.items():\n    tokens = data[\"tokens\"]\n    all_results[section] = analyze_morphology(tokens)\n\n# Print out the morphological analysis\nfor section, analysis in all_results.items():\n    print(f\"Section: {section}\")\n    for item in analysis:\n        print(f\"Original Word: {item['original_word']}, Root: {item['root']}, Prefix: {item['prefix']}, Suffix: {item['suffix']}\")\n    print(\"\\n\")\n\n# Optionally, save the results to a JSON file for further review\nwith open(\"morphological_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(all_results, f, ensure_ascii=False, indent=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:53:29.028965Z","iopub.execute_input":"2025-02-05T10:53:29.030079Z","iopub.status.idle":"2025-02-05T10:53:29.056605Z","shell.execute_reply.started":"2025-02-05T10:53:29.029987Z","shell.execute_reply":"2025-02-05T10:53:29.055255Z"}},"outputs":[{"name":"stdout","text":"Section: section_001\nOriginal Word: আম, Root: আম, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: ব, Root: ব, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: ং, Root: ং, Prefix: , Suffix: \nOriginal Word: ল, Root: ল, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: দ, Root: দ, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: শ, Root: শ, Prefix: , Suffix: \nOriginal Word: গ, Root: গ, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: য, Root: য, Prefix: , Suffix: \nOriginal Word: ়, Root: ়, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: ছ, Root: ছ, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: ল, Root: ল, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: ম, Root: ম, Prefix: , Suffix: \nOriginal Word: ।, Root: ।, Prefix: , Suffix: \nOriginal Word: স, Root: স, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: খ, Root: খ, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: ন, Root: ন, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: অন, Root: অন, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: ক, Root: ক, Prefix: , Suffix: \nOriginal Word: ক, Root: ক, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: ছ, Root: ছ, Prefix: , Suffix: \nOriginal Word: ু, Root: ু, Prefix: , Suffix: \nOriginal Word: দ, Root: দ, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: খ, Root: খ, Prefix: , Suffix: \nOriginal Word: ে, Root: ে, Prefix: , Suffix: \nOriginal Word: ছ, Root: ছ, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: !, Root: !, Prefix: , Suffix: \n\n\nSection: section_002\nOriginal Word: ব, Root: ব, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: শ, Root: শ, Prefix: , Suffix: \nOriginal Word: ্, Root: ্, Prefix: , Suffix: \nOriginal Word: বব, Root: বব, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: দ, Root: দ, Prefix: , Suffix: \nOriginal Word: ্, Root: ্, Prefix: , Suffix: \nOriginal Word: য, Root: য, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: লয়, Root: লয়, Prefix: , Suffix: \nOriginal Word: ।, Root: ।, Prefix: , Suffix: \nOriginal Word: আম, Root: আম, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: ভ, Root: ভ, Prefix: , Suffix: \nOriginal Word: া, Root: া, Prefix: , Suffix: \nOriginal Word: ল, Root: ল, Prefix: , Suffix: \nOriginal Word: ো, Root: ো, Prefix: , Suffix: \nOriginal Word: আছ, Root: আছ, Prefix: , Suffix: \nOriginal Word: ি, Root: ি, Prefix: , Suffix: \nOriginal Word: :, Root: :, Prefix: , Suffix: \nOriginal Word: ), Root: ), Prefix: , Suffix: \n\n\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import json\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# Sample labeled sentiment data (replace with actual data)\ndata = [\n    (\"বিদেশযাত্রার উদ্যোগ হইতে লাগিল ।\", \"positive\"),\n]\n   \n\n# Split data into texts and labels\ntexts, labels = zip(*data)\n\n# Vectorize text using TF-IDF\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(texts)\ny = labels\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nprint(classification_report(y_test, y_pred))\n\n# Predict sentiment for new text (e.g., from Task 7)\nnew_text = [\"এই অধ্যায়টা বেশ শিক্ষামূলক\"]\nnew_X = vectorizer.transform(new_text)\nprediction = model.predict(new_X)\nprint(f\"Predicted Sentiment: {prediction[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T13:31:11.759301Z","iopub.execute_input":"2025-02-05T13:31:11.759684Z","iopub.status.idle":"2025-02-05T13:31:12.577737Z","shell.execute_reply.started":"2025-02-05T13:31:11.759651Z","shell.execute_reply":"2025-02-05T13:31:12.576348Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3ef314226887>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Split into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train Naive Bayes model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."],"ename":"ValueError","evalue":"With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"pip install transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:10:24.214370Z","iopub.execute_input":"2025-02-05T11:10:24.214844Z","iopub.status.idle":"2025-02-05T11:10:28.743156Z","shell.execute_reply.started":"2025-02-05T11:10:24.214807Z","shell.execute_reply":"2025-02-05T11:10:28.741841Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n\n# Load a pre-trained sentiment analysis model (e.g., BERT-based for multilingual tasks)\nmodel_name = \"bhadresh-savani/bert-base-uncased-sentiment\"\nsentiment_model = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)\n\n# Example text from Task 7\ntexts = [\n    \"বিদেশযাত্রার উদ্যোগ হইতে লাগিল ।\", \n    \"এটা খুব খারাপ\", \n    \"মাঝে মাঝে ভালো লাগছে\"\n]\n\n# Make predictions using the pre-trained model\npredictions = sentiment_model(texts)\n\n# Output predictions\nfor text, prediction in zip(texts, predictions):\n    print(f\"Text: {text} | Sentiment: {prediction['label']} | Confidence: {prediction['score']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:15:23.530980Z","iopub.execute_input":"2025-02-05T11:15:23.531374Z","iopub.status.idle":"2025-02-05T11:15:23.683586Z","shell.execute_reply.started":"2025-02-05T11:15:23.531345Z","shell.execute_reply":"2025-02-05T11:15:23.681989Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/bhadresh-savani/bert-base-uncased-sentiment/resolve/main/config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_connection_errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67a3484b-4473490e68b2737323366f91;c2bcce84-e131-4872-9ccd-17857e89490d)\n\nRepository Not Found for url: https://huggingface.co/bhadresh-savani/bert-base-uncased-sentiment/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-f3914b575df4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load a pre-trained sentiment analysis model (e.g., BERT-based for multilingual tasks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bhadresh-savani/bert-base-uncased-sentiment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msentiment_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Example text from Task 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    813\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mresolved_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_connection_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: bhadresh-savani/bert-base-uncased-sentiment is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"],"ename":"OSError","evalue":"bhadresh-savani/bert-base-uncased-sentiment is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","output_type":"error"}],"execution_count":70},{"cell_type":"code","source":"from transformers import pipeline\n\n# Use a different, publicly available model for multilingual sentiment analysis\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\nsentiment_model = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)\n\n# Example text from Task 7\ntexts = [\n    \"বিদেশযাত্রার উদ্যোগ হইতে লাগিল ।\", \n    \"এটা খুব খারাপ\", \n    \"মাঝে মাঝে ভালো লাগছে\"\n]\n\n# Make predictions using the pre-trained model\npredictions = sentiment_model(texts)\n\n# Output predictions\nfor text, prediction in zip(texts, predictions):\n    print(f\"Text: {text} | Sentiment: {prediction['label']} | Confidence: {prediction['score']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:11:19.004157Z","iopub.execute_input":"2025-02-05T11:11:19.004502Z","iopub.status.idle":"2025-02-05T11:11:19.785554Z","shell.execute_reply.started":"2025-02-05T11:11:19.004474Z","shell.execute_reply":"2025-02-05T11:11:19.784375Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Text: বিদেশযাত্রার উদ্যোগ হইতে লাগিল । | Sentiment: 3 stars | Confidence: 0.31\nText: এটা খুব খারাপ | Sentiment: 3 stars | Confidence: 0.36\nText: মাঝে মাঝে ভালো লাগছে | Sentiment: 3 stars | Confidence: 0.36\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import json\nimport gensim\nfrom gensim import corpora\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom nltk.corpus import stopwords\n\n# Sample tokenized data (replace with actual Task 7 data)\ntokenized_data = {\n    \"section1\": {\n        \"tokens\": [\"এই\", \"বই\", \"খুব\", \"ভালো\", \"এবং\", \"শিক্ষামূলক\", \"অধ্যায়\"]\n    },\n    \"section2\": {\n        \"tokens\": [\"আমি\", \"খুব\", \"উৎসাহী\", \"অন্বেষণ\", \"করি\", \"নতুন\", \"বিষয়\"]\n    }\n}\n\n# Prepare the text data for LDA by joining tokens\ntexts = [\" \".join(data[\"tokens\"]) for data in tokenized_data.values()]\n\n# Prepare stopwords list\nstop_words = set(stopwords.words('english'))\n\n# Vectorize text using TF-IDF\nvectorizer = TfidfVectorizer(stop_words=stop_words)\nX = vectorizer.fit_transform(texts)\n\n# Apply LDA\nlda = LatentDirichletAllocation(n_components=3, random_state=42)  # k=3 topics for example\nlda.fit(X)\n\n# Get the topic distribution for each document\ntopic_distributions = lda.transform(X)\n\n# Display top words for each topic\nn_top_words = 10\nwords = vectorizer.get_feature_names_out()\nfor topic_idx, topic in enumerate(lda.components_):\n    print(f\"Topic {topic_idx}:\")\n    top_words_idx = topic.argsort()[-n_top_words:][::-1]\n    top_words = [words[i] for i in top_words_idx]\n    print(\"Top words:\", \", \".join(top_words))\n    print()\n\n# Save the topic distribution for each document\ntopic_model_results = {}\nfor i, topic_distribution in enumerate(topic_distributions):\n    topic_model_results[f\"section_{i+1}\"] = topic_distribution.tolist()\n\n# Save results to a JSON file\nwith open(\"topic_model_results.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(topic_model_results, f, ensure_ascii=False, indent=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:11:29.847529Z","iopub.execute_input":"2025-02-05T11:11:29.848058Z","iopub.status.idle":"2025-02-05T11:12:14.513274Z","shell.execute_reply.started":"2025-02-05T11:11:29.848019Z","shell.execute_reply":"2025-02-05T11:12:14.511640Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-0b088f77c78f>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Vectorize text using TF-IDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Apply LDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         )\n\u001b[0;32m-> 2133\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             )\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ngram_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0maccepted\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {'how', \"should've\", 'ours', \"doesn't\", 'were', 'same', 'do', 'with', \"hasn't\", 'below', 'most', 'again', 'there', \"wouldn't\", 'are', 'once', 'until', 'of', 'd', 'll', 'weren', 'have', 'into', 'over', 'hers', 'then', 'didn', 'their', 'shouldn', 'in', \"mightn't\", 'him', 'so', 'your', 'the', 'here', 'when', \"hadn't\", 'off', 'had', 'hadn', \"wasn't\", 'be', 'by', 'mustn', 'own', 'further', 'did', 'only', 'now', 'that', 'yourself', 'such', 'them', 'as', 'having', 'does', 'its', 'myself', 'mightn', \"isn't\", 'but', 'about', 'too', 'isn', 'our', 'to', 'am', 'a', 'both', 'for', \"you'll\", 'which', 'ma', \"don't\", 'can', 'theirs', 'than', 'during', 'my', \"you're\", 'they', 'under', 'was', 'because', 'where', \"haven't\", 'against', 'any', 'at', 'above', 'while', 'me', 'after', 'her', 'who', 'why', 'will', 'hasn', 'what', 'doing', 'herself', \"it's\", 'ain', 'up', 'and', \"won't\", \"she's\", 've', 's', 're', 'ourselves', 'is', 'more', 'just', 'don', \"you've\", 'each', \"shan't\", 'on', 'if', 'from', 'those', 'yourselves', 'we', 'themselves', 'few', 'an', 'has', 'whom', 'm', 'very', 'through', 'out', \"that'll\", 'yours', 'down', \"mustn't\", 'before', \"aren't\", 'needn', 'these', 'been', 'being', 'you', 'wouldn', 'between', \"didn't\", 'itself', 'i', \"you'd\", 'haven', 't', 'he', 'not', 'wasn', 'shan', \"weren't\", 'some', 'nor', 'couldn', \"couldn't\", 'this', \"needn't\", 'himself', 'should', 'aren', 'y', 'o', 'his', 'no', 'doesn', 'she', 'all', 'other', 'or', 'it', \"shouldn't\", 'won'} instead."],"ename":"InvalidParameterError","evalue":"The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {'how', \"should've\", 'ours', \"doesn't\", 'were', 'same', 'do', 'with', \"hasn't\", 'below', 'most', 'again', 'there', \"wouldn't\", 'are', 'once', 'until', 'of', 'd', 'll', 'weren', 'have', 'into', 'over', 'hers', 'then', 'didn', 'their', 'shouldn', 'in', \"mightn't\", 'him', 'so', 'your', 'the', 'here', 'when', \"hadn't\", 'off', 'had', 'hadn', \"wasn't\", 'be', 'by', 'mustn', 'own', 'further', 'did', 'only', 'now', 'that', 'yourself', 'such', 'them', 'as', 'having', 'does', 'its', 'myself', 'mightn', \"isn't\", 'but', 'about', 'too', 'isn', 'our', 'to', 'am', 'a', 'both', 'for', \"you'll\", 'which', 'ma', \"don't\", 'can', 'theirs', 'than', 'during', 'my', \"you're\", 'they', 'under', 'was', 'because', 'where', \"haven't\", 'against', 'any', 'at', 'above', 'while', 'me', 'after', 'her', 'who', 'why', 'will', 'hasn', 'what', 'doing', 'herself', \"it's\", 'ain', 'up', 'and', \"won't\", \"she's\", 've', 's', 're', 'ourselves', 'is', 'more', 'just', 'don', \"you've\", 'each', \"shan't\", 'on', 'if', 'from', 'those', 'yourselves', 'we', 'themselves', 'few', 'an', 'has', 'whom', 'm', 'very', 'through', 'out', \"that'll\", 'yours', 'down', \"mustn't\", 'before', \"aren't\", 'needn', 'these', 'been', 'being', 'you', 'wouldn', 'between', \"didn't\", 'itself', 'i', \"you'd\", 'haven', 't', 'he', 'not', 'wasn', 'shan', \"weren't\", 'some', 'nor', 'couldn', \"couldn't\", 'this', \"needn't\", 'himself', 'should', 'aren', 'y', 'o', 'his', 'no', 'doesn', 'she', 'all', 'other', 'or', 'it', \"shouldn't\", 'won'} instead.","output_type":"error"}],"execution_count":62},{"cell_type":"code","source":"import nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\nimport json\n\n# Download NLTK stopwords (if not already downloaded)\nnltk.download('stopwords')\n\n# Get NLTK stopwords\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\n# Sample text data (replace with your actual tokenized text)\ntexts = [\n    \"This is the first document.\",\n    \"This document is the second document.\",\n    \"And this is the third one.\",\n    \"Is this the first document?\"\n]\n\n# Vectorize text using TF-IDF with NLTK stopwords\nvectorizer = TfidfVectorizer(stop_words=stop_words)\nX = vectorizer.fit_transform(texts)\n\n# Apply LDA\nlda = LDA(n_components=3, random_state=42)\nlda.fit(X)\n\n# Print top words for each topic\nn_top_words = 10\nfeature_names = vectorizer.get_feature_names_out()\n\nfor topic_idx, topic in enumerate(lda.components_):\n    print(f\"Topic #{topic_idx}:\")\n    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n    print()\n\n# Topic modeling results for each document\ntopic_results = []\nfor i, topic in enumerate(lda.transform(X)):\n    topic_results.append({\"document_index\": i, \"topic_distribution\": topic.tolist()})\n\n# Save the topic modeling results to a file\nwith open(\"topic_model_results.json\", \"w\") as outfile:\n    json.dump(topic_results, outfile, indent=4)\n\nprint(\"Topic modeling results have been saved to 'topic_model_results.json'.\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:15:46.713683Z","iopub.execute_input":"2025-02-05T11:15:46.714087Z","iopub.status.idle":"2025-02-05T11:15:46.754011Z","shell.execute_reply.started":"2025-02-05T11:15:46.714058Z","shell.execute_reply":"2025-02-05T11:15:46.752736Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nTopic #0:\nsecond document first third one\n\nTopic #1:\ndocument first second third one\n\nTopic #2:\none third second first document\n\nTopic modeling results have been saved to 'topic_model_results.json'.\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport json\n\n# Example tokenized text and labels (replace with actual data)\ntexts = [\n    \"বিদেশযাত্রার উদ্যোগ হইতে লাগিল ।\",\n  \n]\nlabels = [\"legal\", \"finance\", \"technical\", \"legal\"]\n\n# Vectorize text using TF-IDF\nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(texts)\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n\n# Initialize classifiers\nnb_classifier = MultinomialNB()\nsvm_classifier = SVC(kernel='linear')\n\n# Train classifiers\nnb_classifier.fit(X_train, y_train)\nsvm_classifier.fit(X_train, y_train)\n\n# Predict on test set\nnb_predictions = nb_classifier.predict(X_test)\nsvm_predictions = svm_classifier.predict(X_test)\n\n# Evaluation\nprint(\"Naive Bayes Classification Report:\")\nprint(classification_report(y_test, nb_predictions))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, nb_predictions))\n\nprint(\"\\nSVM Classification Report:\")\nprint(classification_report(y_test, svm_predictions))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, svm_predictions))\n\n# Save model if needed\nimport joblib\njoblib.dump(nb_classifier, 'naive_bayes_classifier.pkl')\njoblib.dump(svm_classifier, 'svm_classifier.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:16:43.267331Z","iopub.execute_input":"2025-02-05T11:16:43.267816Z","iopub.status.idle":"2025-02-05T11:16:43.334163Z","shell.execute_reply.started":"2025-02-05T11:16:43.267773Z","shell.execute_reply":"2025-02-05T11:16:43.332055Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-ef53a842f536>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Split the data into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Initialize classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 4]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1, 4]","output_type":"error"}],"execution_count":75},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\n# Example tokenized data (list of lists of words)\ntokenized_data = [\n    [\"this\", \"is\", \"the\", \"first\", \"sentence\"],\n    [\"this\", \"is\", \"the\", \"second\", \"sentence\"],\n    # Add more tokenized text here\n]\n\n# Train Word2Vec model\nword2vec_model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n\n# Save the model\nword2vec_model.save(\"word2vec_bangla.model\")\n\n# Example: Get vector for a word\nvector = word2vec_model.wv['sentence']\nprint(f\"Vector for 'sentence': {vector}\")\n\n# Example: Find most similar words to 'sentence'\nsimilar_words = word2vec_model.wv.most_similar('sentence', topn=10)\nprint(f\"Most similar words to 'sentence': {similar_words}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:16:59.206733Z","iopub.execute_input":"2025-02-05T11:16:59.207120Z","iopub.status.idle":"2025-02-05T11:16:59.229467Z","shell.execute_reply.started":"2025-02-05T11:16:59.207087Z","shell.execute_reply":"2025-02-05T11:16:59.228261Z"}},"outputs":[{"name":"stdout","text":"Vector for 'sentence': [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\nMost similar words to 'sentence': [('the', -0.01084117777645588), ('second', -0.027750365436077118), ('is', -0.05234675109386444), ('first', -0.059876300394535065), ('this', -0.111670583486557)]\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"from gensim.models import FastText\n\n# Train FastText model\nfasttext_model = FastText(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n\n# Save the model\nfasttext_model.save(\"fasttext_bangla.model\")\n\n# Example: Get vector for a word\nvector = fasttext_model.wv['sentence']\nprint(f\"Vector for 'sentence': {vector}\")\n\n# Example: Find most similar words to 'sentence'\nsimilar_words = fasttext_model.wv.most_similar('sentence', topn=10)\nprint(f\"Most similar words to 'sentence': {similar_words}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:17:04.760045Z","iopub.execute_input":"2025-02-05T11:17:04.760383Z","iopub.status.idle":"2025-02-05T11:17:06.843072Z","shell.execute_reply.started":"2025-02-05T11:17:04.760356Z","shell.execute_reply":"2025-02-05T11:17:06.842038Z"}},"outputs":[{"name":"stdout","text":"Vector for 'sentence': [-1.0012314e-03  2.3569611e-03  1.0409536e-03 -1.6631888e-03\n  1.9683233e-03 -1.0740025e-03  1.3170161e-03  1.2627222e-03\n  7.3809795e-05 -9.9265808e-04  2.5776802e-03 -1.7871390e-04\n  1.3832883e-03 -2.3745578e-03 -3.0688403e-04 -7.4558693e-04\n  1.2936974e-03  6.8700477e-04 -1.1166570e-03 -7.8726053e-04\n  7.8886893e-04  1.4902048e-03  4.3414251e-04  5.6531234e-04\n  7.3821360e-04 -2.7080791e-03  8.8786602e-04  7.6170254e-04\n -9.0490055e-04 -2.0248949e-04 -1.8070947e-03  6.2860228e-04\n  5.6036754e-04 -3.2289657e-03 -9.9195982e-04 -4.7001877e-04\n  9.6502423e-04  2.7476714e-04 -2.0726179e-03  3.7762930e-04\n -6.3014042e-04 -1.7813452e-03  1.6289027e-03  1.7431584e-03\n -1.2638170e-03  3.0606662e-04 -3.1371508e-03 -6.0104055e-04\n  1.9681697e-04  1.0879160e-03 -1.7816564e-03 -1.1390281e-03\n -1.3294938e-03 -3.8955713e-04  2.0285568e-05 -1.4684005e-03\n -2.7513437e-04 -5.6187616e-04 -1.5809125e-03  2.7885378e-04\n -1.3404741e-03  2.6776767e-04  7.4448809e-04 -4.5925262e-04\n  5.5392110e-04  1.8892908e-03 -9.4846700e-04  6.3657132e-04\n  1.6566281e-03  3.6580313e-04  6.8300380e-04  5.2124605e-04\n  1.6687369e-03 -1.7005758e-04 -7.7493588e-04  4.4164262e-04\n -3.4318355e-04 -1.5110390e-03  7.0438796e-04 -7.8829314e-04\n  2.9536616e-04  5.1133946e-04 -3.2930280e-04  3.0736873e-04\n  5.1814929e-04 -6.0530059e-04 -1.2851605e-04  5.0091796e-04\n  2.0934490e-03  1.1730189e-03 -8.3554373e-04  1.3431479e-03\n  5.3425119e-05  1.1152445e-03 -8.2676939e-05 -9.0814818e-04\n  8.9651858e-04  1.0248498e-03 -4.1327611e-04 -9.7331620e-05]\nMost similar words to 'sentence': [('this', 0.18197667598724365), ('is', 0.09770294278860092), ('the', 0.05400815233588219), ('first', 0.005666488315910101), ('second', -0.1739381104707718)]\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\n# Load a pre-trained Bangla BERT model\ntokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert\")\nmodel = BertForMaskedLM.from_pretrained(\"sagorsarker/bangla-bert\")\n\n# Load your tokenized dataset (adjust the file paths as needed)\ndataset = load_dataset('text', data_files={'train': 'train.txt', 'test': 'test.txt'})\n\n# Tokenize dataset\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding='max_length')\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# Fine-tune the model using Trainer\ntraining_args = TrainingArguments(\n    output_dir='./results', \n    num_train_epochs=3, \n    per_device_train_batch_size=16, \n    per_device_eval_batch_size=16,\n    evaluation_strategy=\"epoch\",\n    logging_dir='./logs',\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['test']\n)\n\ntrainer.train()\n\n# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_bangla_bert\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:17:10.567747Z","iopub.execute_input":"2025-02-05T11:17:10.568092Z","iopub.status.idle":"2025-02-05T11:17:10.882471Z","shell.execute_reply.started":"2025-02-05T11:17:10.568065Z","shell.execute_reply":"2025-02-05T11:17:10.880830Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__path__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextra_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mextra_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m )\n\u001b[0;32m---> 90\u001b[0;31m from .trainer_pt_utils import (\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mDistributedTensorGatherer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'set_rng_state_for_device' from 'transformers.trainer_pt_utils' (/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-a6825895940a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load a pre-trained Bangla BERT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sagorsarker/bangla-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_missing_backend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextra_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mextra_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_import_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0;31m# This can be removed once every exportable object has a `export()` export.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'set_rng_state_for_device' from 'transformers.trainer_pt_utils' (/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py)"],"ename":"RuntimeError","evalue":"Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'set_rng_state_for_device' from 'transformers.trainer_pt_utils' (/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py)","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"pip install --upgrade transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:17:20.209219Z","iopub.execute_input":"2025-02-05T11:17:20.209588Z","iopub.status.idle":"2025-02-05T11:17:26.294244Z","shell.execute_reply.started":"2025-02-05T11:17:20.209527Z","shell.execute_reply":"2025-02-05T11:17:26.292935Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.49.0.dev0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"pip install --upgrade datasets torch accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:17:28.018085Z","iopub.execute_input":"2025-02-05T11:17:28.018447Z","iopub.status.idle":"2025-02-05T11:21:06.197332Z","shell.execute_reply.started":"2025-02-05T11:17:28.018417Z","shell.execute_reply":"2025-02-05T11:21:06.195933Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torch\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nCollecting accelerate\n  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m992.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\ntorchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 triton-3.2.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"pip install --upgrade datasets torch accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:21:16.114831Z","iopub.execute_input":"2025-02-05T11:21:16.115177Z","iopub.status.idle":"2025-02-05T11:21:21.068193Z","shell.execute_reply.started":"2025-02-05T11:21:16.115147Z","shell.execute_reply":"2025-02-05T11:21:21.066799Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.6.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"import random\nimport json\n\n# Load outputs from different NLP tasks\nwith open('pos_tagged_data.json', 'r') as f:\n    pos_tagged_data = json.load(f)\n\nwith open('ner_tagged_data.json', 'r') as f:\n    ner_tagged_data = json.load(f)\n\n# Define a function to check accuracy of POS and NER tags\ndef check_pos_accuracy(pos_data, gold_standard):\n    mistakes = []\n    for i, (text, gold_tags) in enumerate(zip(pos_data, gold_standard)):\n        for word, predicted_tag in text:\n            if predicted_tag not in gold_tags.get(word, []):\n                mistakes.append(f\"Mismatch in sentence {i}: {word} predicted as {predicted_tag}, expected {gold_tags.get(word)}\")\n    return mistakes\n\ndef check_ner_accuracy(ner_data, gold_standard):\n    mistakes = []\n    for i, (entities, gold_entities) in enumerate(zip(ner_data, gold_standard)):\n        for entity, predicted_label in entities:\n            if predicted_label not in gold_entities.get(entity, []):\n                mistakes.append(f\"Mismatch in sentence {i}: {entity} predicted as {predicted_label}, expected {gold_entities.get(entity)}\")\n    return mistakes\n\n# Random sampling for QA\nsample_pos_data = random.sample(pos_tagged_data, 5)  # Sample 5 sentences\nsample_ner_data = random.sample(ner_tagged_data, 5)\n\n# Gold standard (manually annotated)\ngold_standard_pos = {}  # Format: {'word': ['correct_tag']}\ngold_standard_ner = {}  # Format: {'entity': ['correct_label']}\n\n# Perform checks\npos_mistakes = check_pos_accuracy(sample_pos_data, gold_standard_pos)\nner_mistakes = check_ner_accuracy(sample_ner_data, gold_standard_ner)\n\n# Compile QA report\nqa_report = {\n    \"pos_mistakes\": pos_mistakes,\n    \"ner_mistakes\": ner_mistakes\n}\n\n# Output the QA report\nwith open('qa_report.json', 'w') as f:\n    json.dump(qa_report, f, indent=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:22:44.453353Z","iopub.execute_input":"2025-02-05T11:22:44.453785Z","iopub.status.idle":"2025-02-05T11:22:44.499577Z","shell.execute_reply.started":"2025-02-05T11:22:44.453745Z","shell.execute_reply":"2025-02-05T11:22:44.498035Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-e2a3282e1f2e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpos_tagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner_tagged_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mner_tagged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ner_tagged_data.json'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'ner_tagged_data.json'","output_type":"error"}],"execution_count":86},{"cell_type":"code","source":"file_path = ''\nfile_path = \nwith open(file_path, 'r') as f:\n    pos_tagged_data = json.load(f)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-05T10:24:31.186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfile_path = 'pos_tagged_data.json'\nif os.path.exists(file_path):\n    with open(file_path, 'r') as f:\n        pos_tagged_data = json.load(f)\nelse:\n    print(f\"The file {file_path} does not exist.\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-05T10:24:31.186Z"}},"outputs":[],"execution_count":null}]}